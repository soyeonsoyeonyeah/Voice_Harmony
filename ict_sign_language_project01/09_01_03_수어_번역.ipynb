{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7f55880d-e145-4609-b511-fb6d366ae83e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Channels:\n",
      " - pytorch\n",
      " - nvidia\n",
      " - defaults\n",
      "Platform: win-64\n",
      "Collecting package metadata (repodata.json): ...working... done\n",
      "Solving environment: ...working... done\n",
      "\n",
      "# All requested packages already installed.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Retrying (Retry(total=2, connect=None, read=None, redirect=None, status=None)) after connection broken by 'ReadTimeoutError(\"HTTPSConnectionPool(host='repo.anaconda.com', port=443): Read timed out. (read timeout=9.15)\")': /pkgs/msys2/win-64/repodata.json.zst\n",
      "\n",
      "Retrying (Retry(total=2, connect=None, read=None, redirect=None, status=None)) after connection broken by 'ReadTimeoutError(\"HTTPSConnectionPool(host='repo.anaconda.com', port=443): Read timed out. (read timeout=9.15)\")': /pkgs/main/win-64/repodata.json.zst\n",
      "\n",
      "Retrying (Retry(total=2, connect=None, read=None, redirect=None, status=None)) after connection broken by 'ReadTimeoutError(\"HTTPSConnectionPool(host='repo.anaconda.com', port=443): Read timed out. (read timeout=60.0)\")': /pkgs/main/noarch/repodata.json.zst\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!conda install pytorch==2.3.0 torchvision==0.18.0 torchaudio==2.3.0 pytorch-cuda=11.8 -c pytorch -c nvidia -y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "55b3620f-1c90-468c-b76b-ee8e8c9886a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4cbbce17-2dfa-4290-9c8b-0869f4c5b35d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#파이토치 GPU 사용 여부 확인\n",
    "torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "21463c92-562b-4c18-9f24-3f2db1ddacf3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.utils.data as D\n",
    "import numpy as np\n",
    "import pickle\n",
    "from tqdm import tqdm\n",
    "import random\n",
    "import math\n",
    "from tqdm.notebook import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b897c74f-ec97-474b-bbe7-8ab383b0622c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#word_to_index.pickle : 수어 스크립트 단어를 어떤 숫자로 변환 해야하는지 저장한 파일\n",
    "with open('data/word_to_index.pickle', 'rb') as f:\n",
    "    #수어 스크립트 단어를 어떤 숫자로 변환 해야하는지 저장한 파일 읽어서 word_to_index에 저장\n",
    "    word_to_index = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "82d76d10-8578-459c-8ef2-29e3d122e69f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'<PAD>': 0,\n",
       " '<START>': 1,\n",
       " '<END>': 2,\n",
       " '6분': 3,\n",
       " '깊고': 4,\n",
       " '고흥군': 5,\n",
       " '되었을': 6,\n",
       " '빼고': 7,\n",
       " '20분': 8,\n",
       " '위경련': 9,\n",
       " '뒤집': 10,\n",
       " '벗고': 11,\n",
       " '털어': 12,\n",
       " '지탱': 13,\n",
       " '휴식': 14,\n",
       " '우리': 15,\n",
       " '용문산': 16,\n",
       " '35': 17,\n",
       " '1시': 18,\n",
       " '된': 19,\n",
       " '14': 20,\n",
       " '영등포구': 21,\n",
       " '바닥': 22,\n",
       " '지키시기': 23,\n",
       " '되었습니다': 24,\n",
       " '농사일': 25,\n",
       " '도크': 26,\n",
       " '식수': 27,\n",
       " '별': 28,\n",
       " '위험하므로': 29,\n",
       " '건물': 30,\n",
       " '세종': 31,\n",
       " '서': 32,\n",
       " '겼을': 33,\n",
       " '도내': 34,\n",
       " '물이': 35,\n",
       " '생긴': 36,\n",
       " '화악산': 37,\n",
       " '어려울': 38,\n",
       " '남부': 39,\n",
       " '14일': 40,\n",
       " '어깨': 41,\n",
       " '강변': 42,\n",
       " '그러한': 43,\n",
       " '때': 44,\n",
       " '05일': 45,\n",
       " '으로': 46,\n",
       " '실외': 47,\n",
       " '라디오': 48,\n",
       " '5월': 49,\n",
       " '여유': 50,\n",
       " '백운산': 51,\n",
       " '반': 52,\n",
       " '여주시': 53,\n",
       " '검은': 54,\n",
       " '나': 55,\n",
       " '완만': 56,\n",
       " '지날': 57,\n",
       " '시청': 58,\n",
       " '오후': 59,\n",
       " '북동쪽': 60,\n",
       " '15일': 61,\n",
       " '전라남도': 62,\n",
       " '야': 63,\n",
       " '건넌다': 64,\n",
       " '근육': 65,\n",
       " '뒤쪽': 66,\n",
       " '우천': 67,\n",
       " '청': 68,\n",
       " '낮게하고': 69,\n",
       " '로프': 70,\n",
       " '놀라서': 71,\n",
       " '경주': 72,\n",
       " '자': 73,\n",
       " '거북이': 74,\n",
       " '암벽': 75,\n",
       " '건너지': 76,\n",
       " '밀고': 77,\n",
       " '끼': 78,\n",
       " '달리는': 79,\n",
       " '사람': 80,\n",
       " '이나': 81,\n",
       " '물기': 82,\n",
       " '하천': 83,\n",
       " '맡기고': 84,\n",
       " '바랍니다': 85,\n",
       " '남남서': 86,\n",
       " '경기': 87,\n",
       " '19시': 88,\n",
       " '절대': 89,\n",
       " '하수': 90,\n",
       " '기를': 91,\n",
       " '떨어졌을': 92,\n",
       " '건너편': 93,\n",
       " '소모': 94,\n",
       " '에서의': 95,\n",
       " '균형': 96,\n",
       " '산사태': 97,\n",
       " '발가락': 98,\n",
       " '3분': 99,\n",
       " '감': 100,\n",
       " '기어': 101,\n",
       " '빠진': 102,\n",
       " '충남': 103,\n",
       " '1일': 104,\n",
       " '옮긴다': 105,\n",
       " '진입': 106,\n",
       " '뱃전': 107,\n",
       " '너무': 108,\n",
       " '하기': 109,\n",
       " '할수록': 110,\n",
       " '조': 111,\n",
       " '도청': 112,\n",
       " '했으니': 113,\n",
       " '이후': 114,\n",
       " '강원도': 115,\n",
       " '잡거나': 116,\n",
       " '헐겁게': 117,\n",
       " '사고': 118,\n",
       " '04월': 119,\n",
       " '크게': 120,\n",
       " '벗기': 121,\n",
       " '통제': 122,\n",
       " '안전': 123,\n",
       " '물': 124,\n",
       " '8시': 125,\n",
       " '이동': 126,\n",
       " '준수': 127,\n",
       " '50': 128,\n",
       " '서울특별시': 129,\n",
       " '번': 130,\n",
       " '새우등': 131,\n",
       " '튜브': 132,\n",
       " '는': 133,\n",
       " '가기': 134,\n",
       " '맞는': 135,\n",
       " '20시': 136,\n",
       " '지켜야': 137,\n",
       " '계곡': 138,\n",
       " '남도': 139,\n",
       " '천둥소리': 140,\n",
       " '하여': 141,\n",
       " '안양시': 142,\n",
       " '갯벌': 143,\n",
       " '머물고': 144,\n",
       " '독산': 145,\n",
       " '하며': 146,\n",
       " '30분': 147,\n",
       " '에서도': 148,\n",
       " '위험할': 149,\n",
       " '아닌': 150,\n",
       " '장비': 151,\n",
       " '하면': 152,\n",
       " '짚는다': 153,\n",
       " '배수구나': 154,\n",
       " '각종': 155,\n",
       " '보행기': 156,\n",
       " '나간다는': 157,\n",
       " '능력': 158,\n",
       " '24일': 159,\n",
       " '이내': 160,\n",
       " '되': 161,\n",
       " '산행': 162,\n",
       " '경주시': 163,\n",
       " '있으므로': 164,\n",
       " '피하': 165,\n",
       " '잃었을': 166,\n",
       " '울산': 167,\n",
       " '버둥대지': 168,\n",
       " '나온다': 169,\n",
       " '포항시': 170,\n",
       " '반드시': 171,\n",
       " '밭': 172,\n",
       " '전라남도청': 173,\n",
       " '피해': 174,\n",
       " '해야': 175,\n",
       " '충청남도청': 176,\n",
       " '이상': 177,\n",
       " '마니산': 178,\n",
       " '29일': 179,\n",
       " '반대': 180,\n",
       " '배안에서': 181,\n",
       " '작업': 182,\n",
       " '양구군': 183,\n",
       " '머리': 184,\n",
       " '지기': 185,\n",
       " '부천시': 186,\n",
       " '쉬운': 187,\n",
       " '안개': 188,\n",
       " '참기보다': 189,\n",
       " '부터': 190,\n",
       " '높은': 191,\n",
       " '흔적': 192,\n",
       " '낙뢰': 193,\n",
       " '즉시': 194,\n",
       " '입': 195,\n",
       " '골프': 196,\n",
       " '호흡': 197,\n",
       " '울리면': 198,\n",
       " '가볍게': 199,\n",
       " '동부': 200,\n",
       " '떨어지는': 201,\n",
       " '4': 202,\n",
       " '육상': 203,\n",
       " '28일': 204,\n",
       " '않아야': 205,\n",
       " '되는': 206,\n",
       " '충북': 207,\n",
       " '10': 208,\n",
       " '수심': 209,\n",
       " '밀양시': 210,\n",
       " '피로한': 211,\n",
       " '각': 212,\n",
       " '안전교육': 213,\n",
       " '가운데': 214,\n",
       " '전주시': 215,\n",
       " '등산로': 216,\n",
       " '나오시기': 217,\n",
       " '표류': 218,\n",
       " '긴급': 219,\n",
       " '하였으니': 220,\n",
       " '관악산': 221,\n",
       " '이다': 222,\n",
       " '잠시': 223,\n",
       " '들': 224,\n",
       " '13시': 225,\n",
       " '규모': 226,\n",
       " '광양시': 227,\n",
       " '안전한': 228,\n",
       " '실종': 229,\n",
       " '양평군': 230,\n",
       " '센': 231,\n",
       " '상류': 232,\n",
       " '결': 233,\n",
       " '나오면': 234,\n",
       " '풀': 235,\n",
       " '22분': 236,\n",
       " '용골': 237,\n",
       " '용산구': 238,\n",
       " '자리': 239,\n",
       " '낄': 240,\n",
       " '수분': 241,\n",
       " '곳': 242,\n",
       " '되도록': 243,\n",
       " '헤엄': 244,\n",
       " '위쪽': 245,\n",
       " '7일': 246,\n",
       " '문': 247,\n",
       " '평창': 248,\n",
       " '에는': 249,\n",
       " '엎드려': 250,\n",
       " '전': 251,\n",
       " '대처': 252,\n",
       " '힐': 253,\n",
       " '부산광역시': 254,\n",
       " '완도': 255,\n",
       " '제품': 256,\n",
       " '33분': 257,\n",
       " '침수': 258,\n",
       " '판단': 259,\n",
       " '맑은': 260,\n",
       " '빨리': 261,\n",
       " '않도록': 262,\n",
       " '겨': 263,\n",
       " '낙석': 264,\n",
       " '피로': 265,\n",
       " '53': 266,\n",
       " '8월': 267,\n",
       " '차오르기': 268,\n",
       " '바다': 269,\n",
       " '빠졌을': 270,\n",
       " '두': 271,\n",
       " '북구': 272,\n",
       " '10월': 273,\n",
       " '아래': 274,\n",
       " '22일': 275,\n",
       " '위로': 276,\n",
       " '경남': 277,\n",
       " '나오고': 278,\n",
       " '33': 279,\n",
       " '침착하게': 280,\n",
       " '돌아': 281,\n",
       " '일찍': 282,\n",
       " '평택시': 283,\n",
       " '우산': 284,\n",
       " '흐르는': 285,\n",
       " '에도': 286,\n",
       " '승선': 287,\n",
       " '기다린': 288,\n",
       " '권': 289,\n",
       " '6일': 290,\n",
       " '또': 291,\n",
       " '께서는': 292,\n",
       " '로': 293,\n",
       " '고': 294,\n",
       " '10일': 295,\n",
       " '18시': 296,\n",
       " '오인': 297,\n",
       " '55분': 298,\n",
       " '서서히': 299,\n",
       " '4시': 300,\n",
       " '모양': 301,\n",
       " '안동': 302,\n",
       " '북북서': 303,\n",
       " '입니다': 304,\n",
       " '상주시': 305,\n",
       " '26': 306,\n",
       " '중랑구': 307,\n",
       " '마시기': 308,\n",
       " '전북': 309,\n",
       " '방식': 310,\n",
       " '임실': 311,\n",
       " '주어': 312,\n",
       " '부산': 313,\n",
       " '하였을': 314,\n",
       " '고성군': 315,\n",
       " '터': 316,\n",
       " '덮': 317,\n",
       " '붙잡아야': 318,\n",
       " '다리': 319,\n",
       " '물체': 320,\n",
       " '노약': 321,\n",
       " '자체': 322,\n",
       " '에서만': 323,\n",
       " '이천시': 324,\n",
       " '12': 325,\n",
       " '횡성': 326,\n",
       " '범위': 327,\n",
       " '시흥시': 328,\n",
       " '숨': 329,\n",
       " '적응력': 330,\n",
       " '길': 331,\n",
       " '보장': 332,\n",
       " '파주': 333,\n",
       " '중심': 334,\n",
       " '300': 335,\n",
       " '비스듬히': 336,\n",
       " '지역': 337,\n",
       " '광주시': 338,\n",
       " '소홀': 339,\n",
       " '건강': 340,\n",
       " '이오니': 341,\n",
       " '움푹': 342,\n",
       " '잡히면': 343,\n",
       " '급류': 344,\n",
       " '22': 345,\n",
       " '움직입니다': 346,\n",
       " '북한': 347,\n",
       " '경보': 348,\n",
       " '있어야': 349,\n",
       " '도': 350,\n",
       " '챙기고': 351,\n",
       " '달서구': 352,\n",
       " '들어가': 353,\n",
       " '30일': 354,\n",
       " '있으니': 355,\n",
       " '25': 356,\n",
       " '쉼': 357,\n",
       " '화성시': 358,\n",
       " '잠길': 359,\n",
       " '올라와': 360,\n",
       " '외부': 361,\n",
       " '사전': 362,\n",
       " '250': 363,\n",
       " '지점': 364,\n",
       " '하루': 365,\n",
       " '대놓고': 366,\n",
       " '다': 367,\n",
       " '특별자치도': 368,\n",
       " '은평구': 369,\n",
       " '추락': 370,\n",
       " '부여군': 371,\n",
       " '계속': 372,\n",
       " '27일': 373,\n",
       " '오히려': 374,\n",
       " '측면': 375,\n",
       " '14시': 376,\n",
       " '주위': 377,\n",
       " '화': 378,\n",
       " '신은': 379,\n",
       " '또한': 380,\n",
       " '강진군': 381,\n",
       " '54': 382,\n",
       " '얕은': 383,\n",
       " '인': 384,\n",
       " '조용히': 385,\n",
       " '3월': 386,\n",
       " '로부터': 387,\n",
       " '가급적': 388,\n",
       " '안': 389,\n",
       " '있으면': 390,\n",
       " '충분히': 391,\n",
       " '들어갈': 392,\n",
       " '대구시': 393,\n",
       " '면': 394,\n",
       " '라고': 395,\n",
       " '있다는': 396,\n",
       " '청취': 397,\n",
       " '를': 398,\n",
       " '넘어가지': 399,\n",
       " '의': 400,\n",
       " '씹거나': 401,\n",
       " '연천군': 402,\n",
       " '행정안전부': 403,\n",
       " '12월': 404,\n",
       " '있는': 405,\n",
       " '거슬러': 406,\n",
       " '이고': 407,\n",
       " '출입': 408,\n",
       " '내': 409,\n",
       " '은': 410,\n",
       " '단': 411,\n",
       " '다음': 412,\n",
       " '운악산': 413,\n",
       " '부드럽게': 414,\n",
       " '논': 415,\n",
       " '발': 416,\n",
       " '8': 417,\n",
       " '영월': 418,\n",
       " '임실군': 419,\n",
       " '9월': 420,\n",
       " '119': 421,\n",
       " '10시': 422,\n",
       " '중앙': 423,\n",
       " '대퇴': 424,\n",
       " '21일': 425,\n",
       " '기분': 426,\n",
       " '설치': 427,\n",
       " '광역': 428,\n",
       " '동쪽': 429,\n",
       " '자연히': 430,\n",
       " '특별자치시': 431,\n",
       " '배': 432,\n",
       " '잘': 433,\n",
       " '휩싸였을': 434,\n",
       " '즉각': 435,\n",
       " '한': 436,\n",
       " '잘못': 437,\n",
       " '불어': 438,\n",
       " '이어질': 439,\n",
       " '재난': 440,\n",
       " '동작구': 441,\n",
       " '친': 442,\n",
       " '축령산': 443,\n",
       " '8시간': 444,\n",
       " '광진구': 445,\n",
       " '유아': 446,\n",
       " '자동차': 447,\n",
       " '남쪽': 448,\n",
       " '시': 449,\n",
       " '되니': 450,\n",
       " '수상': 451,\n",
       " '수': 452,\n",
       " '화상': 453,\n",
       " '살펴보고': 454,\n",
       " '긴': 455,\n",
       " '성동구': 456,\n",
       " '난': 457,\n",
       " '일부': 458,\n",
       " '강남구': 459,\n",
       " '자세': 460,\n",
       " '확보': 461,\n",
       " '자주': 462,\n",
       " '보호': 463,\n",
       " '서귀포시': 464,\n",
       " '강원': 465,\n",
       " '창': 466,\n",
       " '시선': 467,\n",
       " '하시고': 468,\n",
       " '마기': 469,\n",
       " '주': 470,\n",
       " '00시': 471,\n",
       " '과식': 472,\n",
       " '심호흡': 473,\n",
       " '둑': 474,\n",
       " '산': 475,\n",
       " '썬크림': 476,\n",
       " '106': 477,\n",
       " '달': 478,\n",
       " '섭취': 479,\n",
       " '꼭': 480,\n",
       " '감악산': 481,\n",
       " '전역': 482,\n",
       " '북북동': 483,\n",
       " '울진군': 484,\n",
       " '서구': 485,\n",
       " '거리': 486,\n",
       " '낮은': 487,\n",
       " '제주도': 488,\n",
       " '열대야': 489,\n",
       " '소요산': 490,\n",
       " '대항': 491,\n",
       " '특히': 492,\n",
       " '조난': 493,\n",
       " '합니다': 494,\n",
       " '신속히': 495,\n",
       " '보다': 496,\n",
       " '벽': 497,\n",
       " '3': 498,\n",
       " '포항': 499,\n",
       " '도봉산': 500,\n",
       " '마신': 501,\n",
       " '무안': 502,\n",
       " '하지': 503,\n",
       " '시민': 504,\n",
       " '경북': 505,\n",
       " '유명산': 506,\n",
       " '충청북도청': 507,\n",
       " '탈수': 508,\n",
       " '있어': 509,\n",
       " '중구': 510,\n",
       " '등산': 511,\n",
       " '동구': 512,\n",
       " '폭우': 513,\n",
       " '한꺼': 514,\n",
       " '관악구': 515,\n",
       " '아이': 516,\n",
       " '전해': 517,\n",
       " '상': 518,\n",
       " '일반': 519,\n",
       " '뜨기': 520,\n",
       " '이어야': 521,\n",
       " '동': 522,\n",
       " '9분': 523,\n",
       " '재면서': 524,\n",
       " '안전하다': 525,\n",
       " '주의보': 526,\n",
       " '북부': 527,\n",
       " '없는': 528,\n",
       " '발라': 529,\n",
       " '가지': 530,\n",
       " '번개': 531,\n",
       " '가평군': 532,\n",
       " '양': 533,\n",
       " '해역': 534,\n",
       " '고립': 535,\n",
       " '충분한': 536,\n",
       " '현재': 537,\n",
       " '익산시': 538,\n",
       " '약한': 539,\n",
       " '위험': 540,\n",
       " '체험': 541,\n",
       " '군포시': 542,\n",
       " '향': 543,\n",
       " '구급': 544,\n",
       " '적': 545,\n",
       " '유지': 546,\n",
       " '남양주시': 547,\n",
       " '체력': 548,\n",
       " '신호': 549,\n",
       " '11시': 550,\n",
       " '고흥': 551,\n",
       " '할': 552,\n",
       " '물건': 553,\n",
       " '에서': 554,\n",
       " '안성시': 555,\n",
       " '양주시': 556,\n",
       " '직각': 557,\n",
       " '심한': 558,\n",
       " '특보': 559,\n",
       " '휘감': 560,\n",
       " '안정': 561,\n",
       " '모든': 562,\n",
       " '넘실': 563,\n",
       " '목포시': 564,\n",
       " '났을': 565,\n",
       " '준비': 566,\n",
       " '갑자기': 567,\n",
       " '기다리면': 568,\n",
       " '가라앉기': 569,\n",
       " '낮춘': 570,\n",
       " '땐': 571,\n",
       " '차거나': 572,\n",
       " '와': 573,\n",
       " '지속': 574,\n",
       " '빠지는': 575,\n",
       " '천마산': 576,\n",
       " '2시': 577,\n",
       " '팔': 578,\n",
       " '부주의': 579,\n",
       " '경련': 580,\n",
       " '충청남도': 581,\n",
       " '폭염': 582,\n",
       " '일이': 583,\n",
       " '전라북도': 584,\n",
       " '16시': 585,\n",
       " '낚시': 586,\n",
       " '영양군': 587,\n",
       " '내릴': 588,\n",
       " '취한': 589,\n",
       " '및': 590,\n",
       " '채': 591,\n",
       " '전남': 592,\n",
       " '떨어뜨리고': 593,\n",
       " '흘러간': 594,\n",
       " '전속력': 595,\n",
       " '말고': 596,\n",
       " '하는': 597,\n",
       " '순환': 598,\n",
       " '광주': 599,\n",
       " '쳐': 600,\n",
       " '자신': 601,\n",
       " '위': 602,\n",
       " '또는': 603,\n",
       " '버리듯이': 604,\n",
       " '보트': 605,\n",
       " '많이': 606,\n",
       " '혹은': 607,\n",
       " '진주시': 608,\n",
       " '하': 609,\n",
       " '떨어진': 610,\n",
       " '무게': 611,\n",
       " '스스로': 612,\n",
       " '반경': 613,\n",
       " '만약': 614,\n",
       " '안내': 615,\n",
       " '한낮': 616,\n",
       " '긴장': 617,\n",
       " '능선': 618,\n",
       " '놓여': 619,\n",
       " '받는다': 620,\n",
       " '수영': 621,\n",
       " '관리': 622,\n",
       " '가정': 623,\n",
       " '어른': 624,\n",
       " '행': 625,\n",
       " '대전': 626,\n",
       " '56분': 627,\n",
       " '스틱': 628,\n",
       " '기': 629,\n",
       " '빠져': 630,\n",
       " '않으려고': 631,\n",
       " '의정부시': 632,\n",
       " '강서구': 633,\n",
       " '마지막': 634,\n",
       " '17시': 635,\n",
       " '일': 636,\n",
       " '예상': 637,\n",
       " '꾸준히': 638,\n",
       " '시킨': 639,\n",
       " '시기': 640,\n",
       " '나오기': 641,\n",
       " '9시': 642,\n",
       " '맨발': 643,\n",
       " '잡고': 644,\n",
       " '넓은': 645,\n",
       " '해안가': 646,\n",
       " '과천시': 647,\n",
       " '유물': 648,\n",
       " '신고': 649,\n",
       " '적게': 650,\n",
       " '므': 651,\n",
       " '끼우는': 652,\n",
       " '동안': 653,\n",
       " '차례': 654,\n",
       " '이용': 655,\n",
       " '소매': 656,\n",
       " '47분': 657,\n",
       " '으로부터': 658,\n",
       " '안심': 659,\n",
       " '구청': 660,\n",
       " '신체': 661,\n",
       " '여진': 662,\n",
       " '씩': 663,\n",
       " '위치': 664,\n",
       " '4일': 665,\n",
       " '부': 666,\n",
       " '시켜': 667,\n",
       " '강북구': 668,\n",
       " '마시는': 669,\n",
       " '눌려': 670,\n",
       " '혼자': 671,\n",
       " '대피': 672,\n",
       " '130': 673,\n",
       " '만': 674,\n",
       " '방법': 675,\n",
       " '음식물': 676,\n",
       " '부위': 677,\n",
       " '느낀다': 678,\n",
       " '나오며': 679,\n",
       " '해': 680,\n",
       " '사천시': 681,\n",
       " '포천시': 682,\n",
       " '손가락': 683,\n",
       " '물속': 684,\n",
       " '고양시': 685,\n",
       " '요청': 686,\n",
       " '양천구': 687,\n",
       " '색': 688,\n",
       " '연흔': 689,\n",
       " '명지산': 690,\n",
       " '잠깐': 691,\n",
       " '2일': 692,\n",
       " '대구': 693,\n",
       " '익사': 694,\n",
       " '이하': 695,\n",
       " '심해야': 696,\n",
       " '벗어나려는': 697,\n",
       " '야외': 698,\n",
       " '춘천시': 699,\n",
       " '정읍시': 700,\n",
       " '넓어지는': 701,\n",
       " '일어나기': 702,\n",
       " '2': 703,\n",
       " '멀리': 704,\n",
       " '쓰고': 705,\n",
       " '어민': 706,\n",
       " '41분': 707,\n",
       " '보성군': 708,\n",
       " '장난': 709,\n",
       " '유의사항': 710,\n",
       " '하였습니다': 711,\n",
       " '기준': 712,\n",
       " '하류': 713,\n",
       " '하남시': 714,\n",
       " '발표': 715,\n",
       " '물결': 716,\n",
       " '2월': 717,\n",
       " '내뱉으면': 718,\n",
       " '1': 719,\n",
       " '동남쪽': 720,\n",
       " '남서쪽': 721,\n",
       " '흐름': 722,\n",
       " '평영': 723,\n",
       " '경기도': 724,\n",
       " '도움': 725,\n",
       " '주민': 726,\n",
       " '송파구': 727,\n",
       " '같이': 728,\n",
       " '천천히': 729,\n",
       " '정도': 730,\n",
       " '15시': 731,\n",
       " '물살': 732,\n",
       " '파악': 733,\n",
       " '것': 734,\n",
       " '보은군': 735,\n",
       " '보령시': 736,\n",
       " '1월': 737,\n",
       " '먹는': 738,\n",
       " '물놀이': 739,\n",
       " '미리': 740,\n",
       " '0': 741,\n",
       " '되오니': 742,\n",
       " '들었다고': 743,\n",
       " '밀지': 744,\n",
       " '있다': 745,\n",
       " '행동': 746,\n",
       " '풀어야': 747,\n",
       " '태안군': 748,\n",
       " '밑': 749,\n",
       " '잠수': 750,\n",
       " '보이므로': 751,\n",
       " '경상남도': 752,\n",
       " '조류': 753,\n",
       " '대전광역시': 754,\n",
       " '마음': 755,\n",
       " '과는': 756,\n",
       " '등': 757,\n",
       " '증': 758,\n",
       " '화염': 759,\n",
       " '일행': 760,\n",
       " '외출': 761,\n",
       " '상처': 762,\n",
       " '쪽': 763,\n",
       " '기온': 764,\n",
       " '깊이': 765,\n",
       " '발버둥': 766,\n",
       " '광명시': 767,\n",
       " '부지역': 768,\n",
       " '예방': 769,\n",
       " '의해': 770,\n",
       " '아침': 771,\n",
       " '큰': 772,\n",
       " '해서는': 773,\n",
       " '칙': 774,\n",
       " '끌듯이': 775,\n",
       " '맞': 776,\n",
       " '약': 777,\n",
       " '돌이': 778,\n",
       " '부서지는': 779,\n",
       " '있으며': 780,\n",
       " '경산': 781,\n",
       " '수직': 782,\n",
       " '3일': 783,\n",
       " '수도': 784,\n",
       " '57분': 785,\n",
       " '보시': 786,\n",
       " '빠질': 787,\n",
       " '홍천군': 788,\n",
       " '이러한': 789,\n",
       " '동해': 790,\n",
       " '가': 791,\n",
       " '수난': 792,\n",
       " '더': 793,\n",
       " '아산시': 794,\n",
       " '편안한': 795,\n",
       " '작업장': 796,\n",
       " '여러': 797,\n",
       " '연일': 798,\n",
       " '강동구': 799,\n",
       " '9일': 800,\n",
       " '될': 801,\n",
       " '군': 802,\n",
       " '방심하게': 803,\n",
       " '11월': 804,\n",
       " '패각': 805,\n",
       " '명': 806,\n",
       " '넘어오지': 807,\n",
       " '수성구': 808,\n",
       " '알맞은': 809,\n",
       " '사용': 810,\n",
       " '예정': 811,\n",
       " '남동쪽': 812,\n",
       " '상태': 813,\n",
       " '않는다': 814,\n",
       " '나오지': 815,\n",
       " '감긴': 816,\n",
       " '하시기': 817,\n",
       " '북쪽': 818,\n",
       " '양양군': 819,\n",
       " '비상식량': 820,\n",
       " 'TV': 821,\n",
       " '음주': 822,\n",
       " '장화': 823,\n",
       " '움직여': 824,\n",
       " '낮': 825,\n",
       " '에': 826,\n",
       " '30초': 827,\n",
       " '12일': 828,\n",
       " '솟구쳐': 829,\n",
       " '올려놓는다': 830,\n",
       " '떠': 831,\n",
       " '동해시': 832,\n",
       " '17': 833,\n",
       " '15분': 834,\n",
       " '쉽고': 835,\n",
       " '어린이': 836,\n",
       " '선택': 837,\n",
       " '쉽다': 838,\n",
       " '보살핍시다': 839,\n",
       " '주의': 840,\n",
       " '수원시': 841,\n",
       " '껌': 842,\n",
       " '발효': 843,\n",
       " '나란히': 844,\n",
       " '구두': 845,\n",
       " '약간': 846,\n",
       " '지진': 847,\n",
       " '떨어져': 848,\n",
       " '52': 849,\n",
       " '중': 850,\n",
       " '있습니다': 851,\n",
       " '서초구': 852,\n",
       " '위급한': 853,\n",
       " '많으니': 854,\n",
       " '뒷발': 855,\n",
       " '수칙': 856,\n",
       " '나갔을': 857,\n",
       " '예': 858,\n",
       " '침몰': 859,\n",
       " '선미': 860,\n",
       " '후': 861,\n",
       " '평지': 862,\n",
       " '의왕시': 863,\n",
       " '지팡이': 864,\n",
       " '13': 865,\n",
       " '절대로': 866,\n",
       " '인천광역시': 867,\n",
       " '플러그': 868,\n",
       " '뻗어': 869,\n",
       " '적도록': 870,\n",
       " '선정': 871,\n",
       " '양말': 872,\n",
       " '중일': 873,\n",
       " '서대문구': 874,\n",
       " '동두천시': 875,\n",
       " '거': 876,\n",
       " '세종시': 877,\n",
       " '요령': 878,\n",
       " '감독': 879,\n",
       " '나무': 880,\n",
       " '가장': 881,\n",
       " '6시': 882,\n",
       " '바라보고': 883,\n",
       " '유의': 884,\n",
       " '하고': 885,\n",
       " '해주시기': 886,\n",
       " '9': 887,\n",
       " '휴대': 888,\n",
       " '그': 889,\n",
       " '되므로': 890,\n",
       " '방송': 891,\n",
       " '얕다': 892,\n",
       " '우려': 893,\n",
       " '대': 894,\n",
       " '노원구': 895,\n",
       " '수초': 896,\n",
       " '제주': 897,\n",
       " '위해': 898,\n",
       " '구명조끼': 899,\n",
       " '발생': 900,\n",
       " '수면': 901,\n",
       " '탈': 902,\n",
       " '방한': 903,\n",
       " '먹지': 904,\n",
       " '해남군': 905,\n",
       " '되면': 906,\n",
       " '평창군': 907,\n",
       " '을': 908,\n",
       " '강화군': 909,\n",
       " '구조': 910,\n",
       " '구': 911,\n",
       " '되고': 912,\n",
       " '마포구': 913,\n",
       " '최고': 914,\n",
       " '5시': 915,\n",
       " '5': 916,\n",
       " '객': 917,\n",
       " '7': 918,\n",
       " '관련': 919,\n",
       " '도봉구': 920,\n",
       " '하세요': 921,\n",
       " '몸': 922,\n",
       " '서서': 923,\n",
       " '경향': 924,\n",
       " '상체': 925,\n",
       " '경사진': 926,\n",
       " '밀물': 927,\n",
       " '수온': 928,\n",
       " '건널': 929,\n",
       " '야영지': 930,\n",
       " '40분': 931,\n",
       " '때문': 932,\n",
       " '상황': 933,\n",
       " '얕다고': 934,\n",
       " '파인': 935,\n",
       " '지하': 936,\n",
       " '다른': 937,\n",
       " '일어날': 938,\n",
       " '어제': 939,\n",
       " '지키기': 940,\n",
       " '시키고': 941,\n",
       " '초보자': 942,\n",
       " '맞게': 943,\n",
       " '밀려': 944,\n",
       " '간다': 945,\n",
       " '오늘': 946,\n",
       " '항시': 947,\n",
       " '자제': 948,\n",
       " '손': 949,\n",
       " '경우': 950,\n",
       " '북서쪽': 951,\n",
       " '지켜주세요': 952,\n",
       " '11': 953,\n",
       " 'km': 954,\n",
       " '원주': 955,\n",
       " '착용': 956,\n",
       " '과': 957,\n",
       " '준비운동': 958,\n",
       " '강': 959,\n",
       " '장소': 960,\n",
       " '제': 961,\n",
       " '중지': 962,\n",
       " '밧줄': 963,\n",
       " '인지': 964,\n",
       " '에서는': 965,\n",
       " '편안할': 966,\n",
       " '셀': 967,\n",
       " '대비': 968,\n",
       " '칠': 969,\n",
       " '모자': 970,\n",
       " '지대': 971,\n",
       " '주변': 972,\n",
       " '키': 973,\n",
       " '송파': 974,\n",
       " '피로할': 975,\n",
       " '오리': 976,\n",
       " '14분': 977,\n",
       " '천둥': 978,\n",
       " '하얀': 979,\n",
       " '흔히': 980,\n",
       " '가능하다면': 981,\n",
       " '같은': 982,\n",
       " '만조': 983,\n",
       " '무더위': 984,\n",
       " '29분': 985,\n",
       " '언제나': 986,\n",
       " '03': 987,\n",
       " '차단': 988,\n",
       " '연수구': 989,\n",
       " '적응': 990,\n",
       " '시간': 991,\n",
       " '건너야': 992,\n",
       " '부력': 993,\n",
       " '6': 994,\n",
       " '함안군': 995,\n",
       " '23일': 996,\n",
       " '18일': 997,\n",
       " '삼가하기': 998,\n",
       " '하기에': 999,\n",
       " ...}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_to_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "12ee01b8-6d29-4b13-b1fc-684fb706a921",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1078"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#len(word_to_index) : 저장된 단어의 개수\n",
    "len(word_to_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1e30c461-232d-40ec-8e66-02aec411d25f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "device: cuda:0\n"
     ]
    }
   ],
   "source": [
    "HID_DIM = 512\n",
    "OUTPUT_DIM = len(word_to_index)\n",
    "N_LAYER = 2 \n",
    "DEC_DROPOUT = 0.5\n",
    "EMB_DIM = 128\n",
    "BATCH_SIZE = 32\n",
    "N_EPOCH = 1000\n",
    "CLIP = 1\n",
    "learning_rate = 0.0001\n",
    "model_save_path = 'data/'\n",
    "save_model_name = 'model1.pt'\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "print('device:', device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "774b4986-0ce6-49fe-b057-07a90f15cff4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#np.load('data/X_data.npy') : keypoint가 저장죈 X_data.npy 읽어서 리턴\n",
    "X_data = np.load('data/X_data.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3d4550bc-f19a-450c-8147-b652180732ac",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(352, 240, 134)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "afb4744f-8ce1-4109-a1a5-6cfe25dedd0f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[ 0.33139095, -1.2248869 ,  0.31375602, ...,  0.59203297,\n",
       "         -0.07408668,  0.59665173],\n",
       "        [ 0.33017254, -1.2249231 ,  0.31251508, ...,  0.593432  ,\n",
       "         -0.07786492,  0.5957069 ],\n",
       "        [ 0.32986647, -1.2254999 ,  0.3121397 , ...,  0.5932884 ,\n",
       "         -0.07602021,  0.5910137 ],\n",
       "        ...,\n",
       "        [ 0.34666264, -1.2243315 ,  0.32900348, ...,  0.57456756,\n",
       "         -0.10940002,  0.5609939 ],\n",
       "        [ 0.34107053, -1.224629  ,  0.3319686 , ...,  0.5701985 ,\n",
       "         -0.10562919,  0.5633026 ],\n",
       "        [ 0.34480435, -1.2247169 ,  0.33569857, ...,  0.567693  ,\n",
       "         -0.10210186,  0.5561903 ]],\n",
       "\n",
       "       [[ 0.33823052, -1.2373524 ,  0.3206036 , ...,  0.5847284 ,\n",
       "         -0.07379816,  0.5847284 ],\n",
       "        [ 0.33649135, -1.2290341 ,  0.3270037 , ...,  0.58165026,\n",
       "         -0.0718272 ,  0.59097505],\n",
       "        [ 0.34267113, -1.2379397 ,  0.32487038, ...,  0.5861447 ,\n",
       "         -0.07286945,  0.5861447 ],\n",
       "        ...,\n",
       "        [ 0.3576922 , -1.2186489 ,  0.31385562, ...,  0.5698339 ,\n",
       "         -0.09950402,  0.5607598 ],\n",
       "        [ 0.3581048 , -1.2186656 ,  0.3143381 , ...,  0.5694905 ,\n",
       "         -0.09917144,  0.56042075],\n",
       "        [ 0.3581528 , -1.2183939 ,  0.31443158, ...,  0.572455  ,\n",
       "         -0.09901096,  0.56111884]],\n",
       "\n",
       "       [[ 0.34037605, -1.2217554 ,  0.33123878, ...,  0.5833393 ,\n",
       "         -0.0606241 ,  0.57869035],\n",
       "        [ 0.33993724, -1.2214026 ,  0.33082578, ...,  0.5804161 ,\n",
       "         -0.05492372,  0.5849904 ],\n",
       "        [ 0.33826268, -1.2213739 ,  0.32922912, ...,  0.5819942 ,\n",
       "         -0.05630549,  0.58886427],\n",
       "        ...,\n",
       "        [ 0.36416635, -1.2005727 ,  0.32913753, ...,  0.549967  ,\n",
       "         -0.09173033,  0.54118085],\n",
       "        [ 0.35638782, -1.2011069 ,  0.3298942 , ...,  0.5484528 ,\n",
       "         -0.09118733,  0.53981465],\n",
       "        [ 0.35757446, -1.2010229 ,  0.3312037 , ...,  0.5474697 ,\n",
       "         -0.09014776,  0.5386836 ]]], dtype=float32)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_data[0:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ab2ff0ac-bcd9-4b52-a7ef-90582065a9e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#np.load('data/y_data.npy) : 수어 스크립트가 저장된 y_data.npy 읽어서 리턴\n",
    "y_data = np.load('data/y_data.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "4d473fe7-830f-46dc-a4b3-120993c2eb1f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  1, 103, 736, 720, 202, 954, 337, 226, 498, 916, 847, 900, 662,\n",
       "        757, 123, 826, 840,  85,   2,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0],\n",
       "       [  1, 505, 305, 818, 916, 954, 337, 226, 202, 498, 847, 900, 662,\n",
       "        757, 123, 826, 840,  85,   2,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0],\n",
       "       [  1, 484, 448, 994, 954, 337, 226, 498, 498, 847, 900, 662, 757,\n",
       "        123, 826, 840,  85,   2,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0]])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_data[0:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "6a4e7559-2f54-4a81-8291-ea19d39026ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_data = torch.tensor(y_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "0370117e-7d4c-46b1-8b9d-212fce17b27e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([352, 30])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "57354378-f39d-4531-b2fe-a730934872bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_data = torch.tensor(X_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "f6bbf5fe-fa1c-4553-9569-a59706514eb6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([352, 240, 134])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "77f091f8-a63d-452f-9d48-6d4e3909d5dc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch.utils.data.dataset.TensorDataset at 0x15cc63f5780>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#D.TensorDataset(X_data,y_data): X_data와 y_data를 리턴할 객체 생성\n",
    "train_dataset = D.TensorDataset(X_data, y_data)\n",
    "train_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "0deac416-a27e-4652-93e8-ad5c4656d64d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#torch.utils.data.DataLoader( \n",
    "#                            train_dataset\n",
    "#                            , batch_size=16 : 학습시 16행씩 리턴\n",
    "#                            , shuffle=True : X_data 와 y_data의 행을 섞음\n",
    "#                            , drop_last=False : 마지막 데이터의 행이 16개 미만일때도 학습 진행\n",
    "#                            )\n",
    "# : 학습시 X_data 와 y_data 를 리턴하는 객체 생성\n",
    "train_dataloader = torch.utils.data.DataLoader(train_dataset, batch_size=16, shuffle=True, drop_last=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "cf90c826-6af9-44bb-b06f-9f2d6c0373bc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch.utils.data.dataloader.DataLoader at 0x15cc63f58a0>"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "5c0dd529-bb59-4d4d-a2a1-db9597c3683c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "index= 0\n",
      "inp= torch.Size([16, 240, 134])\n",
      "ta= torch.Size([16, 30])\n",
      "====================================================================================================\n"
     ]
    }
   ],
   "source": [
    "for index, (inp,ta) in enumerate(train_dataloader):\n",
    "    print(\"index=\",index)\n",
    "    print(\"inp=\",inp.shape)\n",
    "    print(\"ta=\",ta.shape)\n",
    "    print(\"=\"*100)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "e80098fa-09d4-49d3-bb4e-ba954b0a497f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[ 0.3314, -1.2249,  0.3138,  ...,  0.5920, -0.0741,  0.5967],\n",
       "         [ 0.3302, -1.2249,  0.3125,  ...,  0.5934, -0.0779,  0.5957],\n",
       "         [ 0.3299, -1.2255,  0.3121,  ...,  0.5933, -0.0760,  0.5910],\n",
       "         ...,\n",
       "         [ 0.3467, -1.2243,  0.3290,  ...,  0.5746, -0.1094,  0.5610],\n",
       "         [ 0.3411, -1.2246,  0.3320,  ...,  0.5702, -0.1056,  0.5633],\n",
       "         [ 0.3448, -1.2247,  0.3357,  ...,  0.5677, -0.1021,  0.5562]]])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#입력데이터\n",
    "#정지화면 1개당 134개의 키포인트가 존재\n",
    "#240개의 정지 화면으로 구성\n",
    "X_data[0:1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "577f4016-ec4e-48fe-b10a-efb6ca9bd6dd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 240, 134])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_data[0:1].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "e2c4e208-a838-4885-8df5-1cc7521ab27f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#X_data.shape[2] : X_data의 열의 개수 리턴\n",
    "input_size = X_data.shape[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "0c39a994-9ca8-49c3-b394-1be2116fd51f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "134"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "69e399c1-dfd1-4c00-933a-46145cef3667",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#X_data.shape[2] : X_data의 데이터의 수를 리턴\n",
    "x_row = X_data[0:1].shape[0]\n",
    "x_row"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "9c70079e-ad63-4e22-9463-2734d76c172a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#N_LAYER =2\n",
    "#HID_DIM = 512\n",
    "#n_row = 1\n",
    "\n",
    "#torch.zeros(shape) : 0으로 초기화된 배열 생성\n",
    "#torch.zeros(N_LAYER *2, x_row, HID_DIM) : [4,1,512] shape 0으로 초기화된 3차원 배열 생성\n",
    "\n",
    "#cuda() : GPU에 배열 저장\n",
    "\n",
    "#float() : 배열 타입을 실수로 설정\n",
    "h0 = torch.zeros(N_LAYER *2, x_row, HID_DIM).cuda().float()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "80cb9132-6272-471d-b822-7a7b5e44a316",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[0., 0., 0.,  ..., 0., 0., 0.]],\n",
       "\n",
       "        [[0., 0., 0.,  ..., 0., 0., 0.]],\n",
       "\n",
       "        [[0., 0., 0.,  ..., 0., 0., 0.]],\n",
       "\n",
       "        [[0., 0., 0.,  ..., 0., 0., 0.]]], device='cuda:0')"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "h0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "fc420091-9d60-4e96-9768-40438a50c2b3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([4, 1, 512])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "h0.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "0fa851aa-05e8-49e1-a196-42042a061e43",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "134"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "9bb45f46-4d24-4328-a146-13216083dd6a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "512"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "HID_DIM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "37d4fcc8-c3b8-4f5a-97b2-1a4005066bd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "gru = nn.GRU(\n",
    "    input_size, #입력되는 keypoint 1개의 개수 (134개의 keypoint가 순차적으로 입력됨\n",
    "    HID_DIM, #hidden layer의 size HID_DIM = 512\n",
    "    N_LAYER, # N_LAYER = 2 2개의 GRU가 쌓여서 실행\n",
    "    batch_first = True, #계산 결과가 [데이터수, 입력데이터행, 입력데이터열] 리턴 => [1,240,1024]\n",
    "    bidirectional = True,\n",
    "    dropout=DEC_DROPOUT #Dropout 설정\n",
    ").cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "080cf09b-b779-4d28-997f-c0fa5940829e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GRU(134, 512, num_layers=2, batch_first=True, dropout=0.5, bidirectional=True)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gru"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "d70a35b6-2138-467b-9b51-3695085831b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#GRU 연산 실행\n",
    "encoder_output, encoder_hidden = gru(X_data[0:1].cuda() , h0.cuda())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "04b9b7f3-2f84-4f29-bb3b-dbd07cf0d650",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[ 0.1505,  0.2497,  0.0811,  ..., -0.1775,  0.1487,  0.0590],\n",
       "         [ 0.1277,  0.1981,  0.3587,  ..., -0.1642,  0.1019, -0.0024],\n",
       "         [ 0.0820,  0.1381,  0.3671,  ..., -0.1341, -0.0537,  0.0109],\n",
       "         ...,\n",
       "         [-0.1311,  0.1731,  0.3574,  ..., -0.0007, -0.1417,  0.0567],\n",
       "         [-0.1756,  0.2728,  0.1529,  ...,  0.0329, -0.2524,  0.0442],\n",
       "         [-0.1394,  0.3053,  0.1561,  ..., -0.0814, -0.2073, -0.0540]]],\n",
       "       device='cuda:0', grad_fn=<CudnnRnnBackward0>)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoder_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "2ea2f436-5194-4965-8d37-28e9527cb760",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 240, 1024])"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoder_output.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "adbfc962-a179-4d54-9f3e-c92b9f099a43",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[ 0.4200, -0.5739, -0.0171,  ...,  0.4684,  0.1007, -0.4054]],\n",
       "\n",
       "        [[ 0.0485,  0.2034,  0.0958,  ..., -0.0015, -0.0476,  0.0534]],\n",
       "\n",
       "        [[-0.1394,  0.3053,  0.1561,  ...,  0.4225, -0.0656, -0.0832]],\n",
       "\n",
       "        [[-0.0410,  0.2059,  0.4497,  ..., -0.1775,  0.1487,  0.0590]]],\n",
       "       device='cuda:0', grad_fn=<CudnnRnnBackward0>)"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoder_hidden"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "3e7bd5a2-0d25-4c9a-b4b8-774e9b1fe6f4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([4, 1, 512])"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoder_hidden.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "e69b4503-945e-4a45-a5e3-f09e2a9ee3c9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([4, 1, 512])"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoder_hidden.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "12a17605-1d82-4aa3-9898-9d62c550be6b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.4200, -0.5739, -0.0171,  ..., -0.1775,  0.1487,  0.0590]],\n",
       "       device='cuda:0', grad_fn=<CatBackward0>)"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#\n",
    "# encoder_hidden[-4,:,:],\n",
    "# encoder_hidden[-3,:,:],\n",
    "# encoder_hidden[-2,:,:],\n",
    "# encoder_hidden[-1,:,:]\n",
    "#을 1개로 합쳐서 2차원 배열로 변환\n",
    "\n",
    "#dim = 1 : 배열의 1천뺴 차원에서 합침\n",
    "\n",
    "torch.cat((\n",
    "     encoder_hidden[-4,:,:],\n",
    "     encoder_hidden[-3,:,:],\n",
    "     encoder_hidden[-2,:,:],\n",
    "     encoder_hidden[-1,:,:]\n",
    "), dim = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "6d2e3daa-1cc7-4fad-b631-0e98002863e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "# encoder_hidden[-4,:,:],\n",
    "# encoder_hidden[-3,:,:],\n",
    "# encoder_hidden[-2,:,:],\n",
    "# encoder_hidden[-1,:,:]\n",
    "#을 1개로 합쳐서 2차원 배열로 변환\n",
    "\n",
    "#dim = 1 : 배열의 1천뺴 차원에서 합침\n",
    "\n",
    "encoder_hidden = torch.cat((\n",
    "     encoder_hidden[-4,:,:],\n",
    "     encoder_hidden[-3,:,:],\n",
    "     encoder_hidden[-2,:,:],\n",
    "     encoder_hidden[-1,:,:]\n",
    "), dim = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "8b319566-8ce4-45c8-93ff-fe6fb88497fe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 2048])"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoder_hidden.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "a57dc578-c249-450a-9f4d-5fb3bf4ed6f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#선형 회귀 객체 생성\n",
    "fc = nn.Linear(\n",
    "    HID_DIM * 4, #입력데이터 (encoder_hidden)의 열의 개수 HID_DIM (512)\n",
    "    HID_DIM #계상 결과 (추력데이터)의 열의 개수 HID_DIM (512)\n",
    ").cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "18cf9d50-4bca-4772-9b90-bb41f250105f",
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder_hidden = fc(encoder_hidden)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "61e6a72b-47ea-4c9c-a853-2d3411d29e6f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-2.6731e-02, -2.8492e-02, -2.2107e-02, -7.6137e-02, -1.6818e-01,\n",
       "          4.1211e-02,  1.1476e-01, -2.2332e-01, -9.6641e-02, -2.7740e-02,\n",
       "          9.9955e-02, -2.4105e-01,  4.3593e-02, -4.6121e-03, -1.9914e-01,\n",
       "          4.8469e-02,  4.3703e-02,  1.6191e-01,  7.6041e-02, -1.1429e-01,\n",
       "          4.9460e-02, -2.8985e-01,  2.1878e-01, -1.7574e-01, -7.1943e-02,\n",
       "          4.2752e-03,  1.3126e-01, -4.7563e-02, -1.6651e-01,  9.5412e-03,\n",
       "          1.3457e-01, -1.0672e-02,  3.6466e-01,  3.8801e-01,  8.3215e-02,\n",
       "         -7.3927e-02,  2.4566e-01,  5.6862e-02,  2.1404e-01, -1.0948e-01,\n",
       "         -1.6038e-01, -1.1524e-01,  2.9680e-01,  7.4328e-02,  6.4268e-02,\n",
       "          1.4260e-01, -1.0181e-01,  9.1755e-02, -1.8662e-02, -2.6620e-02,\n",
       "          1.0658e-02,  2.9316e-01,  2.1279e-02,  1.0248e-02, -3.9928e-03,\n",
       "         -3.7584e-04,  1.2952e-02,  2.6277e-01,  4.2112e-02,  2.1225e-01,\n",
       "          7.5519e-02, -7.3691e-02, -9.6566e-02, -5.2502e-02, -3.8493e-03,\n",
       "          9.0256e-03,  2.4548e-01, -2.9186e-01, -1.2433e-01, -7.5739e-02,\n",
       "         -9.0886e-02,  2.3641e-02,  2.7718e-02, -1.4396e-02, -5.5091e-02,\n",
       "          4.2882e-03, -5.8662e-02,  3.5118e-02,  5.1978e-02,  3.9253e-02,\n",
       "         -6.9589e-03,  2.6872e-01, -5.9116e-02,  1.9498e-01, -9.9411e-02,\n",
       "          1.8153e-01, -2.3129e-01,  1.1197e-02,  5.1205e-02,  7.9103e-02,\n",
       "         -1.6393e-01,  7.6223e-02,  7.9719e-02, -3.3222e-02, -6.5901e-02,\n",
       "          2.6397e-01,  6.3329e-02, -2.5164e-01,  1.0736e-01, -2.9014e-01,\n",
       "         -1.0157e-01, -1.0073e-01,  2.1614e-01, -1.0729e-01,  2.8206e-01,\n",
       "         -4.5626e-02, -1.2552e-01,  5.3573e-02,  7.0373e-02, -4.0820e-02,\n",
       "          3.7669e-01, -1.2418e-05,  2.2068e-01, -7.2190e-02,  1.5644e-02,\n",
       "          5.7581e-02, -1.4915e-01, -7.3938e-02, -2.4880e-01,  8.0369e-02,\n",
       "         -2.3083e-01,  1.3917e-01, -3.8489e-03, -9.2974e-02,  1.1870e-01,\n",
       "          1.8472e-02,  2.5804e-01,  1.0065e-01,  1.0308e-01,  1.3012e-01,\n",
       "          4.0527e-02, -4.6670e-02, -7.1639e-02, -8.5120e-02, -7.7454e-02,\n",
       "          6.6421e-02,  2.9701e-01, -2.2329e-01,  1.2013e-01, -2.8630e-01,\n",
       "          1.4057e-02, -1.8208e-01,  1.3037e-01, -1.6064e-01, -1.8313e-01,\n",
       "          1.5850e-01,  2.6433e-01,  2.4695e-01, -3.0653e-02, -4.3316e-02,\n",
       "          1.9443e-01, -6.6174e-02,  1.2360e-01,  8.3549e-02,  3.4495e-01,\n",
       "         -1.8470e-01,  7.8638e-02, -5.9674e-02,  5.7954e-02, -2.7717e-02,\n",
       "          8.6351e-02,  1.7912e-01,  1.5498e-01, -1.8781e-01, -1.1325e-01,\n",
       "         -3.2596e-02, -4.8098e-02, -1.0332e-02,  3.2361e-02, -1.3270e-01,\n",
       "         -2.3752e-01, -7.1366e-02, -1.5846e-01, -9.2057e-02, -1.2765e-01,\n",
       "          4.1164e-01, -1.8253e-01, -1.7798e-01,  7.1703e-02,  7.7320e-02,\n",
       "         -1.7180e-01, -2.0536e-01, -1.6683e-01, -1.6069e-01,  1.8902e-01,\n",
       "          1.6257e-01, -6.6034e-02,  1.5742e-01, -8.7845e-02, -2.1570e-02,\n",
       "          1.3838e-01,  1.6593e-01,  5.0301e-02, -1.7064e-01, -1.7869e-01,\n",
       "          2.3284e-01,  9.0496e-02, -1.0875e-01, -4.6753e-02,  2.1066e-01,\n",
       "         -1.6776e-01,  1.1145e-01, -1.9329e-01,  7.1425e-02, -3.2224e-02,\n",
       "         -8.1988e-02,  3.1259e-01, -1.1430e-04,  2.2732e-01, -1.0161e-01,\n",
       "         -1.2005e-02,  2.7377e-01,  1.4842e-01,  1.1984e-01,  2.4676e-02,\n",
       "         -2.2239e-01,  2.3032e-02, -5.7236e-02, -1.0728e-01,  9.6785e-02,\n",
       "         -2.0901e-01, -8.9334e-02, -8.1665e-03, -1.0752e-01,  6.6348e-02,\n",
       "          1.5246e-01,  2.1734e-01,  1.6583e-01,  1.2295e-01, -9.3648e-02,\n",
       "         -5.3275e-02, -6.4111e-02,  5.0119e-03,  1.1246e-01, -4.1189e-02,\n",
       "          1.3918e-01, -2.7500e-02,  1.6833e-01,  1.6940e-01, -5.2361e-02,\n",
       "          4.2561e-02, -1.1490e-01, -5.1776e-02,  2.6625e-02,  2.2468e-01,\n",
       "         -3.2545e-02, -6.8478e-02,  1.1407e-01,  1.4063e-01,  1.5164e-01,\n",
       "         -4.6100e-02,  9.1062e-02, -4.0627e-02,  3.8640e-02, -2.6644e-01,\n",
       "          4.6741e-02, -4.6597e-02, -1.5267e-01,  2.6826e-02,  1.2872e-01,\n",
       "          6.9809e-02, -3.8373e-02, -7.6129e-02,  6.4159e-02,  1.3642e-01,\n",
       "          1.4868e-01,  9.0634e-02, -1.3863e-01,  1.8477e-02, -1.5362e-02,\n",
       "         -1.3145e-01,  4.1265e-02,  2.0981e-02,  1.1572e-01,  2.8500e-01,\n",
       "          7.7105e-02, -4.6518e-02, -5.1764e-02,  9.9918e-02, -8.7202e-02,\n",
       "         -8.0133e-02,  1.8073e-01, -7.9130e-02, -2.4487e-01,  7.6403e-03,\n",
       "          3.7223e-02, -1.5276e-01,  7.6170e-02,  3.0205e-01,  5.2953e-02,\n",
       "         -9.8730e-02, -7.9947e-03, -1.2051e-01, -1.3026e-01,  1.2982e-02,\n",
       "          2.0166e-01,  1.5723e-02, -5.3386e-02,  1.6802e-01,  9.9406e-02,\n",
       "         -8.8714e-02, -2.4493e-01,  9.0132e-02,  1.3939e-01,  1.2193e-02,\n",
       "          1.9779e-01,  2.7049e-01,  1.4492e-01,  9.2404e-02,  2.1243e-01,\n",
       "         -6.4067e-02,  2.2432e-01,  8.7428e-02, -3.7596e-01,  8.8157e-02,\n",
       "         -2.3410e-01, -2.0846e-01, -9.6338e-02, -1.3290e-01,  3.7451e-02,\n",
       "          3.7476e-02,  1.9144e-01, -1.1462e-01,  4.7282e-02,  8.5190e-02,\n",
       "         -5.3434e-03,  7.7261e-02,  1.6119e-01, -1.4578e-01,  1.1092e-02,\n",
       "         -6.4970e-02,  1.2957e-01, -2.9358e-01,  1.8110e-01,  3.9454e-02,\n",
       "         -3.5696e-02,  1.3249e-01, -1.2853e-01, -1.3403e-01,  9.8159e-02,\n",
       "         -7.1774e-02,  5.3129e-02,  1.6064e-01,  6.6631e-02, -3.4157e-02,\n",
       "          1.4436e-01, -2.4016e-01,  3.3799e-01, -9.0122e-02,  1.3483e-01,\n",
       "          8.3981e-02, -2.8003e-01, -6.3610e-02,  1.7005e-01, -9.3522e-02,\n",
       "          3.8257e-02,  2.5103e-01, -8.9770e-02,  2.9448e-01,  2.4731e-01,\n",
       "         -1.5719e-01,  1.1030e-01, -1.8216e-01,  2.0182e-01,  1.2945e-01,\n",
       "          7.2925e-02,  3.1786e-01, -1.1987e-01,  3.8006e-03, -1.4278e-01,\n",
       "         -3.7970e-02, -9.5573e-02, -7.8751e-02, -3.0641e-01,  1.4424e-01,\n",
       "          1.6525e-02,  1.3890e-01, -1.5429e-02,  1.3792e-02, -4.2829e-02,\n",
       "         -3.9400e-03,  1.3086e-03, -4.7647e-02,  2.6158e-01, -2.2109e-03,\n",
       "         -7.0468e-02, -2.4658e-01,  1.5197e-01, -4.6118e-02,  1.1080e-01,\n",
       "         -7.7560e-02, -2.5739e-01,  8.8851e-02, -2.9674e-01, -8.6632e-03,\n",
       "         -2.2422e-01,  6.9614e-02,  1.7933e-01,  1.0379e-01,  4.4420e-01,\n",
       "         -1.0694e-02,  1.4970e-01, -1.3592e-01, -2.1330e-02, -2.3462e-01,\n",
       "          1.7236e-01, -1.8547e-01,  1.5186e-01, -3.8921e-02,  9.7551e-03,\n",
       "          1.3722e-01, -2.8464e-02, -5.8139e-02, -2.0086e-01, -1.0827e-01,\n",
       "          3.0330e-02,  5.9977e-02, -5.8591e-02,  1.0616e-01,  1.7657e-01,\n",
       "         -5.2382e-03, -4.0846e-02, -2.0527e-02, -3.4073e-02, -4.5392e-03,\n",
       "         -9.0816e-02,  9.6659e-02,  9.4945e-02, -1.5327e-01,  1.7728e-01,\n",
       "         -6.1747e-02, -2.7566e-02,  1.6349e-01,  1.4505e-01,  1.4648e-01,\n",
       "          1.2433e-01, -6.1578e-02, -3.6812e-02,  1.2416e-02, -8.5562e-02,\n",
       "         -9.3672e-02,  9.9787e-02,  9.6789e-03, -1.0820e-01,  4.1684e-02,\n",
       "         -3.0618e-01, -1.0097e-01, -5.8382e-02,  4.5348e-02,  5.9468e-02,\n",
       "         -8.8423e-02,  2.5818e-02, -1.1199e-01,  1.1706e-01,  2.1020e-01,\n",
       "          2.2399e-01, -8.2607e-02,  1.1746e-01,  1.3426e-01, -6.2183e-02,\n",
       "          5.5279e-02, -1.6882e-01,  4.1184e-02,  1.3282e-01,  2.1334e-01,\n",
       "          1.7304e-01,  1.5342e-01, -1.2916e-01, -4.5416e-01, -1.7643e-02,\n",
       "         -6.8432e-03,  1.2076e-01,  2.6253e-01, -1.7486e-02,  9.3739e-03,\n",
       "         -4.7471e-02,  2.0128e-01, -6.5222e-02,  3.5771e-02, -5.0772e-02,\n",
       "          1.3092e-01, -2.3629e-01, -1.7986e-01,  1.0895e-02, -7.0472e-02,\n",
       "         -9.7265e-02,  9.7866e-02,  2.3022e-01,  6.2281e-02,  2.4687e-01,\n",
       "         -1.5817e-01,  3.9846e-02, -1.7029e-01, -2.8082e-01, -2.4245e-01,\n",
       "         -5.2097e-02,  5.8493e-02, -1.5058e-01,  2.6510e-02,  1.5070e-01,\n",
       "         -4.1589e-02,  3.1647e-01, -9.2586e-02, -7.4979e-02, -2.0697e-01,\n",
       "         -3.2137e-01, -1.3750e-01,  6.0359e-02, -1.7000e-01, -8.1845e-02,\n",
       "          5.3737e-02, -1.8009e-01]], device='cuda:0', grad_fn=<AddmmBackward0>)"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoder_hidden"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "d8262473-c4fc-4a38-9f32-13869a36ae4a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 512])"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoder_hidden.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "1c059f35-d27e-4ec2-8183-f4282c040c4c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-2.6725e-02, -2.8484e-02, -2.2103e-02, -7.5990e-02, -1.6661e-01,\n",
       "          4.1188e-02,  1.1426e-01, -2.1968e-01, -9.6342e-02, -2.7733e-02,\n",
       "          9.9623e-02, -2.3648e-01,  4.3565e-02, -4.6121e-03, -1.9655e-01,\n",
       "          4.8431e-02,  4.3675e-02,  1.6051e-01,  7.5895e-02, -1.1379e-01,\n",
       "          4.9420e-02, -2.8200e-01,  2.1536e-01, -1.7395e-01, -7.1819e-02,\n",
       "          4.2751e-03,  1.3051e-01, -4.7527e-02, -1.6499e-01,  9.5409e-03,\n",
       "          1.3376e-01, -1.0672e-02,  3.4931e-01,  3.6965e-01,  8.3024e-02,\n",
       "         -7.3793e-02,  2.4083e-01,  5.6800e-02,  2.1083e-01, -1.0905e-01,\n",
       "         -1.5902e-01, -1.1473e-01,  2.8838e-01,  7.4191e-02,  6.4179e-02,\n",
       "          1.4164e-01, -1.0146e-01,  9.1499e-02, -1.8660e-02, -2.6614e-02,\n",
       "          1.0658e-02,  2.8504e-01,  2.1275e-02,  1.0248e-02, -3.9928e-03,\n",
       "         -3.7584e-04,  1.2951e-02,  2.5689e-01,  4.2087e-02,  2.0912e-01,\n",
       "          7.5375e-02, -7.3558e-02, -9.6267e-02, -5.2454e-02, -3.8492e-03,\n",
       "          9.0253e-03,  2.4067e-01, -2.8385e-01, -1.2369e-01, -7.5594e-02,\n",
       "         -9.0637e-02,  2.3637e-02,  2.7711e-02, -1.4395e-02, -5.5035e-02,\n",
       "          4.2882e-03, -5.8594e-02,  3.5103e-02,  5.1931e-02,  3.9232e-02,\n",
       "         -6.9588e-03,  2.6243e-01, -5.9048e-02,  1.9255e-01, -9.9085e-02,\n",
       "          1.7956e-01, -2.2726e-01,  1.1197e-02,  5.1161e-02,  7.8938e-02,\n",
       "         -1.6248e-01,  7.6075e-02,  7.9550e-02, -3.3210e-02, -6.5805e-02,\n",
       "          2.5801e-01,  6.3244e-02, -2.4646e-01,  1.0695e-01, -2.8226e-01,\n",
       "         -1.0122e-01, -1.0039e-01,  2.1283e-01, -1.0688e-01,  2.7481e-01,\n",
       "         -4.5594e-02, -1.2486e-01,  5.3522e-02,  7.0257e-02, -4.0798e-02,\n",
       "          3.5983e-01, -1.2418e-05,  2.1717e-01, -7.2065e-02,  1.5643e-02,\n",
       "          5.7517e-02, -1.4806e-01, -7.3804e-02, -2.4379e-01,  8.0196e-02,\n",
       "         -2.2682e-01,  1.3828e-01, -3.8489e-03, -9.2707e-02,  1.1814e-01,\n",
       "          1.8470e-02,  2.5246e-01,  1.0031e-01,  1.0272e-01,  1.2939e-01,\n",
       "          4.0505e-02, -4.6636e-02, -7.1517e-02, -8.4915e-02, -7.7300e-02,\n",
       "          6.6324e-02,  2.8858e-01, -2.1965e-01,  1.1955e-01, -2.7873e-01,\n",
       "          1.4056e-02, -1.8009e-01,  1.2964e-01, -1.5927e-01, -1.8111e-01,\n",
       "          1.5719e-01,  2.5834e-01,  2.4205e-01, -3.0644e-02, -4.3289e-02,\n",
       "          1.9202e-01, -6.6077e-02,  1.2297e-01,  8.3355e-02,  3.3189e-01,\n",
       "         -1.8263e-01,  7.8476e-02, -5.9603e-02,  5.7889e-02, -2.7710e-02,\n",
       "          8.6137e-02,  1.7723e-01,  1.5375e-01, -1.8563e-01, -1.1276e-01,\n",
       "         -3.2585e-02, -4.8061e-02, -1.0331e-02,  3.2349e-02, -1.3193e-01,\n",
       "         -2.3315e-01, -7.1245e-02, -1.5715e-01, -9.1798e-02, -1.2696e-01,\n",
       "          3.8986e-01, -1.8053e-01, -1.7613e-01,  7.1580e-02,  7.7166e-02,\n",
       "         -1.7013e-01, -2.0252e-01, -1.6530e-01, -1.5932e-01,  1.8680e-01,\n",
       "          1.6116e-01, -6.5939e-02,  1.5613e-01, -8.7620e-02, -2.1567e-02,\n",
       "          1.3750e-01,  1.6442e-01,  5.0258e-02, -1.6900e-01, -1.7682e-01,\n",
       "          2.2872e-01,  9.0250e-02, -1.0833e-01, -4.6719e-02,  2.0760e-01,\n",
       "         -1.6621e-01,  1.1099e-01, -1.9092e-01,  7.1304e-02, -3.2213e-02,\n",
       "         -8.1805e-02,  3.0279e-01, -1.1430e-04,  2.2348e-01, -1.0126e-01,\n",
       "         -1.2005e-02,  2.6713e-01,  1.4734e-01,  1.1927e-01,  2.4671e-02,\n",
       "         -2.1880e-01,  2.3028e-02, -5.7174e-02, -1.0687e-01,  9.6484e-02,\n",
       "         -2.0602e-01, -8.9097e-02, -8.1663e-03, -1.0710e-01,  6.6250e-02,\n",
       "          1.5129e-01,  2.1398e-01,  1.6433e-01,  1.2233e-01, -9.3375e-02,\n",
       "         -5.3225e-02, -6.4023e-02,  5.0118e-03,  1.1199e-01, -4.1166e-02,\n",
       "          1.3829e-01, -2.7493e-02,  1.6675e-01,  1.6780e-01, -5.2313e-02,\n",
       "          4.2536e-02, -1.1439e-01, -5.1730e-02,  2.6619e-02,  2.2097e-01,\n",
       "         -3.2534e-02, -6.8371e-02,  1.1358e-01,  1.3971e-01,  1.5049e-01,\n",
       "         -4.6067e-02,  9.0811e-02, -4.0605e-02,  3.8621e-02, -2.6031e-01,\n",
       "          4.6707e-02, -4.6563e-02, -1.5150e-01,  2.6820e-02,  1.2802e-01,\n",
       "          6.9696e-02, -3.8354e-02, -7.5983e-02,  6.4071e-02,  1.3558e-01,\n",
       "          1.4760e-01,  9.0387e-02, -1.3775e-01,  1.8475e-02, -1.5360e-02,\n",
       "         -1.3069e-01,  4.1242e-02,  2.0978e-02,  1.1521e-01,  2.7753e-01,\n",
       "          7.6953e-02, -4.6484e-02, -5.1718e-02,  9.9587e-02, -8.6981e-02,\n",
       "         -7.9962e-02,  1.7879e-01, -7.8965e-02, -2.4009e-01,  7.6402e-03,\n",
       "          3.7206e-02, -1.5158e-01,  7.6023e-02,  2.9319e-01,  5.2904e-02,\n",
       "         -9.8411e-02, -7.9945e-03, -1.1993e-01, -1.2953e-01,  1.2981e-02,\n",
       "          1.9897e-01,  1.5721e-02, -5.3336e-02,  1.6646e-01,  9.9080e-02,\n",
       "         -8.8482e-02, -2.4014e-01,  8.9889e-02,  1.3850e-01,  1.2193e-02,\n",
       "          1.9525e-01,  2.6408e-01,  1.4391e-01,  9.2142e-02,  2.0929e-01,\n",
       "         -6.3979e-02,  2.2064e-01,  8.7206e-02, -3.5920e-01,  8.7929e-02,\n",
       "         -2.2991e-01, -2.0549e-01, -9.6041e-02, -1.3213e-01,  3.7434e-02,\n",
       "          3.7458e-02,  1.8913e-01, -1.1412e-01,  4.7247e-02,  8.4984e-02,\n",
       "         -5.3433e-03,  7.7108e-02,  1.5980e-01, -1.4475e-01,  1.1092e-02,\n",
       "         -6.4879e-02,  1.2885e-01, -2.8542e-01,  1.7914e-01,  3.9433e-02,\n",
       "         -3.5681e-02,  1.3172e-01, -1.2783e-01, -1.3323e-01,  9.7845e-02,\n",
       "         -7.1651e-02,  5.3079e-02,  1.5927e-01,  6.6532e-02, -3.4143e-02,\n",
       "          1.4337e-01, -2.3565e-01,  3.2568e-01, -8.9879e-02,  1.3402e-01,\n",
       "          8.3784e-02, -2.7293e-01, -6.3525e-02,  1.6843e-01, -9.3251e-02,\n",
       "          3.8238e-02,  2.4588e-01, -8.9530e-02,  2.8626e-01,  2.4239e-01,\n",
       "         -1.5591e-01,  1.0985e-01, -1.8017e-01,  1.9912e-01,  1.2873e-01,\n",
       "          7.2796e-02,  3.0757e-01, -1.1930e-01,  3.8006e-03, -1.4182e-01,\n",
       "         -3.7952e-02, -9.5283e-02, -7.8589e-02, -2.9717e-01,  1.4325e-01,\n",
       "          1.6523e-02,  1.3802e-01, -1.5428e-02,  1.3791e-02, -4.2803e-02,\n",
       "         -3.9400e-03,  1.3086e-03, -4.7611e-02,  2.5577e-01, -2.2109e-03,\n",
       "         -7.0351e-02, -2.4170e-01,  1.5081e-01, -4.6085e-02,  1.1035e-01,\n",
       "         -7.7404e-02, -2.5185e-01,  8.8618e-02, -2.8833e-01, -8.6630e-03,\n",
       "         -2.2054e-01,  6.9502e-02,  1.7743e-01,  1.0342e-01,  4.1712e-01,\n",
       "         -1.0693e-02,  1.4859e-01, -1.3509e-01, -2.1327e-02, -2.3041e-01,\n",
       "          1.7067e-01, -1.8338e-01,  1.5071e-01, -3.8901e-02,  9.7548e-03,\n",
       "          1.3636e-01, -2.8456e-02, -5.8074e-02, -1.9820e-01, -1.0785e-01,\n",
       "          3.0321e-02,  5.9905e-02, -5.8524e-02,  1.0576e-01,  1.7476e-01,\n",
       "         -5.2382e-03, -4.0823e-02, -2.0524e-02, -3.4060e-02, -4.5391e-03,\n",
       "         -9.0567e-02,  9.6359e-02,  9.4661e-02, -1.5208e-01,  1.7545e-01,\n",
       "         -6.1669e-02, -2.7559e-02,  1.6204e-01,  1.4404e-01,  1.4544e-01,\n",
       "          1.2369e-01, -6.1500e-02, -3.6796e-02,  1.2415e-02, -8.5354e-02,\n",
       "         -9.3399e-02,  9.9457e-02,  9.6786e-03, -1.0778e-01,  4.1660e-02,\n",
       "         -2.9696e-01, -1.0062e-01, -5.8316e-02,  4.5317e-02,  5.9398e-02,\n",
       "         -8.8193e-02,  2.5812e-02, -1.1153e-01,  1.1652e-01,  2.0716e-01,\n",
       "          2.2032e-01, -8.2419e-02,  1.1692e-01,  1.3346e-01, -6.2103e-02,\n",
       "          5.5223e-02, -1.6724e-01,  4.1161e-02,  1.3205e-01,  2.1016e-01,\n",
       "          1.7133e-01,  1.5223e-01, -1.2845e-01, -4.2531e-01, -1.7641e-02,\n",
       "         -6.8431e-03,  1.2018e-01,  2.5666e-01, -1.7484e-02,  9.3737e-03,\n",
       "         -4.7435e-02,  1.9860e-01, -6.5129e-02,  3.5756e-02, -5.0728e-02,\n",
       "          1.3018e-01, -2.3199e-01, -1.7794e-01,  1.0895e-02, -7.0356e-02,\n",
       "         -9.6959e-02,  9.7555e-02,  2.2623e-01,  6.2200e-02,  2.4198e-01,\n",
       "         -1.5687e-01,  3.9824e-02, -1.6867e-01, -2.7366e-01, -2.3781e-01,\n",
       "         -5.2050e-02,  5.8426e-02, -1.4945e-01,  2.6504e-02,  1.4957e-01,\n",
       "         -4.1565e-02,  3.0631e-01, -9.2323e-02, -7.4839e-02, -2.0406e-01,\n",
       "         -3.1074e-01, -1.3664e-01,  6.0285e-02, -1.6838e-01, -8.1663e-02,\n",
       "          5.3685e-02, -1.7817e-01]], device='cuda:0', grad_fn=<TanhBackward0>)"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#활성함수 tanh 실행\n",
    "\n",
    "torch.tanh(encoder_hidden)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "645b1d9b-57d1-47fc-8605-54c75abea4eb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "134"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "26cf12ec-5f1b-4c74-9417-30e9a0864c90",
   "metadata": {},
   "outputs": [],
   "source": [
    "#인코더 연산을 클래스로 선언\n",
    "class Encoder(nn.Module):\n",
    "    def __init__(self, input_size, hid_dim, n_layer):\n",
    "        super().__init__()\n",
    "        self.hid_dim = hid_dim\n",
    "        self.n_layer = n_layer\n",
    "        self.gru = nn.GRU(\n",
    "            input_size,\n",
    "            hid_dim,\n",
    "            n_layer,\n",
    "            batch_first = True,\n",
    "            bidirectional = True\n",
    "        )\n",
    "\n",
    "        self.fc = nn.Linear(\n",
    "            hid_dim * 4,\n",
    "            hid_dim\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        h0 = torch.zeros(self.n_layer*2, x.shape[0], self.hid_dim).cuda().float()\n",
    "        encoder_output, encoder_hidden = gru(x,h0)\n",
    "\n",
    "        encoder_hidden = torch.cat((\n",
    "            encoder_hidden[-4,:,:],\n",
    "            encoder_hidden[-3,:,:],\n",
    "            encoder_hidden[-2,:,:],\n",
    "            encoder_hidden[-1,:,:]\n",
    "        ), dim = 1)\n",
    "\n",
    "        encoder_hidden = torch.tanh(self.fc(encoder_hidden))\n",
    "        return encoder_output, encoder_hidden"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "742b8581-43f1-436d-9f6c-ad1603a9ff8f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 240, 1024])"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoder_output.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "90f56f0f-9702-4b28-bf1d-5f03d81c0b33",
   "metadata": {},
   "outputs": [],
   "source": [
    "#encoder_output.shape[1] : 인코더 결과의 행의 개수 => 240프레임\n",
    "src_len = encoder_output.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "e835e6c5-7087-446d-81c1-63f3b83c4742",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "240"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "src_len"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "fbda7a9a-2f4d-4744-95b7-6181e13f04a6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-2.6731e-02, -2.8492e-02, -2.2107e-02, -7.6137e-02, -1.6818e-01,\n",
       "          4.1211e-02,  1.1476e-01, -2.2332e-01, -9.6641e-02, -2.7740e-02,\n",
       "          9.9955e-02, -2.4105e-01,  4.3593e-02, -4.6121e-03, -1.9914e-01,\n",
       "          4.8469e-02,  4.3703e-02,  1.6191e-01,  7.6041e-02, -1.1429e-01,\n",
       "          4.9460e-02, -2.8985e-01,  2.1878e-01, -1.7574e-01, -7.1943e-02,\n",
       "          4.2752e-03,  1.3126e-01, -4.7563e-02, -1.6651e-01,  9.5412e-03,\n",
       "          1.3457e-01, -1.0672e-02,  3.6466e-01,  3.8801e-01,  8.3215e-02,\n",
       "         -7.3927e-02,  2.4566e-01,  5.6862e-02,  2.1404e-01, -1.0948e-01,\n",
       "         -1.6038e-01, -1.1524e-01,  2.9680e-01,  7.4328e-02,  6.4268e-02,\n",
       "          1.4260e-01, -1.0181e-01,  9.1755e-02, -1.8662e-02, -2.6620e-02,\n",
       "          1.0658e-02,  2.9316e-01,  2.1279e-02,  1.0248e-02, -3.9928e-03,\n",
       "         -3.7584e-04,  1.2952e-02,  2.6277e-01,  4.2112e-02,  2.1225e-01,\n",
       "          7.5519e-02, -7.3691e-02, -9.6566e-02, -5.2502e-02, -3.8493e-03,\n",
       "          9.0256e-03,  2.4548e-01, -2.9186e-01, -1.2433e-01, -7.5739e-02,\n",
       "         -9.0886e-02,  2.3641e-02,  2.7718e-02, -1.4396e-02, -5.5091e-02,\n",
       "          4.2882e-03, -5.8662e-02,  3.5118e-02,  5.1978e-02,  3.9253e-02,\n",
       "         -6.9589e-03,  2.6872e-01, -5.9116e-02,  1.9498e-01, -9.9411e-02,\n",
       "          1.8153e-01, -2.3129e-01,  1.1197e-02,  5.1205e-02,  7.9103e-02,\n",
       "         -1.6393e-01,  7.6223e-02,  7.9719e-02, -3.3222e-02, -6.5901e-02,\n",
       "          2.6397e-01,  6.3329e-02, -2.5164e-01,  1.0736e-01, -2.9014e-01,\n",
       "         -1.0157e-01, -1.0073e-01,  2.1614e-01, -1.0729e-01,  2.8206e-01,\n",
       "         -4.5626e-02, -1.2552e-01,  5.3573e-02,  7.0373e-02, -4.0820e-02,\n",
       "          3.7669e-01, -1.2418e-05,  2.2068e-01, -7.2190e-02,  1.5644e-02,\n",
       "          5.7581e-02, -1.4915e-01, -7.3938e-02, -2.4880e-01,  8.0369e-02,\n",
       "         -2.3083e-01,  1.3917e-01, -3.8489e-03, -9.2974e-02,  1.1870e-01,\n",
       "          1.8472e-02,  2.5804e-01,  1.0065e-01,  1.0308e-01,  1.3012e-01,\n",
       "          4.0527e-02, -4.6670e-02, -7.1639e-02, -8.5120e-02, -7.7454e-02,\n",
       "          6.6421e-02,  2.9701e-01, -2.2329e-01,  1.2013e-01, -2.8630e-01,\n",
       "          1.4057e-02, -1.8208e-01,  1.3037e-01, -1.6064e-01, -1.8313e-01,\n",
       "          1.5850e-01,  2.6433e-01,  2.4695e-01, -3.0653e-02, -4.3316e-02,\n",
       "          1.9443e-01, -6.6174e-02,  1.2360e-01,  8.3549e-02,  3.4495e-01,\n",
       "         -1.8470e-01,  7.8638e-02, -5.9674e-02,  5.7954e-02, -2.7717e-02,\n",
       "          8.6351e-02,  1.7912e-01,  1.5498e-01, -1.8781e-01, -1.1325e-01,\n",
       "         -3.2596e-02, -4.8098e-02, -1.0332e-02,  3.2361e-02, -1.3270e-01,\n",
       "         -2.3752e-01, -7.1366e-02, -1.5846e-01, -9.2057e-02, -1.2765e-01,\n",
       "          4.1164e-01, -1.8253e-01, -1.7798e-01,  7.1703e-02,  7.7320e-02,\n",
       "         -1.7180e-01, -2.0536e-01, -1.6683e-01, -1.6069e-01,  1.8902e-01,\n",
       "          1.6257e-01, -6.6034e-02,  1.5742e-01, -8.7845e-02, -2.1570e-02,\n",
       "          1.3838e-01,  1.6593e-01,  5.0301e-02, -1.7064e-01, -1.7869e-01,\n",
       "          2.3284e-01,  9.0496e-02, -1.0875e-01, -4.6753e-02,  2.1066e-01,\n",
       "         -1.6776e-01,  1.1145e-01, -1.9329e-01,  7.1425e-02, -3.2224e-02,\n",
       "         -8.1988e-02,  3.1259e-01, -1.1430e-04,  2.2732e-01, -1.0161e-01,\n",
       "         -1.2005e-02,  2.7377e-01,  1.4842e-01,  1.1984e-01,  2.4676e-02,\n",
       "         -2.2239e-01,  2.3032e-02, -5.7236e-02, -1.0728e-01,  9.6785e-02,\n",
       "         -2.0901e-01, -8.9334e-02, -8.1665e-03, -1.0752e-01,  6.6348e-02,\n",
       "          1.5246e-01,  2.1734e-01,  1.6583e-01,  1.2295e-01, -9.3648e-02,\n",
       "         -5.3275e-02, -6.4111e-02,  5.0119e-03,  1.1246e-01, -4.1189e-02,\n",
       "          1.3918e-01, -2.7500e-02,  1.6833e-01,  1.6940e-01, -5.2361e-02,\n",
       "          4.2561e-02, -1.1490e-01, -5.1776e-02,  2.6625e-02,  2.2468e-01,\n",
       "         -3.2545e-02, -6.8478e-02,  1.1407e-01,  1.4063e-01,  1.5164e-01,\n",
       "         -4.6100e-02,  9.1062e-02, -4.0627e-02,  3.8640e-02, -2.6644e-01,\n",
       "          4.6741e-02, -4.6597e-02, -1.5267e-01,  2.6826e-02,  1.2872e-01,\n",
       "          6.9809e-02, -3.8373e-02, -7.6129e-02,  6.4159e-02,  1.3642e-01,\n",
       "          1.4868e-01,  9.0634e-02, -1.3863e-01,  1.8477e-02, -1.5362e-02,\n",
       "         -1.3145e-01,  4.1265e-02,  2.0981e-02,  1.1572e-01,  2.8500e-01,\n",
       "          7.7105e-02, -4.6518e-02, -5.1764e-02,  9.9918e-02, -8.7202e-02,\n",
       "         -8.0133e-02,  1.8073e-01, -7.9130e-02, -2.4487e-01,  7.6403e-03,\n",
       "          3.7223e-02, -1.5276e-01,  7.6170e-02,  3.0205e-01,  5.2953e-02,\n",
       "         -9.8730e-02, -7.9947e-03, -1.2051e-01, -1.3026e-01,  1.2982e-02,\n",
       "          2.0166e-01,  1.5723e-02, -5.3386e-02,  1.6802e-01,  9.9406e-02,\n",
       "         -8.8714e-02, -2.4493e-01,  9.0132e-02,  1.3939e-01,  1.2193e-02,\n",
       "          1.9779e-01,  2.7049e-01,  1.4492e-01,  9.2404e-02,  2.1243e-01,\n",
       "         -6.4067e-02,  2.2432e-01,  8.7428e-02, -3.7596e-01,  8.8157e-02,\n",
       "         -2.3410e-01, -2.0846e-01, -9.6338e-02, -1.3290e-01,  3.7451e-02,\n",
       "          3.7476e-02,  1.9144e-01, -1.1462e-01,  4.7282e-02,  8.5190e-02,\n",
       "         -5.3434e-03,  7.7261e-02,  1.6119e-01, -1.4578e-01,  1.1092e-02,\n",
       "         -6.4970e-02,  1.2957e-01, -2.9358e-01,  1.8110e-01,  3.9454e-02,\n",
       "         -3.5696e-02,  1.3249e-01, -1.2853e-01, -1.3403e-01,  9.8159e-02,\n",
       "         -7.1774e-02,  5.3129e-02,  1.6064e-01,  6.6631e-02, -3.4157e-02,\n",
       "          1.4436e-01, -2.4016e-01,  3.3799e-01, -9.0122e-02,  1.3483e-01,\n",
       "          8.3981e-02, -2.8003e-01, -6.3610e-02,  1.7005e-01, -9.3522e-02,\n",
       "          3.8257e-02,  2.5103e-01, -8.9770e-02,  2.9448e-01,  2.4731e-01,\n",
       "         -1.5719e-01,  1.1030e-01, -1.8216e-01,  2.0182e-01,  1.2945e-01,\n",
       "          7.2925e-02,  3.1786e-01, -1.1987e-01,  3.8006e-03, -1.4278e-01,\n",
       "         -3.7970e-02, -9.5573e-02, -7.8751e-02, -3.0641e-01,  1.4424e-01,\n",
       "          1.6525e-02,  1.3890e-01, -1.5429e-02,  1.3792e-02, -4.2829e-02,\n",
       "         -3.9400e-03,  1.3086e-03, -4.7647e-02,  2.6158e-01, -2.2109e-03,\n",
       "         -7.0468e-02, -2.4658e-01,  1.5197e-01, -4.6118e-02,  1.1080e-01,\n",
       "         -7.7560e-02, -2.5739e-01,  8.8851e-02, -2.9674e-01, -8.6632e-03,\n",
       "         -2.2422e-01,  6.9614e-02,  1.7933e-01,  1.0379e-01,  4.4420e-01,\n",
       "         -1.0694e-02,  1.4970e-01, -1.3592e-01, -2.1330e-02, -2.3462e-01,\n",
       "          1.7236e-01, -1.8547e-01,  1.5186e-01, -3.8921e-02,  9.7551e-03,\n",
       "          1.3722e-01, -2.8464e-02, -5.8139e-02, -2.0086e-01, -1.0827e-01,\n",
       "          3.0330e-02,  5.9977e-02, -5.8591e-02,  1.0616e-01,  1.7657e-01,\n",
       "         -5.2382e-03, -4.0846e-02, -2.0527e-02, -3.4073e-02, -4.5392e-03,\n",
       "         -9.0816e-02,  9.6659e-02,  9.4945e-02, -1.5327e-01,  1.7728e-01,\n",
       "         -6.1747e-02, -2.7566e-02,  1.6349e-01,  1.4505e-01,  1.4648e-01,\n",
       "          1.2433e-01, -6.1578e-02, -3.6812e-02,  1.2416e-02, -8.5562e-02,\n",
       "         -9.3672e-02,  9.9787e-02,  9.6789e-03, -1.0820e-01,  4.1684e-02,\n",
       "         -3.0618e-01, -1.0097e-01, -5.8382e-02,  4.5348e-02,  5.9468e-02,\n",
       "         -8.8423e-02,  2.5818e-02, -1.1199e-01,  1.1706e-01,  2.1020e-01,\n",
       "          2.2399e-01, -8.2607e-02,  1.1746e-01,  1.3426e-01, -6.2183e-02,\n",
       "          5.5279e-02, -1.6882e-01,  4.1184e-02,  1.3282e-01,  2.1334e-01,\n",
       "          1.7304e-01,  1.5342e-01, -1.2916e-01, -4.5416e-01, -1.7643e-02,\n",
       "         -6.8432e-03,  1.2076e-01,  2.6253e-01, -1.7486e-02,  9.3739e-03,\n",
       "         -4.7471e-02,  2.0128e-01, -6.5222e-02,  3.5771e-02, -5.0772e-02,\n",
       "          1.3092e-01, -2.3629e-01, -1.7986e-01,  1.0895e-02, -7.0472e-02,\n",
       "         -9.7265e-02,  9.7866e-02,  2.3022e-01,  6.2281e-02,  2.4687e-01,\n",
       "         -1.5817e-01,  3.9846e-02, -1.7029e-01, -2.8082e-01, -2.4245e-01,\n",
       "         -5.2097e-02,  5.8493e-02, -1.5058e-01,  2.6510e-02,  1.5070e-01,\n",
       "         -4.1589e-02,  3.1647e-01, -9.2586e-02, -7.4979e-02, -2.0697e-01,\n",
       "         -3.2137e-01, -1.3750e-01,  6.0359e-02, -1.7000e-01, -8.1845e-02,\n",
       "          5.3737e-02, -1.8009e-01]], device='cuda:0', grad_fn=<AddmmBackward0>)"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#인코더의 히든 레이어 결과\n",
    "encoder_hidden"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "a117366c-8d61-4c2b-8500-1555cf48f449",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 512])"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoder_hidden.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "4a8854df-0fc7-4a15-9628-a65f9711107f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[-2.6731e-02, -2.8492e-02, -2.2107e-02, -7.6137e-02, -1.6818e-01,\n",
       "           4.1211e-02,  1.1476e-01, -2.2332e-01, -9.6641e-02, -2.7740e-02,\n",
       "           9.9955e-02, -2.4105e-01,  4.3593e-02, -4.6121e-03, -1.9914e-01,\n",
       "           4.8469e-02,  4.3703e-02,  1.6191e-01,  7.6041e-02, -1.1429e-01,\n",
       "           4.9460e-02, -2.8985e-01,  2.1878e-01, -1.7574e-01, -7.1943e-02,\n",
       "           4.2752e-03,  1.3126e-01, -4.7563e-02, -1.6651e-01,  9.5412e-03,\n",
       "           1.3457e-01, -1.0672e-02,  3.6466e-01,  3.8801e-01,  8.3215e-02,\n",
       "          -7.3927e-02,  2.4566e-01,  5.6862e-02,  2.1404e-01, -1.0948e-01,\n",
       "          -1.6038e-01, -1.1524e-01,  2.9680e-01,  7.4328e-02,  6.4268e-02,\n",
       "           1.4260e-01, -1.0181e-01,  9.1755e-02, -1.8662e-02, -2.6620e-02,\n",
       "           1.0658e-02,  2.9316e-01,  2.1279e-02,  1.0248e-02, -3.9928e-03,\n",
       "          -3.7584e-04,  1.2952e-02,  2.6277e-01,  4.2112e-02,  2.1225e-01,\n",
       "           7.5519e-02, -7.3691e-02, -9.6566e-02, -5.2502e-02, -3.8493e-03,\n",
       "           9.0256e-03,  2.4548e-01, -2.9186e-01, -1.2433e-01, -7.5739e-02,\n",
       "          -9.0886e-02,  2.3641e-02,  2.7718e-02, -1.4396e-02, -5.5091e-02,\n",
       "           4.2882e-03, -5.8662e-02,  3.5118e-02,  5.1978e-02,  3.9253e-02,\n",
       "          -6.9589e-03,  2.6872e-01, -5.9116e-02,  1.9498e-01, -9.9411e-02,\n",
       "           1.8153e-01, -2.3129e-01,  1.1197e-02,  5.1205e-02,  7.9103e-02,\n",
       "          -1.6393e-01,  7.6223e-02,  7.9719e-02, -3.3222e-02, -6.5901e-02,\n",
       "           2.6397e-01,  6.3329e-02, -2.5164e-01,  1.0736e-01, -2.9014e-01,\n",
       "          -1.0157e-01, -1.0073e-01,  2.1614e-01, -1.0729e-01,  2.8206e-01,\n",
       "          -4.5626e-02, -1.2552e-01,  5.3573e-02,  7.0373e-02, -4.0820e-02,\n",
       "           3.7669e-01, -1.2418e-05,  2.2068e-01, -7.2190e-02,  1.5644e-02,\n",
       "           5.7581e-02, -1.4915e-01, -7.3938e-02, -2.4880e-01,  8.0369e-02,\n",
       "          -2.3083e-01,  1.3917e-01, -3.8489e-03, -9.2974e-02,  1.1870e-01,\n",
       "           1.8472e-02,  2.5804e-01,  1.0065e-01,  1.0308e-01,  1.3012e-01,\n",
       "           4.0527e-02, -4.6670e-02, -7.1639e-02, -8.5120e-02, -7.7454e-02,\n",
       "           6.6421e-02,  2.9701e-01, -2.2329e-01,  1.2013e-01, -2.8630e-01,\n",
       "           1.4057e-02, -1.8208e-01,  1.3037e-01, -1.6064e-01, -1.8313e-01,\n",
       "           1.5850e-01,  2.6433e-01,  2.4695e-01, -3.0653e-02, -4.3316e-02,\n",
       "           1.9443e-01, -6.6174e-02,  1.2360e-01,  8.3549e-02,  3.4495e-01,\n",
       "          -1.8470e-01,  7.8638e-02, -5.9674e-02,  5.7954e-02, -2.7717e-02,\n",
       "           8.6351e-02,  1.7912e-01,  1.5498e-01, -1.8781e-01, -1.1325e-01,\n",
       "          -3.2596e-02, -4.8098e-02, -1.0332e-02,  3.2361e-02, -1.3270e-01,\n",
       "          -2.3752e-01, -7.1366e-02, -1.5846e-01, -9.2057e-02, -1.2765e-01,\n",
       "           4.1164e-01, -1.8253e-01, -1.7798e-01,  7.1703e-02,  7.7320e-02,\n",
       "          -1.7180e-01, -2.0536e-01, -1.6683e-01, -1.6069e-01,  1.8902e-01,\n",
       "           1.6257e-01, -6.6034e-02,  1.5742e-01, -8.7845e-02, -2.1570e-02,\n",
       "           1.3838e-01,  1.6593e-01,  5.0301e-02, -1.7064e-01, -1.7869e-01,\n",
       "           2.3284e-01,  9.0496e-02, -1.0875e-01, -4.6753e-02,  2.1066e-01,\n",
       "          -1.6776e-01,  1.1145e-01, -1.9329e-01,  7.1425e-02, -3.2224e-02,\n",
       "          -8.1988e-02,  3.1259e-01, -1.1430e-04,  2.2732e-01, -1.0161e-01,\n",
       "          -1.2005e-02,  2.7377e-01,  1.4842e-01,  1.1984e-01,  2.4676e-02,\n",
       "          -2.2239e-01,  2.3032e-02, -5.7236e-02, -1.0728e-01,  9.6785e-02,\n",
       "          -2.0901e-01, -8.9334e-02, -8.1665e-03, -1.0752e-01,  6.6348e-02,\n",
       "           1.5246e-01,  2.1734e-01,  1.6583e-01,  1.2295e-01, -9.3648e-02,\n",
       "          -5.3275e-02, -6.4111e-02,  5.0119e-03,  1.1246e-01, -4.1189e-02,\n",
       "           1.3918e-01, -2.7500e-02,  1.6833e-01,  1.6940e-01, -5.2361e-02,\n",
       "           4.2561e-02, -1.1490e-01, -5.1776e-02,  2.6625e-02,  2.2468e-01,\n",
       "          -3.2545e-02, -6.8478e-02,  1.1407e-01,  1.4063e-01,  1.5164e-01,\n",
       "          -4.6100e-02,  9.1062e-02, -4.0627e-02,  3.8640e-02, -2.6644e-01,\n",
       "           4.6741e-02, -4.6597e-02, -1.5267e-01,  2.6826e-02,  1.2872e-01,\n",
       "           6.9809e-02, -3.8373e-02, -7.6129e-02,  6.4159e-02,  1.3642e-01,\n",
       "           1.4868e-01,  9.0634e-02, -1.3863e-01,  1.8477e-02, -1.5362e-02,\n",
       "          -1.3145e-01,  4.1265e-02,  2.0981e-02,  1.1572e-01,  2.8500e-01,\n",
       "           7.7105e-02, -4.6518e-02, -5.1764e-02,  9.9918e-02, -8.7202e-02,\n",
       "          -8.0133e-02,  1.8073e-01, -7.9130e-02, -2.4487e-01,  7.6403e-03,\n",
       "           3.7223e-02, -1.5276e-01,  7.6170e-02,  3.0205e-01,  5.2953e-02,\n",
       "          -9.8730e-02, -7.9947e-03, -1.2051e-01, -1.3026e-01,  1.2982e-02,\n",
       "           2.0166e-01,  1.5723e-02, -5.3386e-02,  1.6802e-01,  9.9406e-02,\n",
       "          -8.8714e-02, -2.4493e-01,  9.0132e-02,  1.3939e-01,  1.2193e-02,\n",
       "           1.9779e-01,  2.7049e-01,  1.4492e-01,  9.2404e-02,  2.1243e-01,\n",
       "          -6.4067e-02,  2.2432e-01,  8.7428e-02, -3.7596e-01,  8.8157e-02,\n",
       "          -2.3410e-01, -2.0846e-01, -9.6338e-02, -1.3290e-01,  3.7451e-02,\n",
       "           3.7476e-02,  1.9144e-01, -1.1462e-01,  4.7282e-02,  8.5190e-02,\n",
       "          -5.3434e-03,  7.7261e-02,  1.6119e-01, -1.4578e-01,  1.1092e-02,\n",
       "          -6.4970e-02,  1.2957e-01, -2.9358e-01,  1.8110e-01,  3.9454e-02,\n",
       "          -3.5696e-02,  1.3249e-01, -1.2853e-01, -1.3403e-01,  9.8159e-02,\n",
       "          -7.1774e-02,  5.3129e-02,  1.6064e-01,  6.6631e-02, -3.4157e-02,\n",
       "           1.4436e-01, -2.4016e-01,  3.3799e-01, -9.0122e-02,  1.3483e-01,\n",
       "           8.3981e-02, -2.8003e-01, -6.3610e-02,  1.7005e-01, -9.3522e-02,\n",
       "           3.8257e-02,  2.5103e-01, -8.9770e-02,  2.9448e-01,  2.4731e-01,\n",
       "          -1.5719e-01,  1.1030e-01, -1.8216e-01,  2.0182e-01,  1.2945e-01,\n",
       "           7.2925e-02,  3.1786e-01, -1.1987e-01,  3.8006e-03, -1.4278e-01,\n",
       "          -3.7970e-02, -9.5573e-02, -7.8751e-02, -3.0641e-01,  1.4424e-01,\n",
       "           1.6525e-02,  1.3890e-01, -1.5429e-02,  1.3792e-02, -4.2829e-02,\n",
       "          -3.9400e-03,  1.3086e-03, -4.7647e-02,  2.6158e-01, -2.2109e-03,\n",
       "          -7.0468e-02, -2.4658e-01,  1.5197e-01, -4.6118e-02,  1.1080e-01,\n",
       "          -7.7560e-02, -2.5739e-01,  8.8851e-02, -2.9674e-01, -8.6632e-03,\n",
       "          -2.2422e-01,  6.9614e-02,  1.7933e-01,  1.0379e-01,  4.4420e-01,\n",
       "          -1.0694e-02,  1.4970e-01, -1.3592e-01, -2.1330e-02, -2.3462e-01,\n",
       "           1.7236e-01, -1.8547e-01,  1.5186e-01, -3.8921e-02,  9.7551e-03,\n",
       "           1.3722e-01, -2.8464e-02, -5.8139e-02, -2.0086e-01, -1.0827e-01,\n",
       "           3.0330e-02,  5.9977e-02, -5.8591e-02,  1.0616e-01,  1.7657e-01,\n",
       "          -5.2382e-03, -4.0846e-02, -2.0527e-02, -3.4073e-02, -4.5392e-03,\n",
       "          -9.0816e-02,  9.6659e-02,  9.4945e-02, -1.5327e-01,  1.7728e-01,\n",
       "          -6.1747e-02, -2.7566e-02,  1.6349e-01,  1.4505e-01,  1.4648e-01,\n",
       "           1.2433e-01, -6.1578e-02, -3.6812e-02,  1.2416e-02, -8.5562e-02,\n",
       "          -9.3672e-02,  9.9787e-02,  9.6789e-03, -1.0820e-01,  4.1684e-02,\n",
       "          -3.0618e-01, -1.0097e-01, -5.8382e-02,  4.5348e-02,  5.9468e-02,\n",
       "          -8.8423e-02,  2.5818e-02, -1.1199e-01,  1.1706e-01,  2.1020e-01,\n",
       "           2.2399e-01, -8.2607e-02,  1.1746e-01,  1.3426e-01, -6.2183e-02,\n",
       "           5.5279e-02, -1.6882e-01,  4.1184e-02,  1.3282e-01,  2.1334e-01,\n",
       "           1.7304e-01,  1.5342e-01, -1.2916e-01, -4.5416e-01, -1.7643e-02,\n",
       "          -6.8432e-03,  1.2076e-01,  2.6253e-01, -1.7486e-02,  9.3739e-03,\n",
       "          -4.7471e-02,  2.0128e-01, -6.5222e-02,  3.5771e-02, -5.0772e-02,\n",
       "           1.3092e-01, -2.3629e-01, -1.7986e-01,  1.0895e-02, -7.0472e-02,\n",
       "          -9.7265e-02,  9.7866e-02,  2.3022e-01,  6.2281e-02,  2.4687e-01,\n",
       "          -1.5817e-01,  3.9846e-02, -1.7029e-01, -2.8082e-01, -2.4245e-01,\n",
       "          -5.2097e-02,  5.8493e-02, -1.5058e-01,  2.6510e-02,  1.5070e-01,\n",
       "          -4.1589e-02,  3.1647e-01, -9.2586e-02, -7.4979e-02, -2.0697e-01,\n",
       "          -3.2137e-01, -1.3750e-01,  6.0359e-02, -1.7000e-01, -8.1845e-02,\n",
       "           5.3737e-02, -1.8009e-01]]], device='cuda:0',\n",
       "       grad_fn=<UnsqueezeBackward0>)"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#인코더 히든 레이어의 차원을 1개 더 추가\n",
    "# unsqueeze(1) : 1번째 차원 행을 1개 더 추가함\n",
    "encoder_hidden.unsqueeze(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "cabc5df6-098e-4dd6-94d9-7909e56581de",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 1, 512])"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoder_hidden.unsqueeze(1).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "28e67dc1-4f01-4e7d-b737-9a69f20e0821",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[-0.0267, -0.0285, -0.0221,  ..., -0.0818,  0.0537, -0.1801],\n",
       "         [-0.0267, -0.0285, -0.0221,  ..., -0.0818,  0.0537, -0.1801],\n",
       "         [-0.0267, -0.0285, -0.0221,  ..., -0.0818,  0.0537, -0.1801],\n",
       "         ...,\n",
       "         [-0.0267, -0.0285, -0.0221,  ..., -0.0818,  0.0537, -0.1801],\n",
       "         [-0.0267, -0.0285, -0.0221,  ..., -0.0818,  0.0537, -0.1801],\n",
       "         [-0.0267, -0.0285, -0.0221,  ..., -0.0818,  0.0537, -0.1801]]],\n",
       "       device='cuda:0', grad_fn=<RepeatBackward0>)"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#인코더 히든 레이어의 차원을 1개 더 추가\n",
    "# unsqueeze(1) : 1번쨰 차원 행을 1개 더 추가함\n",
    "\n",
    "#repeat(1, src_len, 1) : 데이터를 1개의 배열, src_len (240행) 으로 1번 반복\n",
    "encoder_hidden.unsqueeze(1).repeat(1,src_len,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "8284c3a8-2cbb-4e0e-b630-ef5f2df9a15f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 240, 512])"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoder_hidden.unsqueeze(1).repeat(1, src_len, 1).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "02d83688-8548-4076-9dcb-f13f57f10e5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#인코더 히든 레이어의 차원을 1개 더 추가\n",
    "# unsqueeze(1) : 1번째 차원 행을 1개 더 추가함\n",
    "\n",
    "#repeat(1, src_len, 1) : 데이터를 1개의 배열, src_len (240행) 으로 1번 반복\n",
    "\n",
    "att_encoder_hidden = encoder_hidden.unsqueeze(1).repeat(1, src_len, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "55e0e591-7d74-4261-bb74-8ac92976bb81",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 240, 512])"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "att_encoder_hidden.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "ef948547-ef49-448e-8f1d-ecf402e09adb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 240, 1024])"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoder_output.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "094279d6-afa7-4934-9da9-6a8bf72d1883",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[-0.0267, -0.0285, -0.0221,  ..., -0.1775,  0.1487,  0.0590],\n",
       "         [-0.0267, -0.0285, -0.0221,  ..., -0.1642,  0.1019, -0.0024],\n",
       "         [-0.0267, -0.0285, -0.0221,  ..., -0.1341, -0.0537,  0.0109],\n",
       "         ...,\n",
       "         [-0.0267, -0.0285, -0.0221,  ..., -0.0007, -0.1417,  0.0567],\n",
       "         [-0.0267, -0.0285, -0.0221,  ...,  0.0329, -0.2524,  0.0442],\n",
       "         [-0.0267, -0.0285, -0.0221,  ..., -0.0814, -0.2073, -0.0540]]],\n",
       "       device='cuda:0', grad_fn=<CatBackward0>)"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#att_encoder_hidden 과 encoder_output 을 1개읠 배열로 함침\n",
    "#dim = 2 : 열방향으로 합침\n",
    "torch.cat((att_encoder_hidden, encoder_output), dim = 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "cafc2c09-1ce0-4f45-bbf1-207c1c55e3fd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 240, 1536])"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cat((att_encoder_hidden, encoder_output), dim = 2).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "bf814ecb-7d5c-43cf-8b5f-fab607671291",
   "metadata": {},
   "outputs": [],
   "source": [
    "#선형 회귀 객체 생성\n",
    "attn = nn.Linear(\n",
    "    (HID_DIM * 2) + HID_DIM, #입력데이터의 열의 개수\n",
    "                             #HID_DIM (512) * 2 + HID_DIM =>\n",
    "    HID_DIM #선형회귀 결과의 열의 개수\n",
    ").cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "73ddbf98-6530-4d99-8d7f-143cc81e824c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Linear(in_features=1536, out_features=512, bias=True)"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "attn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "a5a3fa20-1b0e-4cd8-b8b0-cde6199baafa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[ 0.0089, -0.0350,  0.1939,  ..., -0.1087,  0.0033,  0.0291],\n",
       "         [ 0.1154, -0.0384,  0.1936,  ..., -0.0893,  0.0022, -0.0118],\n",
       "         [ 0.0059, -0.0305,  0.1054,  ..., -0.1971, -0.0171, -0.0673],\n",
       "         ...,\n",
       "         [-0.0661, -0.0791,  0.2208,  ..., -0.2602, -0.0220, -0.0919],\n",
       "         [-0.0526, -0.1507,  0.1672,  ..., -0.2168, -0.0561, -0.1017],\n",
       "         [-0.0170, -0.1074,  0.0828,  ..., -0.1872, -0.0725, -0.0667]]],\n",
       "       device='cuda:0', grad_fn=<ViewBackward0>)"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#att_encoder_hidden 과 encoder_output 을 1개의 배열로 합침\n",
    "#dim = 2 : 열방향으로 합침\n",
    "#torch.cat((att_encoder_hidden, encoder_output), dim = 2)\n",
    "\n",
    "#attn : 선형회귀 실행\n",
    "attn (torch.cat((att_encoder_hidden, encoder_output), dim = 2) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "f0e59270-6fba-40d3-acd4-759396648038",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[ 0.0089, -0.0350,  0.1915,  ..., -0.1083,  0.0033,  0.0291],\n",
       "         [ 0.1149, -0.0384,  0.1912,  ..., -0.0890,  0.0022, -0.0118],\n",
       "         [ 0.0059, -0.0305,  0.1050,  ..., -0.1946, -0.0171, -0.0672],\n",
       "         ...,\n",
       "         [-0.0660, -0.0789,  0.2172,  ..., -0.2545, -0.0220, -0.0917],\n",
       "         [-0.0525, -0.1495,  0.1657,  ..., -0.2134, -0.0560, -0.1013],\n",
       "         [-0.0170, -0.1070,  0.0826,  ..., -0.1850, -0.0724, -0.0666]]],\n",
       "       device='cuda:0', grad_fn=<TanhBackward0>)"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#att_encoder_hidden 과 encoder_output 을 1개의 배열로 합침\n",
    "#dim = 2 : 열방향으로 합침\n",
    "#torch.cat((att_encoder_hidden, encoder_output), dim = 2)\n",
    "\n",
    "#attn : 선형회귀 실행\n",
    "#attn (torch.cat((att_encoder_hidden, encoder_output), dim = 2) )\n",
    "\n",
    "#torch.tanh : tanh 활성함수 실행\n",
    "torch.tanh( attn (torch.cat((att_encoder_hidden, encoder_output), dim = 2) ) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "df1aea70-1f63-4791-a85f-7ec82e444b5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#att_encoder_hidden 과 encoder_output 을 1개의 배열로 합침\n",
    "#dim = 2 : 열방향으로 합침\n",
    "#torch.cat((att_encoder_hidden, encoder_output), dim = 2)\n",
    "\n",
    "#attn : 선형회귀 실행\n",
    "#attn (torch.cat((att_encoder_hidden, encoder_output), dim = 2) )\n",
    "\n",
    "#torch.tanh : tanh 활성함수 실행\n",
    "\n",
    "\n",
    "energy = torch.tanh( attn (torch.cat((att_encoder_hidden, encoder_output), dim = 2) ) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "95fa3b62-2ed3-44d8-946f-3e22377d69ed",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[ 0.0089, -0.0350,  0.1915,  ..., -0.1083,  0.0033,  0.0291],\n",
       "         [ 0.1149, -0.0384,  0.1912,  ..., -0.0890,  0.0022, -0.0118],\n",
       "         [ 0.0059, -0.0305,  0.1050,  ..., -0.1946, -0.0171, -0.0672],\n",
       "         ...,\n",
       "         [-0.0660, -0.0789,  0.2172,  ..., -0.2545, -0.0220, -0.0917],\n",
       "         [-0.0525, -0.1495,  0.1657,  ..., -0.2134, -0.0560, -0.1013],\n",
       "         [-0.0170, -0.1070,  0.0826,  ..., -0.1850, -0.0724, -0.0666]]],\n",
       "       device='cuda:0', grad_fn=<TanhBackward0>)"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "energy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "55aeccd3-6559-4a74-92b2-a42e3e4819e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#선형회귀 객체 선언\n",
    "v = nn.Linear(\n",
    "    HID_DIM, #입력데이터의 열의 개수 (HID_DIM : 512)\n",
    "    1, #출력데이터 열의 개수\n",
    "    bias = False #선형회귀시 더하기 bias사용안함\n",
    ").cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "9249efa7-829c-440c-9161-22159f6d95e1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[ 0.0022],\n",
       "         [-0.0129],\n",
       "         [ 0.0008],\n",
       "         [ 0.0263],\n",
       "         [ 0.0037],\n",
       "         [ 0.0347],\n",
       "         [ 0.0330],\n",
       "         [ 0.0526],\n",
       "         [ 0.1041],\n",
       "         [ 0.0542],\n",
       "         [ 0.0639],\n",
       "         [ 0.0347],\n",
       "         [ 0.0766],\n",
       "         [ 0.0545],\n",
       "         [ 0.0643],\n",
       "         [ 0.0289],\n",
       "         [-0.0072],\n",
       "         [ 0.0228],\n",
       "         [ 0.0083],\n",
       "         [ 0.0314],\n",
       "         [ 0.0419],\n",
       "         [ 0.0290],\n",
       "         [ 0.0205],\n",
       "         [ 0.0332],\n",
       "         [ 0.0112],\n",
       "         [-0.0021],\n",
       "         [-0.0325],\n",
       "         [-0.0346],\n",
       "         [-0.0027],\n",
       "         [-0.0340],\n",
       "         [ 0.0015],\n",
       "         [ 0.0071],\n",
       "         [-0.0335],\n",
       "         [ 0.0045],\n",
       "         [-0.0110],\n",
       "         [-0.0080],\n",
       "         [ 0.0413],\n",
       "         [ 0.0320],\n",
       "         [ 0.0911],\n",
       "         [ 0.0741],\n",
       "         [ 0.0520],\n",
       "         [-0.0186],\n",
       "         [-0.0191],\n",
       "         [-0.0210],\n",
       "         [ 0.0357],\n",
       "         [ 0.0684],\n",
       "         [ 0.0357],\n",
       "         [ 0.0196],\n",
       "         [ 0.0118],\n",
       "         [-0.0041],\n",
       "         [ 0.0092],\n",
       "         [ 0.0516],\n",
       "         [ 0.0495],\n",
       "         [ 0.0897],\n",
       "         [ 0.0837],\n",
       "         [ 0.0559],\n",
       "         [-0.0250],\n",
       "         [ 0.0130],\n",
       "         [-0.0282],\n",
       "         [-0.0134],\n",
       "         [-0.0111],\n",
       "         [ 0.0249],\n",
       "         [ 0.0029],\n",
       "         [ 0.0363],\n",
       "         [ 0.0364],\n",
       "         [ 0.0693],\n",
       "         [ 0.0309],\n",
       "         [ 0.0491],\n",
       "         [ 0.0782],\n",
       "         [ 0.0038],\n",
       "         [ 0.0157],\n",
       "         [ 0.0278],\n",
       "         [ 0.0558],\n",
       "         [ 0.0895],\n",
       "         [ 0.0657],\n",
       "         [ 0.0640],\n",
       "         [ 0.0240],\n",
       "         [ 0.0372],\n",
       "         [ 0.0382],\n",
       "         [ 0.0355],\n",
       "         [ 0.0412],\n",
       "         [ 0.0334],\n",
       "         [ 0.0348],\n",
       "         [ 0.0258],\n",
       "         [ 0.0152],\n",
       "         [ 0.0204],\n",
       "         [ 0.0016],\n",
       "         [ 0.0653],\n",
       "         [-0.0107],\n",
       "         [-0.0272],\n",
       "         [-0.0196],\n",
       "         [ 0.0014],\n",
       "         [ 0.0108],\n",
       "         [-0.0167],\n",
       "         [ 0.0207],\n",
       "         [ 0.0453],\n",
       "         [-0.0465],\n",
       "         [-0.0224],\n",
       "         [-0.0346],\n",
       "         [-0.0719],\n",
       "         [-0.0231],\n",
       "         [ 0.0109],\n",
       "         [ 0.0257],\n",
       "         [ 0.0210],\n",
       "         [-0.0084],\n",
       "         [ 0.0648],\n",
       "         [ 0.0461],\n",
       "         [ 0.0170],\n",
       "         [ 0.0209],\n",
       "         [ 0.0130],\n",
       "         [-0.0193],\n",
       "         [-0.0176],\n",
       "         [ 0.0125],\n",
       "         [-0.0098],\n",
       "         [-0.0030],\n",
       "         [ 0.0210],\n",
       "         [ 0.0047],\n",
       "         [-0.0172],\n",
       "         [ 0.0141],\n",
       "         [ 0.0093],\n",
       "         [-0.0163],\n",
       "         [-0.0127],\n",
       "         [ 0.0121],\n",
       "         [ 0.0070],\n",
       "         [ 0.0373],\n",
       "         [ 0.0621],\n",
       "         [ 0.0573],\n",
       "         [ 0.0068],\n",
       "         [ 0.0647],\n",
       "         [ 0.0681],\n",
       "         [ 0.0573],\n",
       "         [ 0.0118],\n",
       "         [ 0.0142],\n",
       "         [-0.0086],\n",
       "         [ 0.0010],\n",
       "         [ 0.0097],\n",
       "         [ 0.0310],\n",
       "         [ 0.0116],\n",
       "         [ 0.0221],\n",
       "         [ 0.0063],\n",
       "         [ 0.0131],\n",
       "         [ 0.0191],\n",
       "         [ 0.0355],\n",
       "         [ 0.0114],\n",
       "         [ 0.0104],\n",
       "         [ 0.0230],\n",
       "         [ 0.0225],\n",
       "         [ 0.0333],\n",
       "         [ 0.0076],\n",
       "         [ 0.0353],\n",
       "         [-0.0609],\n",
       "         [-0.0619],\n",
       "         [-0.0316],\n",
       "         [-0.0072],\n",
       "         [ 0.0183],\n",
       "         [ 0.0309],\n",
       "         [-0.0044],\n",
       "         [-0.0223],\n",
       "         [-0.0338],\n",
       "         [ 0.0153],\n",
       "         [ 0.0304],\n",
       "         [-0.0286],\n",
       "         [ 0.0113],\n",
       "         [-0.0291],\n",
       "         [ 0.0153],\n",
       "         [ 0.0617],\n",
       "         [ 0.0427],\n",
       "         [ 0.0043],\n",
       "         [ 0.0125],\n",
       "         [-0.0031],\n",
       "         [-0.0164],\n",
       "         [-0.0456],\n",
       "         [-0.0170],\n",
       "         [-0.0214],\n",
       "         [ 0.0035],\n",
       "         [ 0.0023],\n",
       "         [-0.0068],\n",
       "         [ 0.0346],\n",
       "         [ 0.0503],\n",
       "         [ 0.0487],\n",
       "         [ 0.0520],\n",
       "         [-0.0074],\n",
       "         [-0.0268],\n",
       "         [ 0.0104],\n",
       "         [ 0.0118],\n",
       "         [-0.0082],\n",
       "         [-0.0033],\n",
       "         [-0.0710],\n",
       "         [-0.0249],\n",
       "         [-0.0121],\n",
       "         [-0.0138],\n",
       "         [-0.0210],\n",
       "         [ 0.0318],\n",
       "         [ 0.0218],\n",
       "         [ 0.0336],\n",
       "         [ 0.0122],\n",
       "         [-0.0277],\n",
       "         [-0.0311],\n",
       "         [-0.0583],\n",
       "         [-0.0322],\n",
       "         [-0.0239],\n",
       "         [ 0.0554],\n",
       "         [ 0.0379],\n",
       "         [ 0.0157],\n",
       "         [ 0.0029],\n",
       "         [-0.0024],\n",
       "         [ 0.0886],\n",
       "         [ 0.0518],\n",
       "         [ 0.0362],\n",
       "         [-0.0121],\n",
       "         [ 0.0085],\n",
       "         [ 0.0141],\n",
       "         [-0.0130],\n",
       "         [-0.0435],\n",
       "         [-0.0085],\n",
       "         [ 0.0167],\n",
       "         [ 0.0083],\n",
       "         [-0.0017],\n",
       "         [-0.0136],\n",
       "         [ 0.0116],\n",
       "         [ 0.0283],\n",
       "         [ 0.0761],\n",
       "         [ 0.0490],\n",
       "         [ 0.0661],\n",
       "         [ 0.0378],\n",
       "         [ 0.0308],\n",
       "         [ 0.0708],\n",
       "         [ 0.0417],\n",
       "         [ 0.0290],\n",
       "         [-0.0107],\n",
       "         [ 0.0286],\n",
       "         [ 0.0004],\n",
       "         [ 0.0220],\n",
       "         [ 0.0348],\n",
       "         [ 0.0074],\n",
       "         [ 0.0653],\n",
       "         [ 0.0516],\n",
       "         [ 0.0621],\n",
       "         [ 0.0075],\n",
       "         [ 0.0125]]], device='cuda:0', grad_fn=<UnsafeViewBackward0>)"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "v(energy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "a56c500a-7447-41b5-9c30-d8c6181d547c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 240, 1])"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "v(energy).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "84b3d811-d25d-4f27-b881-326618b5b124",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.0022, -0.0129,  0.0008,  0.0263,  0.0037,  0.0347,  0.0330,  0.0526,\n",
       "          0.1041,  0.0542,  0.0639,  0.0347,  0.0766,  0.0545,  0.0643,  0.0289,\n",
       "         -0.0072,  0.0228,  0.0083,  0.0314,  0.0419,  0.0290,  0.0205,  0.0332,\n",
       "          0.0112, -0.0021, -0.0325, -0.0346, -0.0027, -0.0340,  0.0015,  0.0071,\n",
       "         -0.0335,  0.0045, -0.0110, -0.0080,  0.0413,  0.0320,  0.0911,  0.0741,\n",
       "          0.0520, -0.0186, -0.0191, -0.0210,  0.0357,  0.0684,  0.0357,  0.0196,\n",
       "          0.0118, -0.0041,  0.0092,  0.0516,  0.0495,  0.0897,  0.0837,  0.0559,\n",
       "         -0.0250,  0.0130, -0.0282, -0.0134, -0.0111,  0.0249,  0.0029,  0.0363,\n",
       "          0.0364,  0.0693,  0.0309,  0.0491,  0.0782,  0.0038,  0.0157,  0.0278,\n",
       "          0.0558,  0.0895,  0.0657,  0.0640,  0.0240,  0.0372,  0.0382,  0.0355,\n",
       "          0.0412,  0.0334,  0.0348,  0.0258,  0.0152,  0.0204,  0.0016,  0.0653,\n",
       "         -0.0107, -0.0272, -0.0196,  0.0014,  0.0108, -0.0167,  0.0207,  0.0453,\n",
       "         -0.0465, -0.0224, -0.0346, -0.0719, -0.0231,  0.0109,  0.0257,  0.0210,\n",
       "         -0.0084,  0.0648,  0.0461,  0.0170,  0.0209,  0.0130, -0.0193, -0.0176,\n",
       "          0.0125, -0.0098, -0.0030,  0.0210,  0.0047, -0.0172,  0.0141,  0.0093,\n",
       "         -0.0163, -0.0127,  0.0121,  0.0070,  0.0373,  0.0621,  0.0573,  0.0068,\n",
       "          0.0647,  0.0681,  0.0573,  0.0118,  0.0142, -0.0086,  0.0010,  0.0097,\n",
       "          0.0310,  0.0116,  0.0221,  0.0063,  0.0131,  0.0191,  0.0355,  0.0114,\n",
       "          0.0104,  0.0230,  0.0225,  0.0333,  0.0076,  0.0353, -0.0609, -0.0619,\n",
       "         -0.0316, -0.0072,  0.0183,  0.0309, -0.0044, -0.0223, -0.0338,  0.0153,\n",
       "          0.0304, -0.0286,  0.0113, -0.0291,  0.0153,  0.0617,  0.0427,  0.0043,\n",
       "          0.0125, -0.0031, -0.0164, -0.0456, -0.0170, -0.0214,  0.0035,  0.0023,\n",
       "         -0.0068,  0.0346,  0.0503,  0.0487,  0.0520, -0.0074, -0.0268,  0.0104,\n",
       "          0.0118, -0.0082, -0.0033, -0.0710, -0.0249, -0.0121, -0.0138, -0.0210,\n",
       "          0.0318,  0.0218,  0.0336,  0.0122, -0.0277, -0.0311, -0.0583, -0.0322,\n",
       "         -0.0239,  0.0554,  0.0379,  0.0157,  0.0029, -0.0024,  0.0886,  0.0518,\n",
       "          0.0362, -0.0121,  0.0085,  0.0141, -0.0130, -0.0435, -0.0085,  0.0167,\n",
       "          0.0083, -0.0017, -0.0136,  0.0116,  0.0283,  0.0761,  0.0490,  0.0661,\n",
       "          0.0378,  0.0308,  0.0708,  0.0417,  0.0290, -0.0107,  0.0286,  0.0004,\n",
       "          0.0220,  0.0348,  0.0074,  0.0653,  0.0516,  0.0621,  0.0075,  0.0125]],\n",
       "       device='cuda:0', grad_fn=<SqueezeBackward1>)"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#선형회귀 실행\n",
    "#v(energy)\n",
    "\n",
    "#squeeze(2) : 3차원 배열인 v(energy)\n",
    "# 차원을 1개 축소시켜 2차원 배열로 변환\n",
    "# 2번쨰 차원 열을 삭제\n",
    "v(energy).squeeze(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "09ee1e53-c122-4ac4-be1f-54c03e825f4a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 240])"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#선형회귀 실행\n",
    "#v(energy)\n",
    "\n",
    "#squeeze(2) : 3차원 배열인 v(energy)\n",
    "# 차원을 1개 축소시켜 2차원 배열로 변환\n",
    "# 2번쨰 차원 열을 삭제\n",
    "v(energy).squeeze(2).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "b8381a73-ee47-4d33-956a-77e1db6972f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#선형회귀 실행\n",
    "#v(energy)\n",
    "\n",
    "#squeeze(2) : 3차원 배열인 v(energy)\n",
    "# 차원을 1개 축소시켜 2차원 배열로 변환\n",
    "# 2번쨰 차원 열을 삭제\n",
    "\n",
    "attention_output = v(energy).squeeze(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "50ef837f-3387-4a79-bce5-1f70c362568f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.0022, -0.0129,  0.0008,  0.0263,  0.0037,  0.0347,  0.0330,  0.0526,\n",
       "          0.1041,  0.0542,  0.0639,  0.0347,  0.0766,  0.0545,  0.0643,  0.0289,\n",
       "         -0.0072,  0.0228,  0.0083,  0.0314,  0.0419,  0.0290,  0.0205,  0.0332,\n",
       "          0.0112, -0.0021, -0.0325, -0.0346, -0.0027, -0.0340,  0.0015,  0.0071,\n",
       "         -0.0335,  0.0045, -0.0110, -0.0080,  0.0413,  0.0320,  0.0911,  0.0741,\n",
       "          0.0520, -0.0186, -0.0191, -0.0210,  0.0357,  0.0684,  0.0357,  0.0196,\n",
       "          0.0118, -0.0041,  0.0092,  0.0516,  0.0495,  0.0897,  0.0837,  0.0559,\n",
       "         -0.0250,  0.0130, -0.0282, -0.0134, -0.0111,  0.0249,  0.0029,  0.0363,\n",
       "          0.0364,  0.0693,  0.0309,  0.0491,  0.0782,  0.0038,  0.0157,  0.0278,\n",
       "          0.0558,  0.0895,  0.0657,  0.0640,  0.0240,  0.0372,  0.0382,  0.0355,\n",
       "          0.0412,  0.0334,  0.0348,  0.0258,  0.0152,  0.0204,  0.0016,  0.0653,\n",
       "         -0.0107, -0.0272, -0.0196,  0.0014,  0.0108, -0.0167,  0.0207,  0.0453,\n",
       "         -0.0465, -0.0224, -0.0346, -0.0719, -0.0231,  0.0109,  0.0257,  0.0210,\n",
       "         -0.0084,  0.0648,  0.0461,  0.0170,  0.0209,  0.0130, -0.0193, -0.0176,\n",
       "          0.0125, -0.0098, -0.0030,  0.0210,  0.0047, -0.0172,  0.0141,  0.0093,\n",
       "         -0.0163, -0.0127,  0.0121,  0.0070,  0.0373,  0.0621,  0.0573,  0.0068,\n",
       "          0.0647,  0.0681,  0.0573,  0.0118,  0.0142, -0.0086,  0.0010,  0.0097,\n",
       "          0.0310,  0.0116,  0.0221,  0.0063,  0.0131,  0.0191,  0.0355,  0.0114,\n",
       "          0.0104,  0.0230,  0.0225,  0.0333,  0.0076,  0.0353, -0.0609, -0.0619,\n",
       "         -0.0316, -0.0072,  0.0183,  0.0309, -0.0044, -0.0223, -0.0338,  0.0153,\n",
       "          0.0304, -0.0286,  0.0113, -0.0291,  0.0153,  0.0617,  0.0427,  0.0043,\n",
       "          0.0125, -0.0031, -0.0164, -0.0456, -0.0170, -0.0214,  0.0035,  0.0023,\n",
       "         -0.0068,  0.0346,  0.0503,  0.0487,  0.0520, -0.0074, -0.0268,  0.0104,\n",
       "          0.0118, -0.0082, -0.0033, -0.0710, -0.0249, -0.0121, -0.0138, -0.0210,\n",
       "          0.0318,  0.0218,  0.0336,  0.0122, -0.0277, -0.0311, -0.0583, -0.0322,\n",
       "         -0.0239,  0.0554,  0.0379,  0.0157,  0.0029, -0.0024,  0.0886,  0.0518,\n",
       "          0.0362, -0.0121,  0.0085,  0.0141, -0.0130, -0.0435, -0.0085,  0.0167,\n",
       "          0.0083, -0.0017, -0.0136,  0.0116,  0.0283,  0.0761,  0.0490,  0.0661,\n",
       "          0.0378,  0.0308,  0.0708,  0.0417,  0.0290, -0.0107,  0.0286,  0.0004,\n",
       "          0.0220,  0.0348,  0.0074,  0.0653,  0.0516,  0.0621,  0.0075,  0.0125]],\n",
       "       device='cuda:0', grad_fn=<SqueezeBackward1>)"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "attention_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "a3efb1e2-2dad-4cdb-9f33-ab7b6bd40291",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.0041, 0.0040, 0.0041, 0.0042, 0.0041, 0.0042, 0.0042, 0.0043, 0.0045,\n",
       "         0.0043, 0.0044, 0.0042, 0.0044, 0.0043, 0.0044, 0.0042, 0.0041, 0.0042,\n",
       "         0.0041, 0.0042, 0.0043, 0.0042, 0.0042, 0.0042, 0.0041, 0.0041, 0.0040,\n",
       "         0.0040, 0.0041, 0.0040, 0.0041, 0.0041, 0.0040, 0.0041, 0.0041, 0.0041,\n",
       "         0.0043, 0.0042, 0.0045, 0.0044, 0.0043, 0.0040, 0.0040, 0.0040, 0.0042,\n",
       "         0.0044, 0.0042, 0.0042, 0.0041, 0.0041, 0.0041, 0.0043, 0.0043, 0.0045,\n",
       "         0.0045, 0.0043, 0.0040, 0.0042, 0.0040, 0.0040, 0.0041, 0.0042, 0.0041,\n",
       "         0.0043, 0.0043, 0.0044, 0.0042, 0.0043, 0.0044, 0.0041, 0.0042, 0.0042,\n",
       "         0.0043, 0.0045, 0.0044, 0.0044, 0.0042, 0.0043, 0.0043, 0.0042, 0.0043,\n",
       "         0.0042, 0.0042, 0.0042, 0.0042, 0.0042, 0.0041, 0.0044, 0.0041, 0.0040,\n",
       "         0.0040, 0.0041, 0.0041, 0.0040, 0.0042, 0.0043, 0.0039, 0.0040, 0.0040,\n",
       "         0.0038, 0.0040, 0.0041, 0.0042, 0.0042, 0.0041, 0.0044, 0.0043, 0.0042,\n",
       "         0.0042, 0.0042, 0.0040, 0.0040, 0.0042, 0.0041, 0.0041, 0.0042, 0.0041,\n",
       "         0.0040, 0.0042, 0.0041, 0.0040, 0.0040, 0.0041, 0.0041, 0.0043, 0.0044,\n",
       "         0.0043, 0.0041, 0.0044, 0.0044, 0.0043, 0.0041, 0.0042, 0.0041, 0.0041,\n",
       "         0.0041, 0.0042, 0.0041, 0.0042, 0.0041, 0.0042, 0.0042, 0.0042, 0.0041,\n",
       "         0.0041, 0.0042, 0.0042, 0.0042, 0.0041, 0.0042, 0.0039, 0.0039, 0.0040,\n",
       "         0.0041, 0.0042, 0.0042, 0.0041, 0.0040, 0.0040, 0.0042, 0.0042, 0.0040,\n",
       "         0.0041, 0.0040, 0.0042, 0.0044, 0.0043, 0.0041, 0.0042, 0.0041, 0.0040,\n",
       "         0.0039, 0.0040, 0.0040, 0.0041, 0.0041, 0.0041, 0.0042, 0.0043, 0.0043,\n",
       "         0.0043, 0.0041, 0.0040, 0.0041, 0.0041, 0.0041, 0.0041, 0.0038, 0.0040,\n",
       "         0.0040, 0.0040, 0.0040, 0.0042, 0.0042, 0.0042, 0.0041, 0.0040, 0.0040,\n",
       "         0.0039, 0.0040, 0.0040, 0.0043, 0.0043, 0.0042, 0.0041, 0.0041, 0.0045,\n",
       "         0.0043, 0.0043, 0.0040, 0.0041, 0.0042, 0.0040, 0.0039, 0.0041, 0.0042,\n",
       "         0.0041, 0.0041, 0.0040, 0.0041, 0.0042, 0.0044, 0.0043, 0.0044, 0.0043,\n",
       "         0.0042, 0.0044, 0.0043, 0.0042, 0.0041, 0.0042, 0.0041, 0.0042, 0.0042,\n",
       "         0.0041, 0.0044, 0.0043, 0.0044, 0.0041, 0.0042]], device='cuda:0',\n",
       "       grad_fn=<SoftmaxBackward0>)"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#F.softmax() 활성함수 실행\n",
    "F.softmax(attention_output, dim = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "d70a78f9-3bf3-40cd-aa01-5453292bb3c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#F.softmax() 활성함수 실행\n",
    "attention_output = F.softmax(attention_output, dim = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "20ca38d5-35c0-4109-b881-71dda73d3676",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.0041, 0.0040, 0.0041, 0.0042, 0.0041, 0.0042, 0.0042, 0.0043, 0.0045,\n",
       "         0.0043, 0.0044, 0.0042, 0.0044, 0.0043, 0.0044, 0.0042, 0.0041, 0.0042,\n",
       "         0.0041, 0.0042, 0.0043, 0.0042, 0.0042, 0.0042, 0.0041, 0.0041, 0.0040,\n",
       "         0.0040, 0.0041, 0.0040, 0.0041, 0.0041, 0.0040, 0.0041, 0.0041, 0.0041,\n",
       "         0.0043, 0.0042, 0.0045, 0.0044, 0.0043, 0.0040, 0.0040, 0.0040, 0.0042,\n",
       "         0.0044, 0.0042, 0.0042, 0.0041, 0.0041, 0.0041, 0.0043, 0.0043, 0.0045,\n",
       "         0.0045, 0.0043, 0.0040, 0.0042, 0.0040, 0.0040, 0.0041, 0.0042, 0.0041,\n",
       "         0.0043, 0.0043, 0.0044, 0.0042, 0.0043, 0.0044, 0.0041, 0.0042, 0.0042,\n",
       "         0.0043, 0.0045, 0.0044, 0.0044, 0.0042, 0.0043, 0.0043, 0.0042, 0.0043,\n",
       "         0.0042, 0.0042, 0.0042, 0.0042, 0.0042, 0.0041, 0.0044, 0.0041, 0.0040,\n",
       "         0.0040, 0.0041, 0.0041, 0.0040, 0.0042, 0.0043, 0.0039, 0.0040, 0.0040,\n",
       "         0.0038, 0.0040, 0.0041, 0.0042, 0.0042, 0.0041, 0.0044, 0.0043, 0.0042,\n",
       "         0.0042, 0.0042, 0.0040, 0.0040, 0.0042, 0.0041, 0.0041, 0.0042, 0.0041,\n",
       "         0.0040, 0.0042, 0.0041, 0.0040, 0.0040, 0.0041, 0.0041, 0.0043, 0.0044,\n",
       "         0.0043, 0.0041, 0.0044, 0.0044, 0.0043, 0.0041, 0.0042, 0.0041, 0.0041,\n",
       "         0.0041, 0.0042, 0.0041, 0.0042, 0.0041, 0.0042, 0.0042, 0.0042, 0.0041,\n",
       "         0.0041, 0.0042, 0.0042, 0.0042, 0.0041, 0.0042, 0.0039, 0.0039, 0.0040,\n",
       "         0.0041, 0.0042, 0.0042, 0.0041, 0.0040, 0.0040, 0.0042, 0.0042, 0.0040,\n",
       "         0.0041, 0.0040, 0.0042, 0.0044, 0.0043, 0.0041, 0.0042, 0.0041, 0.0040,\n",
       "         0.0039, 0.0040, 0.0040, 0.0041, 0.0041, 0.0041, 0.0042, 0.0043, 0.0043,\n",
       "         0.0043, 0.0041, 0.0040, 0.0041, 0.0041, 0.0041, 0.0041, 0.0038, 0.0040,\n",
       "         0.0040, 0.0040, 0.0040, 0.0042, 0.0042, 0.0042, 0.0041, 0.0040, 0.0040,\n",
       "         0.0039, 0.0040, 0.0040, 0.0043, 0.0043, 0.0042, 0.0041, 0.0041, 0.0045,\n",
       "         0.0043, 0.0043, 0.0040, 0.0041, 0.0042, 0.0040, 0.0039, 0.0041, 0.0042,\n",
       "         0.0041, 0.0041, 0.0040, 0.0041, 0.0042, 0.0044, 0.0043, 0.0044, 0.0043,\n",
       "         0.0042, 0.0044, 0.0043, 0.0042, 0.0041, 0.0042, 0.0041, 0.0042, 0.0042,\n",
       "         0.0041, 0.0044, 0.0043, 0.0044, 0.0041, 0.0042]], device='cuda:0',\n",
       "       grad_fn=<SoftmaxBackward0>)"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "attention_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "5a5f7d1e-0dad-47f3-a9c1-af1e83d4e735",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 240])"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "attention_output.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "9911a4bf-f32d-4947-b491-4cad6658b73b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Attention을 클래스로 구현\n",
    "\n",
    "class Attention(nn.Module):\n",
    "    def __init__(self, hid_dim):\n",
    "        super().__init__()\n",
    "\n",
    "        self.attn = nn.Linear((hid_dim * 2) + hid_dim, hid_dim)\n",
    "        self.v = nn.Linear(hid_dim, 1, bias = False)\n",
    "\n",
    "    def forward(self, hidden, encoder_output):\n",
    "\n",
    "        batch_size = encoder_output.shape[0]\n",
    "        src_len = encoder_output.shape[1]\n",
    "        hidden = hidden.unsqueeze(1).repeat(1, src_len, 1)\n",
    "        energy = torch.tanh(self.attn(torch.cat((hidden, encoder_output), dim = 2)))\n",
    "\n",
    "        attention = self.v(energy).squeeze(2)\n",
    "        return F.softmax(attention, dim = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "87ac973d-586d-476c-bf00-e478711ac452",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[  1, 103, 736,  ...,   0,   0,   0],\n",
       "        [  1, 505, 305,  ...,   0,   0,   0],\n",
       "        [  1, 484, 448,  ...,   0,   0,   0],\n",
       "        ...,\n",
       "        [  1, 403, 143,  ...,   0,   0,   0],\n",
       "        [  1, 403, 123,  ..., 529, 453,   2],\n",
       "        [  1, 403, 123,  ...,   0,   0,   0]], dtype=torch.int32)"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#수어번역결과\n",
    "y_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "7b0cfc0a-8418-4fec-bbff-bc139cab761e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([720], dtype=torch.int32)"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#수어 번역결과 38 => \"부지역\"\n",
    "y_data[0][3:4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "ceb950f9-e5a7-45fe-9b9a-59d97448630f",
   "metadata": {},
   "outputs": [],
   "source": [
    "input = y_data[0][3:4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "d3349459-0ec8-4713-b6a8-9526dfffc9fc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([720], dtype=torch.int32)"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "7ec6a985-526b-4b8f-890b-74e289a2608c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[720]], dtype=torch.int32)"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#input의 차원을 1개 늘려서 2차원으로 변환\n",
    "#unsqueeze(0) : 0번째 차원 행을 1개 추가\n",
    "input.unsqueeze(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "eb2318a1-5b40-468e-b808-0ae01e01af12",
   "metadata": {},
   "outputs": [],
   "source": [
    "#input의 차원을 1개 늘려서 2차원으로 변환\n",
    "#unsqueeze(0) : 0번째 차원 행을 1개 추가\n",
    "#input.unsqueeze(0)\n",
    "\n",
    "input = input.unsqueeze(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "900790ba-9202-40f8-b638-f8d3abb4569a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[720]], dtype=torch.int32)"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "970b793f-5470-453a-ab02-b1c04f24eb91",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 1])"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "d9a2474b-e3dc-4dbf-8038-c62cba10d35d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1078"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "OUTPUT_DIM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "fb8e7e94-2dd0-4e02-8ae0-c119f1c8bf59",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "128"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "EMB_DIM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "7e30659a-1044-4ac1-8c2e-027a2af667b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#nn.Embedding : 수어 번역 단어를 입력으로 단어의 특성을 잘 표현하는 배열을 생성하는 객체\n",
    "embedding = nn.Embedding(\n",
    "    OUTPUT_DIM, #번역할 수어 단어의 종류개수\n",
    "    EMB_DIM #Embedding 결과 열의 개수\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "7bc7af18-1115-463c-a687-5c801605584a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Embedding(1078, 128)"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "ebf1a1ad-c23e-41c1-b38f-056257a77be2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[-0.1419,  1.0665,  1.8103,  0.9215, -0.3699, -0.3985,  0.5305,\n",
       "          -0.9677,  0.1530, -0.5210,  0.8421, -1.9539, -0.4675,  0.7059,\n",
       "           0.5563,  1.9950,  0.2280,  0.6944,  0.4038, -1.4784,  0.1829,\n",
       "          -0.1135, -0.7106,  0.3231,  1.1481,  0.2314, -1.4081, -1.3473,\n",
       "           0.4470, -1.5788,  0.0310, -0.4250,  0.0878,  0.0913,  1.8632,\n",
       "           0.7942, -0.8224, -0.2114,  0.4836,  0.3305,  1.0909, -0.6224,\n",
       "          -1.2750,  1.1412, -0.4788, -1.1304,  1.7502, -0.7665,  0.0974,\n",
       "           1.2215,  0.4477, -0.1316,  0.4656, -1.6697, -0.9317, -1.6635,\n",
       "           0.6694,  1.0785, -1.2680, -0.9164,  1.0590, -0.5228, -0.8256,\n",
       "          -0.4428,  1.2043, -0.3686, -0.9278, -1.0731, -0.8064,  0.2029,\n",
       "           0.0444,  0.4846,  0.5846,  1.0107,  0.6770,  1.2714,  0.6559,\n",
       "           0.1976,  0.5915,  0.3368, -0.5658,  2.0398,  1.3629,  2.0164,\n",
       "           0.2637,  0.9488, -0.5347,  0.6231, -2.0867, -1.0632,  0.3333,\n",
       "          -0.8872,  0.4860, -0.9380, -0.3168,  0.5204,  0.1637, -0.8543,\n",
       "           0.2151, -0.1241,  0.6308,  0.1104, -0.2122, -0.2911, -0.0781,\n",
       "           0.4206,  0.8024, -0.5445,  0.3791, -0.6482,  1.6137, -0.5102,\n",
       "          -1.8636,  0.6636, -0.2115,  0.6226, -0.8598, -0.1015, -0.6600,\n",
       "          -0.8382, -0.7758,  0.1411, -0.0575, -0.0231,  0.3800, -1.3470,\n",
       "           0.7497, -0.5403]]], grad_fn=<EmbeddingBackward0>)"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embedding(input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "baf70d13-3ecc-476d-ba42-6cf17b5d0683",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 1, 128])"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embedding(input).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "d8a717ea-5550-4be0-ab33-cb90bb766b11",
   "metadata": {},
   "outputs": [],
   "source": [
    "#드롭아웃을 실행할 객체 생성\n",
    "dropout = nn.Dropout(0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "028743a6-0974-4d55-895f-f50fe29dd19c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[-0.2838,  2.1331,  3.6205,  0.0000, -0.0000, -0.7969,  0.0000,\n",
       "          -0.0000,  0.3059, -0.0000,  1.6841, -0.0000, -0.0000,  0.0000,\n",
       "           0.0000,  3.9900,  0.4560,  0.0000,  0.0000, -2.9568,  0.0000,\n",
       "          -0.0000, -1.4211,  0.0000,  2.2962,  0.0000, -2.8163, -2.6946,\n",
       "           0.8940, -3.1577,  0.0000, -0.8500,  0.0000,  0.1826,  3.7263,\n",
       "           0.0000, -1.6448, -0.0000,  0.9672,  0.0000,  2.1818, -0.0000,\n",
       "          -0.0000,  0.0000, -0.9576, -0.0000,  3.5003, -1.5331,  0.1948,\n",
       "           0.0000,  0.0000, -0.0000,  0.0000, -0.0000, -0.0000, -3.3269,\n",
       "           0.0000,  0.0000, -0.0000, -1.8327,  2.1179, -0.0000, -1.6512,\n",
       "          -0.0000,  0.0000, -0.0000, -1.8556, -2.1463, -1.6128,  0.4058,\n",
       "           0.0000,  0.9693,  0.0000,  0.0000,  1.3541,  0.0000,  0.0000,\n",
       "           0.0000,  1.1830,  0.0000, -0.0000,  0.0000,  2.7259,  0.0000,\n",
       "           0.0000,  1.8977, -1.0695,  0.0000, -4.1733, -2.1265,  0.0000,\n",
       "          -1.7744,  0.0000, -0.0000, -0.0000,  1.0409,  0.0000, -1.7085,\n",
       "           0.4302, -0.0000,  1.2615,  0.0000, -0.4245, -0.0000, -0.1563,\n",
       "           0.8412,  1.6048, -1.0889,  0.0000, -1.2963,  0.0000, -0.0000,\n",
       "          -0.0000,  1.3273, -0.0000,  0.0000, -1.7196, -0.2031, -1.3200,\n",
       "          -1.6764, -1.5516,  0.2822, -0.1149, -0.0000,  0.0000, -2.6939,\n",
       "           0.0000, -0.0000]]], grad_fn=<MulBackward0>)"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "##nn.Embedding : 수어 번역 단어를 입력으로 단어의 특성을 잘 표현하는 배열을 생성하는 Embedding객체에 dropout 실행\n",
    "dropout(embedding(input))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "61128b5d-4407-4601-8523-33805511c6a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "embedded = dropout(embedding(input))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "11e9c445-d9ca-4a4c-a0f3-7125027fa8c8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[-0.0000,  2.1331,  3.6205,  1.8431, -0.7399, -0.7969,  1.0610,\n",
       "          -1.9354,  0.0000, -0.0000,  0.0000, -0.0000, -0.9350,  0.0000,\n",
       "           1.1125,  0.0000,  0.4560,  0.0000,  0.0000, -0.0000,  0.3657,\n",
       "          -0.0000, -0.0000,  0.0000,  0.0000,  0.0000, -2.8163, -0.0000,\n",
       "           0.8940, -0.0000,  0.0619, -0.8500,  0.0000,  0.1826,  0.0000,\n",
       "           1.5884, -1.6448, -0.4228,  0.0000,  0.6610,  2.1818, -1.2447,\n",
       "          -0.0000,  0.0000, -0.9576, -2.2609,  0.0000, -1.5331,  0.1948,\n",
       "           0.0000,  0.0000, -0.2633,  0.0000, -3.3394, -1.8633, -0.0000,\n",
       "           1.3387,  2.1570, -0.0000, -0.0000,  0.0000, -1.0456, -0.0000,\n",
       "          -0.0000,  2.4087, -0.7371, -1.8556, -0.0000, -0.0000,  0.4058,\n",
       "           0.0000,  0.0000,  1.1692,  0.0000,  1.3541,  2.5428,  0.0000,\n",
       "           0.3952,  1.1830,  0.6736, -0.0000,  0.0000,  0.0000,  0.0000,\n",
       "           0.5274,  1.8977, -0.0000,  1.2462, -0.0000, -2.1265,  0.6666,\n",
       "          -1.7744,  0.9720, -0.0000, -0.0000,  1.0409,  0.3273, -1.7085,\n",
       "           0.0000, -0.0000,  0.0000,  0.0000, -0.0000, -0.0000, -0.1563,\n",
       "           0.0000,  1.6048, -1.0889,  0.7582, -0.0000,  3.2274, -0.0000,\n",
       "          -0.0000,  0.0000, -0.4231,  0.0000, -1.7196, -0.0000, -0.0000,\n",
       "          -0.0000, -0.0000,  0.2822, -0.1149, -0.0461,  0.0000, -2.6939,\n",
       "           0.0000, -0.0000]]], grad_fn=<MulBackward0>)"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embedded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "5852e149-9ddb-4a77-8784-fcb4ea954be8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 1, 128])"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embedded.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "ef10b55c-7872-4787-9e01-b80faa8ba528",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.0041, 0.0040, 0.0041, 0.0042, 0.0041, 0.0042, 0.0042, 0.0043, 0.0045,\n",
       "         0.0043, 0.0044, 0.0042, 0.0044, 0.0043, 0.0044, 0.0042, 0.0041, 0.0042,\n",
       "         0.0041, 0.0042, 0.0043, 0.0042, 0.0042, 0.0042, 0.0041, 0.0041, 0.0040,\n",
       "         0.0040, 0.0041, 0.0040, 0.0041, 0.0041, 0.0040, 0.0041, 0.0041, 0.0041,\n",
       "         0.0043, 0.0042, 0.0045, 0.0044, 0.0043, 0.0040, 0.0040, 0.0040, 0.0042,\n",
       "         0.0044, 0.0042, 0.0042, 0.0041, 0.0041, 0.0041, 0.0043, 0.0043, 0.0045,\n",
       "         0.0045, 0.0043, 0.0040, 0.0042, 0.0040, 0.0040, 0.0041, 0.0042, 0.0041,\n",
       "         0.0043, 0.0043, 0.0044, 0.0042, 0.0043, 0.0044, 0.0041, 0.0042, 0.0042,\n",
       "         0.0043, 0.0045, 0.0044, 0.0044, 0.0042, 0.0043, 0.0043, 0.0042, 0.0043,\n",
       "         0.0042, 0.0042, 0.0042, 0.0042, 0.0042, 0.0041, 0.0044, 0.0041, 0.0040,\n",
       "         0.0040, 0.0041, 0.0041, 0.0040, 0.0042, 0.0043, 0.0039, 0.0040, 0.0040,\n",
       "         0.0038, 0.0040, 0.0041, 0.0042, 0.0042, 0.0041, 0.0044, 0.0043, 0.0042,\n",
       "         0.0042, 0.0042, 0.0040, 0.0040, 0.0042, 0.0041, 0.0041, 0.0042, 0.0041,\n",
       "         0.0040, 0.0042, 0.0041, 0.0040, 0.0040, 0.0041, 0.0041, 0.0043, 0.0044,\n",
       "         0.0043, 0.0041, 0.0044, 0.0044, 0.0043, 0.0041, 0.0042, 0.0041, 0.0041,\n",
       "         0.0041, 0.0042, 0.0041, 0.0042, 0.0041, 0.0042, 0.0042, 0.0042, 0.0041,\n",
       "         0.0041, 0.0042, 0.0042, 0.0042, 0.0041, 0.0042, 0.0039, 0.0039, 0.0040,\n",
       "         0.0041, 0.0042, 0.0042, 0.0041, 0.0040, 0.0040, 0.0042, 0.0042, 0.0040,\n",
       "         0.0041, 0.0040, 0.0042, 0.0044, 0.0043, 0.0041, 0.0042, 0.0041, 0.0040,\n",
       "         0.0039, 0.0040, 0.0040, 0.0041, 0.0041, 0.0041, 0.0042, 0.0043, 0.0043,\n",
       "         0.0043, 0.0041, 0.0040, 0.0041, 0.0041, 0.0041, 0.0041, 0.0038, 0.0040,\n",
       "         0.0040, 0.0040, 0.0040, 0.0042, 0.0042, 0.0042, 0.0041, 0.0040, 0.0040,\n",
       "         0.0039, 0.0040, 0.0040, 0.0043, 0.0043, 0.0042, 0.0041, 0.0041, 0.0045,\n",
       "         0.0043, 0.0043, 0.0040, 0.0041, 0.0042, 0.0040, 0.0039, 0.0041, 0.0042,\n",
       "         0.0041, 0.0041, 0.0040, 0.0041, 0.0042, 0.0044, 0.0043, 0.0044, 0.0043,\n",
       "         0.0042, 0.0044, 0.0043, 0.0042, 0.0041, 0.0042, 0.0041, 0.0042, 0.0042,\n",
       "         0.0041, 0.0044, 0.0043, 0.0044, 0.0041, 0.0042]], device='cuda:0',\n",
       "       grad_fn=<SoftmaxBackward0>)"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Attention 결과가 저장된 변수\n",
    "attention_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "0c08473a-44dd-473c-a1b2-01b520d6ec62",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 240])"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "attention_output.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "8ccc011e-978a-4780-b204-2c4b9f972d99",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[0.0041, 0.0040, 0.0041, 0.0042, 0.0041, 0.0042, 0.0042, 0.0043,\n",
       "          0.0045, 0.0043, 0.0044, 0.0042, 0.0044, 0.0043, 0.0044, 0.0042,\n",
       "          0.0041, 0.0042, 0.0041, 0.0042, 0.0043, 0.0042, 0.0042, 0.0042,\n",
       "          0.0041, 0.0041, 0.0040, 0.0040, 0.0041, 0.0040, 0.0041, 0.0041,\n",
       "          0.0040, 0.0041, 0.0041, 0.0041, 0.0043, 0.0042, 0.0045, 0.0044,\n",
       "          0.0043, 0.0040, 0.0040, 0.0040, 0.0042, 0.0044, 0.0042, 0.0042,\n",
       "          0.0041, 0.0041, 0.0041, 0.0043, 0.0043, 0.0045, 0.0045, 0.0043,\n",
       "          0.0040, 0.0042, 0.0040, 0.0040, 0.0041, 0.0042, 0.0041, 0.0043,\n",
       "          0.0043, 0.0044, 0.0042, 0.0043, 0.0044, 0.0041, 0.0042, 0.0042,\n",
       "          0.0043, 0.0045, 0.0044, 0.0044, 0.0042, 0.0043, 0.0043, 0.0042,\n",
       "          0.0043, 0.0042, 0.0042, 0.0042, 0.0042, 0.0042, 0.0041, 0.0044,\n",
       "          0.0041, 0.0040, 0.0040, 0.0041, 0.0041, 0.0040, 0.0042, 0.0043,\n",
       "          0.0039, 0.0040, 0.0040, 0.0038, 0.0040, 0.0041, 0.0042, 0.0042,\n",
       "          0.0041, 0.0044, 0.0043, 0.0042, 0.0042, 0.0042, 0.0040, 0.0040,\n",
       "          0.0042, 0.0041, 0.0041, 0.0042, 0.0041, 0.0040, 0.0042, 0.0041,\n",
       "          0.0040, 0.0040, 0.0041, 0.0041, 0.0043, 0.0044, 0.0043, 0.0041,\n",
       "          0.0044, 0.0044, 0.0043, 0.0041, 0.0042, 0.0041, 0.0041, 0.0041,\n",
       "          0.0042, 0.0041, 0.0042, 0.0041, 0.0042, 0.0042, 0.0042, 0.0041,\n",
       "          0.0041, 0.0042, 0.0042, 0.0042, 0.0041, 0.0042, 0.0039, 0.0039,\n",
       "          0.0040, 0.0041, 0.0042, 0.0042, 0.0041, 0.0040, 0.0040, 0.0042,\n",
       "          0.0042, 0.0040, 0.0041, 0.0040, 0.0042, 0.0044, 0.0043, 0.0041,\n",
       "          0.0042, 0.0041, 0.0040, 0.0039, 0.0040, 0.0040, 0.0041, 0.0041,\n",
       "          0.0041, 0.0042, 0.0043, 0.0043, 0.0043, 0.0041, 0.0040, 0.0041,\n",
       "          0.0041, 0.0041, 0.0041, 0.0038, 0.0040, 0.0040, 0.0040, 0.0040,\n",
       "          0.0042, 0.0042, 0.0042, 0.0041, 0.0040, 0.0040, 0.0039, 0.0040,\n",
       "          0.0040, 0.0043, 0.0043, 0.0042, 0.0041, 0.0041, 0.0045, 0.0043,\n",
       "          0.0043, 0.0040, 0.0041, 0.0042, 0.0040, 0.0039, 0.0041, 0.0042,\n",
       "          0.0041, 0.0041, 0.0040, 0.0041, 0.0042, 0.0044, 0.0043, 0.0044,\n",
       "          0.0043, 0.0042, 0.0044, 0.0043, 0.0042, 0.0041, 0.0042, 0.0041,\n",
       "          0.0042, 0.0042, 0.0041, 0.0044, 0.0043, 0.0044, 0.0041, 0.0042]]],\n",
       "       device='cuda:0', grad_fn=<UnsqueezeBackward0>)"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Attention 결과가 저장된 변수 attention_output 배열차원을 1추가\n",
    "#unsqueeze(1) : 1번째 차원 추가\n",
    "attention_output.unsqueeze(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "810bae52-4e7d-450c-ba2b-7b7ac0b26bf9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 1, 240])"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Attention 결과가 저장된 변수 attention_output 배열차원을 1추가\n",
    "#unsqueeze(1) : 1번째 차원 추가\n",
    "attention_output.unsqueeze(1).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "f9cc68af-53dd-422d-97ae-884cd91acd80",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Attention 결과가 저장된 변수 attention_output 배열차원을 1추가\n",
    "#unsqueeze(1) : 1번째 차원 추가\n",
    "#attention_output.unsqueeze(1)\n",
    "attention_output = attention_output.unsqueeze(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "3849b38c-0e49-462f-8c6d-d4306de8d565",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 1, 240])"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "attention_output.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "5cd682cc-8639-47e4-aca3-317bca39f715",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 240, 1024])"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#encoder_output : 인코더 결과\n",
    "encoder_output.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "5810c77b-1450-4c1e-9260-5921fb5e0651",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[-0.0623,  0.1425,  0.2584,  ..., -0.1821,  0.1533, -0.0247]]],\n",
       "       device='cuda:0', grad_fn=<BmmBackward0>)"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#attention_output (어텐션 결과) encoder_output(인코더 결과)\n",
    "# 의 곱을 계산\n",
    "torch.bmm(attention_output, encoder_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "c02298e9-c791-456c-9dc7-0b8443908c91",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 1, 1024])"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#attention_output(어텐션결과) encoder_output(인코더결과)\n",
    "#의 곱을 계산\n",
    "#torch.bmm(attention_output, encoder_output)\n",
    "torch.bmm(attention_output, encoder_output).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "11fcb6b8-a92c-4568-b716-f4a0e06c3209",
   "metadata": {},
   "outputs": [],
   "source": [
    "weighted = torch.bmm(attention_output, encoder_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "de1d86bf-9d43-48e5-b8b5-9d799adec530",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[-0.0623,  0.1425,  0.2584,  ..., -0.1821,  0.1533, -0.0247]]],\n",
       "       device='cuda:0', grad_fn=<BmmBackward0>)"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weighted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "f17949f6-aa56-443a-b6d5-9754733cab3b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 1, 1024])"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weighted.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "897c072e-55cf-43a3-b068-c4e524d8ecfd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[-0.0623,  0.1425,  0.2584,  ..., -0.1821,  0.1533, -0.0247]]],\n",
       "       device='cuda:0', grad_fn=<PermuteBackward0>)"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#weighted.permute(1,0,2): weighted의 배열의 차원을 1, 0, 2로 변환\n",
    "weighted.permute(1,0,2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "4f3ad295-d8f4-486d-9dfb-2ff0205237a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "weighted = weighted.permute(1,0,2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "abf5a2c6-5fc5-4584-82a6-3879145a5084",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[-0.0623,  0.1425,  0.2584,  ..., -0.1821,  0.1533, -0.0247]]],\n",
       "       device='cuda:0', grad_fn=<PermuteBackward0>)"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weighted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "b0d84dd0-4440-4b52-a4d7-13854b23984a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 1, 1024])"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weighted.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "3bb04654-1752-42dc-a7c9-dd2f3aa45caf",
   "metadata": {},
   "outputs": [],
   "source": [
    "##입력한 단어 38 => \"부지역\"\n",
    "#특성을 저장한 배열 embedded\n",
    "\n",
    "#attention_output(어텐션결과) encoder_output(인코더결과)\n",
    "#의 곱을 계산 한 weighted\n",
    "\n",
    "#torch.cat((embedded.cuda(), weighted.cuda()), dim= 2)\n",
    "#embedded와 weighted를 하나로 합침\n",
    "#dim =2 : 배열의 2번째 차원에서 합침\n",
    "rnn_input = torch.cat((embedded.cuda(), weighted.cuda()), dim = 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "b4c9ba0e-add0-4328-b9d9-68378267a548",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[-0.0000,  2.1331,  3.6205,  ..., -0.1821,  0.1533, -0.0247]]],\n",
       "       device='cuda:0', grad_fn=<CatBackward0>)"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rnn_input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "755257cb-bec5-4b01-8439-9eff44947da8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 1, 1152])"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rnn_input.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "93c9c2e9-94df-4fa3-a8c5-511056742ba5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 512])"
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#encoder_hidden: 인코더의 실행 결과\n",
    "encoder_hidden.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "b0cda1ea-08b0-407b-8da7-46d48f0861d6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 1, 512])"
      ]
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#.unsqueeze(0): 차원을 1증가\n",
    "#                0번째 차원을 1 증가\n",
    "encoder_hidden.unsqueeze(0).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "32f5ab28-ba0f-4201-8daa-d4cd03cf44e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#GRU 연산 실행 할 객체\n",
    "gru = nn.GRU(\n",
    "             HID_DIM*2+EMB_DIM, #입력값의 열의 개수\n",
    "                               #HID_DIM(512) * 2 + EMB_DIM(128) => 1152\n",
    "             HID_DIM         #hidden layer의 열의 개수 HID_DIM(512) 출력 512 할다다\n",
    "            ).cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "d84cbf15-4251-4b2d-be35-34d005c296ba",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 1, 1152])"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rnn_input.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "3c57759c-901d-4247-b80e-49f72e2985fa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 512])"
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoder_hidden.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "496b0a1a-b1ee-4425-99b1-f41c17044fb8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[[ 0.0531,  0.1032, -0.3259, -0.0329,  0.2102, -0.0819,  0.2782,\n",
       "           -0.1939, -0.0209,  0.0204,  0.0541, -0.0774, -0.0147,  0.0439,\n",
       "            0.0974,  0.2558,  0.1534, -0.0048, -0.1775,  0.1940,  0.2559,\n",
       "            0.0911,  0.4602, -0.1321, -0.0504, -0.0969,  0.0923, -0.0790,\n",
       "           -0.0063, -0.0842,  0.1760, -0.0056,  0.2708, -0.0958,  0.2160,\n",
       "           -0.1291,  0.0010,  0.0935,  0.2566,  0.1014, -0.0209,  0.0225,\n",
       "           -0.1249,  0.0580,  0.0675, -0.1330, -0.0669,  0.3336, -0.0116,\n",
       "           -0.0761, -0.4173,  0.0891, -0.0179,  0.0597, -0.1879,  0.1096,\n",
       "           -0.1793,  0.0509, -0.0942,  0.4694, -0.2836,  0.2470,  0.1813,\n",
       "            0.1659,  0.1959, -0.1338,  0.1581, -0.1622,  0.0559, -0.4297,\n",
       "           -0.0129,  0.1603, -0.0344, -0.1248,  0.4458, -0.0053, -0.0601,\n",
       "            0.0449, -0.1083,  0.1231, -0.0264,  0.2023,  0.1130, -0.1210,\n",
       "            0.0123, -0.1203,  0.0847, -0.0948, -0.1133,  0.2529,  0.3957,\n",
       "            0.0554,  0.1320,  0.0210, -0.1022,  0.1989, -0.0163, -0.3036,\n",
       "           -0.1175, -0.0993,  0.0750, -0.1470,  0.1715,  0.2423,  0.0526,\n",
       "           -0.1157,  0.0616, -0.1812, -0.2592, -0.1878,  0.2633, -0.1289,\n",
       "            0.0411,  0.1806,  0.1357, -0.1767,  0.0259,  0.1047, -0.0333,\n",
       "           -0.1002, -0.1918, -0.0060,  0.2067, -0.2833,  0.2299, -0.0056,\n",
       "            0.0785, -0.0120,  0.2351,  0.0646, -0.0178, -0.0953, -0.2846,\n",
       "            0.1253,  0.2730, -0.0374,  0.0352, -0.2099,  0.3661,  0.0113,\n",
       "           -0.1875, -0.0741,  0.1073, -0.2015, -0.0420, -0.1782,  0.3130,\n",
       "           -0.0981, -0.3111,  0.1306,  0.1263, -0.2391, -0.1831,  0.0538,\n",
       "            0.2418, -0.0968,  0.2311, -0.1566, -0.1091, -0.1609, -0.1820,\n",
       "            0.3776,  0.1220, -0.0214, -0.0580, -0.2657, -0.0368,  0.1876,\n",
       "           -0.0147,  0.1958,  0.1780,  0.1583, -0.0944,  0.0894, -0.2133,\n",
       "            0.3320, -0.1633, -0.0439, -0.0206, -0.1223, -0.2331, -0.0313,\n",
       "           -0.0057, -0.1217,  0.1927, -0.0252, -0.0969,  0.2134,  0.2614,\n",
       "            0.0167,  0.1139,  0.0051,  0.2403,  0.0512,  0.0863,  0.3031,\n",
       "           -0.0092,  0.1633,  0.0028,  0.3419,  0.0494,  0.2033, -0.1232,\n",
       "            0.1057, -0.1192, -0.0862,  0.1428,  0.2772,  0.3415, -0.0135,\n",
       "           -0.3260,  0.2297, -0.1112,  0.1494,  0.0402, -0.0035, -0.3595,\n",
       "            0.0530,  0.0768,  0.1043, -0.4540, -0.3675, -0.0347, -0.2939,\n",
       "            0.0986,  0.3436, -0.2551, -0.0425,  0.3878,  0.0232, -0.1985,\n",
       "            0.0871,  0.1413,  0.0420, -0.3377, -0.0517,  0.0734,  0.2853,\n",
       "            0.1263,  0.2080,  0.3106,  0.0363, -0.1259,  0.1367, -0.0236,\n",
       "            0.0059, -0.2059,  0.0770,  0.2314,  0.2887, -0.2321,  0.2677,\n",
       "            0.3322, -0.0104,  0.0753,  0.1792, -0.0364, -0.1600,  0.2044,\n",
       "            0.1066,  0.0878, -0.0729, -0.3002,  0.2410,  0.1514,  0.0786,\n",
       "            0.2157,  0.0044,  0.0313, -0.1811, -0.0677,  0.1213,  0.0166,\n",
       "           -0.0895,  0.0730,  0.3020,  0.1025, -0.2539,  0.0202, -0.1291,\n",
       "           -0.0147,  0.1801, -0.2723, -0.2467, -0.2597,  0.2114, -0.0116,\n",
       "           -0.1242, -0.2467,  0.2093, -0.0415,  0.3189,  0.1016, -0.1427,\n",
       "            0.1504,  0.0359, -0.0202, -0.1183, -0.1273,  0.0713,  0.3022,\n",
       "           -0.3362,  0.0889, -0.0651,  0.0354,  0.0996,  0.2898,  0.2654,\n",
       "            0.0181,  0.0476,  0.0671,  0.0450,  0.1042, -0.2330,  0.1694,\n",
       "           -0.2912,  0.0498, -0.2012,  0.0054, -0.0980, -0.2290,  0.3548,\n",
       "            0.0393,  0.1183,  0.0140, -0.0550,  0.2119, -0.0482, -0.1635,\n",
       "           -0.2126, -0.1331, -0.0749, -0.1528,  0.2511, -0.3572,  0.0651,\n",
       "            0.1639, -0.0474, -0.2276,  0.2130, -0.2172, -0.0088, -0.1910,\n",
       "           -0.1349, -0.0925,  0.0368,  0.0115, -0.0905, -0.3161, -0.2291,\n",
       "            0.3855, -0.0119, -0.1859, -0.0184,  0.2718, -0.0435,  0.0294,\n",
       "            0.0048,  0.0609,  0.3427,  0.2663,  0.0738, -0.1906,  0.1415,\n",
       "            0.0080,  0.2293,  0.1016, -0.0851,  0.1614, -0.2153, -0.2513,\n",
       "           -0.2231,  0.1939, -0.3983,  0.2780, -0.1536,  0.2901,  0.2071,\n",
       "            0.0864,  0.2847, -0.4276, -0.1412, -0.2593,  0.1157, -0.0944,\n",
       "           -0.1299,  0.0309, -0.3528, -0.2229,  0.1776,  0.1256, -0.0362,\n",
       "            0.1899, -0.3575, -0.1139,  0.0121,  0.2975,  0.1429, -0.1966,\n",
       "            0.3859,  0.0024,  0.1990, -0.1001,  0.1957,  0.0387,  0.2655,\n",
       "           -0.1472, -0.0603, -0.3520, -0.1476,  0.0266,  0.1393, -0.0705,\n",
       "           -0.0923,  0.1358, -0.2218, -0.0456,  0.0808, -0.0215,  0.2949,\n",
       "            0.2635,  0.1083,  0.0824,  0.0128, -0.1098,  0.2651,  0.2884,\n",
       "           -0.1883, -0.0537, -0.2159,  0.2914,  0.1183, -0.0550,  0.1706,\n",
       "           -0.1728,  0.1213, -0.0561,  0.0713, -0.0686, -0.2940, -0.0996,\n",
       "            0.0281,  0.0606,  0.2186,  0.0151, -0.1051, -0.2021,  0.0501,\n",
       "           -0.0493,  0.2234,  0.1382,  0.1215,  0.0035, -0.0251,  0.2637,\n",
       "           -0.1322, -0.0746, -0.0817,  0.1829,  0.0098, -0.0150, -0.0982,\n",
       "            0.1615,  0.0883,  0.0474,  0.0061, -0.0326, -0.1693, -0.0166,\n",
       "           -0.0873, -0.0079, -0.0015, -0.0054, -0.1735, -0.3530, -0.1937,\n",
       "            0.2845,  0.0228,  0.1186,  0.0256,  0.1347, -0.3437, -0.1867,\n",
       "           -0.1196, -0.3519, -0.1176,  0.1276, -0.1165,  0.0405,  0.1707,\n",
       "            0.2719,  0.0322, -0.0073, -0.1450,  0.0280, -0.2774,  0.1542,\n",
       "           -0.2600,  0.2099,  0.1891,  0.2556,  0.2311, -0.1214, -0.1028,\n",
       "           -0.2564,  0.0048,  0.0430, -0.0607,  0.1109,  0.0481, -0.1368,\n",
       "           -0.1015]]], device='cuda:0', grad_fn=<CudnnRnnBackward0>),\n",
       " tensor([[[ 0.0531,  0.1032, -0.3259, -0.0329,  0.2102, -0.0819,  0.2782,\n",
       "           -0.1939, -0.0209,  0.0204,  0.0541, -0.0774, -0.0147,  0.0439,\n",
       "            0.0974,  0.2558,  0.1534, -0.0048, -0.1775,  0.1940,  0.2559,\n",
       "            0.0911,  0.4602, -0.1321, -0.0504, -0.0969,  0.0923, -0.0790,\n",
       "           -0.0063, -0.0842,  0.1760, -0.0056,  0.2708, -0.0958,  0.2160,\n",
       "           -0.1291,  0.0010,  0.0935,  0.2566,  0.1014, -0.0209,  0.0225,\n",
       "           -0.1249,  0.0580,  0.0675, -0.1330, -0.0669,  0.3336, -0.0116,\n",
       "           -0.0761, -0.4173,  0.0891, -0.0179,  0.0597, -0.1879,  0.1096,\n",
       "           -0.1793,  0.0509, -0.0942,  0.4694, -0.2836,  0.2470,  0.1813,\n",
       "            0.1659,  0.1959, -0.1338,  0.1581, -0.1622,  0.0559, -0.4297,\n",
       "           -0.0129,  0.1603, -0.0344, -0.1248,  0.4458, -0.0053, -0.0601,\n",
       "            0.0449, -0.1083,  0.1231, -0.0264,  0.2023,  0.1130, -0.1210,\n",
       "            0.0123, -0.1203,  0.0847, -0.0948, -0.1133,  0.2529,  0.3957,\n",
       "            0.0554,  0.1320,  0.0210, -0.1022,  0.1989, -0.0163, -0.3036,\n",
       "           -0.1175, -0.0993,  0.0750, -0.1470,  0.1715,  0.2423,  0.0526,\n",
       "           -0.1157,  0.0616, -0.1812, -0.2592, -0.1878,  0.2633, -0.1289,\n",
       "            0.0411,  0.1806,  0.1357, -0.1767,  0.0259,  0.1047, -0.0333,\n",
       "           -0.1002, -0.1918, -0.0060,  0.2067, -0.2833,  0.2299, -0.0056,\n",
       "            0.0785, -0.0120,  0.2351,  0.0646, -0.0178, -0.0953, -0.2846,\n",
       "            0.1253,  0.2730, -0.0374,  0.0352, -0.2099,  0.3661,  0.0113,\n",
       "           -0.1875, -0.0741,  0.1073, -0.2015, -0.0420, -0.1782,  0.3130,\n",
       "           -0.0981, -0.3111,  0.1306,  0.1263, -0.2391, -0.1831,  0.0538,\n",
       "            0.2418, -0.0968,  0.2311, -0.1566, -0.1091, -0.1609, -0.1820,\n",
       "            0.3776,  0.1220, -0.0214, -0.0580, -0.2657, -0.0368,  0.1876,\n",
       "           -0.0147,  0.1958,  0.1780,  0.1583, -0.0944,  0.0894, -0.2133,\n",
       "            0.3320, -0.1633, -0.0439, -0.0206, -0.1223, -0.2331, -0.0313,\n",
       "           -0.0057, -0.1217,  0.1927, -0.0252, -0.0969,  0.2134,  0.2614,\n",
       "            0.0167,  0.1139,  0.0051,  0.2403,  0.0512,  0.0863,  0.3031,\n",
       "           -0.0092,  0.1633,  0.0028,  0.3419,  0.0494,  0.2033, -0.1232,\n",
       "            0.1057, -0.1192, -0.0862,  0.1428,  0.2772,  0.3415, -0.0135,\n",
       "           -0.3260,  0.2297, -0.1112,  0.1494,  0.0402, -0.0035, -0.3595,\n",
       "            0.0530,  0.0768,  0.1043, -0.4540, -0.3675, -0.0347, -0.2939,\n",
       "            0.0986,  0.3436, -0.2551, -0.0425,  0.3878,  0.0232, -0.1985,\n",
       "            0.0871,  0.1413,  0.0420, -0.3377, -0.0517,  0.0734,  0.2853,\n",
       "            0.1263,  0.2080,  0.3106,  0.0363, -0.1259,  0.1367, -0.0236,\n",
       "            0.0059, -0.2059,  0.0770,  0.2314,  0.2887, -0.2321,  0.2677,\n",
       "            0.3322, -0.0104,  0.0753,  0.1792, -0.0364, -0.1600,  0.2044,\n",
       "            0.1066,  0.0878, -0.0729, -0.3002,  0.2410,  0.1514,  0.0786,\n",
       "            0.2157,  0.0044,  0.0313, -0.1811, -0.0677,  0.1213,  0.0166,\n",
       "           -0.0895,  0.0730,  0.3020,  0.1025, -0.2539,  0.0202, -0.1291,\n",
       "           -0.0147,  0.1801, -0.2723, -0.2467, -0.2597,  0.2114, -0.0116,\n",
       "           -0.1242, -0.2467,  0.2093, -0.0415,  0.3189,  0.1016, -0.1427,\n",
       "            0.1504,  0.0359, -0.0202, -0.1183, -0.1273,  0.0713,  0.3022,\n",
       "           -0.3362,  0.0889, -0.0651,  0.0354,  0.0996,  0.2898,  0.2654,\n",
       "            0.0181,  0.0476,  0.0671,  0.0450,  0.1042, -0.2330,  0.1694,\n",
       "           -0.2912,  0.0498, -0.2012,  0.0054, -0.0980, -0.2290,  0.3548,\n",
       "            0.0393,  0.1183,  0.0140, -0.0550,  0.2119, -0.0482, -0.1635,\n",
       "           -0.2126, -0.1331, -0.0749, -0.1528,  0.2511, -0.3572,  0.0651,\n",
       "            0.1639, -0.0474, -0.2276,  0.2130, -0.2172, -0.0088, -0.1910,\n",
       "           -0.1349, -0.0925,  0.0368,  0.0115, -0.0905, -0.3161, -0.2291,\n",
       "            0.3855, -0.0119, -0.1859, -0.0184,  0.2718, -0.0435,  0.0294,\n",
       "            0.0048,  0.0609,  0.3427,  0.2663,  0.0738, -0.1906,  0.1415,\n",
       "            0.0080,  0.2293,  0.1016, -0.0851,  0.1614, -0.2153, -0.2513,\n",
       "           -0.2231,  0.1939, -0.3983,  0.2780, -0.1536,  0.2901,  0.2071,\n",
       "            0.0864,  0.2847, -0.4276, -0.1412, -0.2593,  0.1157, -0.0944,\n",
       "           -0.1299,  0.0309, -0.3528, -0.2229,  0.1776,  0.1256, -0.0362,\n",
       "            0.1899, -0.3575, -0.1139,  0.0121,  0.2975,  0.1429, -0.1966,\n",
       "            0.3859,  0.0024,  0.1990, -0.1001,  0.1957,  0.0387,  0.2655,\n",
       "           -0.1472, -0.0603, -0.3520, -0.1476,  0.0266,  0.1393, -0.0705,\n",
       "           -0.0923,  0.1358, -0.2218, -0.0456,  0.0808, -0.0215,  0.2949,\n",
       "            0.2635,  0.1083,  0.0824,  0.0128, -0.1098,  0.2651,  0.2884,\n",
       "           -0.1883, -0.0537, -0.2159,  0.2914,  0.1183, -0.0550,  0.1706,\n",
       "           -0.1728,  0.1213, -0.0561,  0.0713, -0.0686, -0.2940, -0.0996,\n",
       "            0.0281,  0.0606,  0.2186,  0.0151, -0.1051, -0.2021,  0.0501,\n",
       "           -0.0493,  0.2234,  0.1382,  0.1215,  0.0035, -0.0251,  0.2637,\n",
       "           -0.1322, -0.0746, -0.0817,  0.1829,  0.0098, -0.0150, -0.0982,\n",
       "            0.1615,  0.0883,  0.0474,  0.0061, -0.0326, -0.1693, -0.0166,\n",
       "           -0.0873, -0.0079, -0.0015, -0.0054, -0.1735, -0.3530, -0.1937,\n",
       "            0.2845,  0.0228,  0.1186,  0.0256,  0.1347, -0.3437, -0.1867,\n",
       "           -0.1196, -0.3519, -0.1176,  0.1276, -0.1165,  0.0405,  0.1707,\n",
       "            0.2719,  0.0322, -0.0073, -0.1450,  0.0280, -0.2774,  0.1542,\n",
       "           -0.2600,  0.2099,  0.1891,  0.2556,  0.2311, -0.1214, -0.1028,\n",
       "           -0.2564,  0.0048,  0.0430, -0.0607,  0.1109,  0.0481, -0.1368,\n",
       "           -0.1015]]], device='cuda:0', grad_fn=<CudnnRnnBackward0>))"
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#GRU 연산\n",
    "\n",
    "#rnn_input:\n",
    "##입력한 단어 38 => \"부지역\"\n",
    "#특성을 저장한 배열 embedded\n",
    "\n",
    "#attention_output(어텐션 결과) encoder_output(인코더결과)\n",
    "#의 곱을 계산 한 weighted\n",
    "#하나로 합침\n",
    "\n",
    "#encoder_hidden : 인코더의 실행 결과\n",
    "#.unsqueeze(0): 차원을 1증가\n",
    "#               0번째 차원을 증가\n",
    "\n",
    "gru(\n",
    "    rnn_input.cuda(),\n",
    "    encoder_hidden.unsqueeze(0).cuda()\n",
    ")\n",
    "\n",
    "\n",
    "##65페이지 여기서부터 다시치기 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "05a34d18-9b4b-4519-a19e-20c2804829b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#GRU 연산\n",
    "#rnn_input:\n",
    "## 입력한 단어 38 => \"부지역\"\n",
    "#특성을 저장한 배열 embedded\n",
    "#attention_output(어텐션결과) encoder_output(인코더결과)\n",
    "#의 곱을 계산한 weighted 하나로 합침\n",
    "\n",
    "#encoder_hidden: 인코더의 실행 결과\n",
    "#.unsqueeze(0) : 차원을 1증가\n",
    "#                0번째 차원을 1 증가\n",
    "decoder_out, decoder_hidden = gru(rnn_input.cuda(), encoder_hidden.unsqueeze(0).cuda())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "ccac8c88-6608-4389-a1eb-4d3435be057b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[ 0.0531,  0.1032, -0.3259, -0.0329,  0.2102, -0.0819,  0.2782,\n",
       "          -0.1939, -0.0209,  0.0204,  0.0541, -0.0774, -0.0147,  0.0439,\n",
       "           0.0974,  0.2558,  0.1534, -0.0048, -0.1775,  0.1940,  0.2559,\n",
       "           0.0911,  0.4602, -0.1321, -0.0504, -0.0969,  0.0923, -0.0790,\n",
       "          -0.0063, -0.0842,  0.1760, -0.0056,  0.2708, -0.0958,  0.2160,\n",
       "          -0.1291,  0.0010,  0.0935,  0.2566,  0.1014, -0.0209,  0.0225,\n",
       "          -0.1249,  0.0580,  0.0675, -0.1330, -0.0669,  0.3336, -0.0116,\n",
       "          -0.0761, -0.4173,  0.0891, -0.0179,  0.0597, -0.1879,  0.1096,\n",
       "          -0.1793,  0.0509, -0.0942,  0.4694, -0.2836,  0.2470,  0.1813,\n",
       "           0.1659,  0.1959, -0.1338,  0.1581, -0.1622,  0.0559, -0.4297,\n",
       "          -0.0129,  0.1603, -0.0344, -0.1248,  0.4458, -0.0053, -0.0601,\n",
       "           0.0449, -0.1083,  0.1231, -0.0264,  0.2023,  0.1130, -0.1210,\n",
       "           0.0123, -0.1203,  0.0847, -0.0948, -0.1133,  0.2529,  0.3957,\n",
       "           0.0554,  0.1320,  0.0210, -0.1022,  0.1989, -0.0163, -0.3036,\n",
       "          -0.1175, -0.0993,  0.0750, -0.1470,  0.1715,  0.2423,  0.0526,\n",
       "          -0.1157,  0.0616, -0.1812, -0.2592, -0.1878,  0.2633, -0.1289,\n",
       "           0.0411,  0.1806,  0.1357, -0.1767,  0.0259,  0.1047, -0.0333,\n",
       "          -0.1002, -0.1918, -0.0060,  0.2067, -0.2833,  0.2299, -0.0056,\n",
       "           0.0785, -0.0120,  0.2351,  0.0646, -0.0178, -0.0953, -0.2846,\n",
       "           0.1253,  0.2730, -0.0374,  0.0352, -0.2099,  0.3661,  0.0113,\n",
       "          -0.1875, -0.0741,  0.1073, -0.2015, -0.0420, -0.1782,  0.3130,\n",
       "          -0.0981, -0.3111,  0.1306,  0.1263, -0.2391, -0.1831,  0.0538,\n",
       "           0.2418, -0.0968,  0.2311, -0.1566, -0.1091, -0.1609, -0.1820,\n",
       "           0.3776,  0.1220, -0.0214, -0.0580, -0.2657, -0.0368,  0.1876,\n",
       "          -0.0147,  0.1958,  0.1780,  0.1583, -0.0944,  0.0894, -0.2133,\n",
       "           0.3320, -0.1633, -0.0439, -0.0206, -0.1223, -0.2331, -0.0313,\n",
       "          -0.0057, -0.1217,  0.1927, -0.0252, -0.0969,  0.2134,  0.2614,\n",
       "           0.0167,  0.1139,  0.0051,  0.2403,  0.0512,  0.0863,  0.3031,\n",
       "          -0.0092,  0.1633,  0.0028,  0.3419,  0.0494,  0.2033, -0.1232,\n",
       "           0.1057, -0.1192, -0.0862,  0.1428,  0.2772,  0.3415, -0.0135,\n",
       "          -0.3260,  0.2297, -0.1112,  0.1494,  0.0402, -0.0035, -0.3595,\n",
       "           0.0530,  0.0768,  0.1043, -0.4540, -0.3675, -0.0347, -0.2939,\n",
       "           0.0986,  0.3436, -0.2551, -0.0425,  0.3878,  0.0232, -0.1985,\n",
       "           0.0871,  0.1413,  0.0420, -0.3377, -0.0517,  0.0734,  0.2853,\n",
       "           0.1263,  0.2080,  0.3106,  0.0363, -0.1259,  0.1367, -0.0236,\n",
       "           0.0059, -0.2059,  0.0770,  0.2314,  0.2887, -0.2321,  0.2677,\n",
       "           0.3322, -0.0104,  0.0753,  0.1792, -0.0364, -0.1600,  0.2044,\n",
       "           0.1066,  0.0878, -0.0729, -0.3002,  0.2410,  0.1514,  0.0786,\n",
       "           0.2157,  0.0044,  0.0313, -0.1811, -0.0677,  0.1213,  0.0166,\n",
       "          -0.0895,  0.0730,  0.3020,  0.1025, -0.2539,  0.0202, -0.1291,\n",
       "          -0.0147,  0.1801, -0.2723, -0.2467, -0.2597,  0.2114, -0.0116,\n",
       "          -0.1242, -0.2467,  0.2093, -0.0415,  0.3189,  0.1016, -0.1427,\n",
       "           0.1504,  0.0359, -0.0202, -0.1183, -0.1273,  0.0713,  0.3022,\n",
       "          -0.3362,  0.0889, -0.0651,  0.0354,  0.0996,  0.2898,  0.2654,\n",
       "           0.0181,  0.0476,  0.0671,  0.0450,  0.1042, -0.2330,  0.1694,\n",
       "          -0.2912,  0.0498, -0.2012,  0.0054, -0.0980, -0.2290,  0.3548,\n",
       "           0.0393,  0.1183,  0.0140, -0.0550,  0.2119, -0.0482, -0.1635,\n",
       "          -0.2126, -0.1331, -0.0749, -0.1528,  0.2511, -0.3572,  0.0651,\n",
       "           0.1639, -0.0474, -0.2276,  0.2130, -0.2172, -0.0088, -0.1910,\n",
       "          -0.1349, -0.0925,  0.0368,  0.0115, -0.0905, -0.3161, -0.2291,\n",
       "           0.3855, -0.0119, -0.1859, -0.0184,  0.2718, -0.0435,  0.0294,\n",
       "           0.0048,  0.0609,  0.3427,  0.2663,  0.0738, -0.1906,  0.1415,\n",
       "           0.0080,  0.2293,  0.1016, -0.0851,  0.1614, -0.2153, -0.2513,\n",
       "          -0.2231,  0.1939, -0.3983,  0.2780, -0.1536,  0.2901,  0.2071,\n",
       "           0.0864,  0.2847, -0.4276, -0.1412, -0.2593,  0.1157, -0.0944,\n",
       "          -0.1299,  0.0309, -0.3528, -0.2229,  0.1776,  0.1256, -0.0362,\n",
       "           0.1899, -0.3575, -0.1139,  0.0121,  0.2975,  0.1429, -0.1966,\n",
       "           0.3859,  0.0024,  0.1990, -0.1001,  0.1957,  0.0387,  0.2655,\n",
       "          -0.1472, -0.0603, -0.3520, -0.1476,  0.0266,  0.1393, -0.0705,\n",
       "          -0.0923,  0.1358, -0.2218, -0.0456,  0.0808, -0.0215,  0.2949,\n",
       "           0.2635,  0.1083,  0.0824,  0.0128, -0.1098,  0.2651,  0.2884,\n",
       "          -0.1883, -0.0537, -0.2159,  0.2914,  0.1183, -0.0550,  0.1706,\n",
       "          -0.1728,  0.1213, -0.0561,  0.0713, -0.0686, -0.2940, -0.0996,\n",
       "           0.0281,  0.0606,  0.2186,  0.0151, -0.1051, -0.2021,  0.0501,\n",
       "          -0.0493,  0.2234,  0.1382,  0.1215,  0.0035, -0.0251,  0.2637,\n",
       "          -0.1322, -0.0746, -0.0817,  0.1829,  0.0098, -0.0150, -0.0982,\n",
       "           0.1615,  0.0883,  0.0474,  0.0061, -0.0326, -0.1693, -0.0166,\n",
       "          -0.0873, -0.0079, -0.0015, -0.0054, -0.1735, -0.3530, -0.1937,\n",
       "           0.2845,  0.0228,  0.1186,  0.0256,  0.1347, -0.3437, -0.1867,\n",
       "          -0.1196, -0.3519, -0.1176,  0.1276, -0.1165,  0.0405,  0.1707,\n",
       "           0.2719,  0.0322, -0.0073, -0.1450,  0.0280, -0.2774,  0.1542,\n",
       "          -0.2600,  0.2099,  0.1891,  0.2556,  0.2311, -0.1214, -0.1028,\n",
       "          -0.2564,  0.0048,  0.0430, -0.0607,  0.1109,  0.0481, -0.1368,\n",
       "          -0.1015]]], device='cuda:0', grad_fn=<CudnnRnnBackward0>)"
      ]
     },
     "execution_count": 127,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "decoder_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "6ef35e78-728a-4c02-9011-565ebcaf8c86",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[ 0.0531,  0.1032, -0.3259, -0.0329,  0.2102, -0.0819,  0.2782,\n",
       "          -0.1939, -0.0209,  0.0204,  0.0541, -0.0774, -0.0147,  0.0439,\n",
       "           0.0974,  0.2558,  0.1534, -0.0048, -0.1775,  0.1940,  0.2559,\n",
       "           0.0911,  0.4602, -0.1321, -0.0504, -0.0969,  0.0923, -0.0790,\n",
       "          -0.0063, -0.0842,  0.1760, -0.0056,  0.2708, -0.0958,  0.2160,\n",
       "          -0.1291,  0.0010,  0.0935,  0.2566,  0.1014, -0.0209,  0.0225,\n",
       "          -0.1249,  0.0580,  0.0675, -0.1330, -0.0669,  0.3336, -0.0116,\n",
       "          -0.0761, -0.4173,  0.0891, -0.0179,  0.0597, -0.1879,  0.1096,\n",
       "          -0.1793,  0.0509, -0.0942,  0.4694, -0.2836,  0.2470,  0.1813,\n",
       "           0.1659,  0.1959, -0.1338,  0.1581, -0.1622,  0.0559, -0.4297,\n",
       "          -0.0129,  0.1603, -0.0344, -0.1248,  0.4458, -0.0053, -0.0601,\n",
       "           0.0449, -0.1083,  0.1231, -0.0264,  0.2023,  0.1130, -0.1210,\n",
       "           0.0123, -0.1203,  0.0847, -0.0948, -0.1133,  0.2529,  0.3957,\n",
       "           0.0554,  0.1320,  0.0210, -0.1022,  0.1989, -0.0163, -0.3036,\n",
       "          -0.1175, -0.0993,  0.0750, -0.1470,  0.1715,  0.2423,  0.0526,\n",
       "          -0.1157,  0.0616, -0.1812, -0.2592, -0.1878,  0.2633, -0.1289,\n",
       "           0.0411,  0.1806,  0.1357, -0.1767,  0.0259,  0.1047, -0.0333,\n",
       "          -0.1002, -0.1918, -0.0060,  0.2067, -0.2833,  0.2299, -0.0056,\n",
       "           0.0785, -0.0120,  0.2351,  0.0646, -0.0178, -0.0953, -0.2846,\n",
       "           0.1253,  0.2730, -0.0374,  0.0352, -0.2099,  0.3661,  0.0113,\n",
       "          -0.1875, -0.0741,  0.1073, -0.2015, -0.0420, -0.1782,  0.3130,\n",
       "          -0.0981, -0.3111,  0.1306,  0.1263, -0.2391, -0.1831,  0.0538,\n",
       "           0.2418, -0.0968,  0.2311, -0.1566, -0.1091, -0.1609, -0.1820,\n",
       "           0.3776,  0.1220, -0.0214, -0.0580, -0.2657, -0.0368,  0.1876,\n",
       "          -0.0147,  0.1958,  0.1780,  0.1583, -0.0944,  0.0894, -0.2133,\n",
       "           0.3320, -0.1633, -0.0439, -0.0206, -0.1223, -0.2331, -0.0313,\n",
       "          -0.0057, -0.1217,  0.1927, -0.0252, -0.0969,  0.2134,  0.2614,\n",
       "           0.0167,  0.1139,  0.0051,  0.2403,  0.0512,  0.0863,  0.3031,\n",
       "          -0.0092,  0.1633,  0.0028,  0.3419,  0.0494,  0.2033, -0.1232,\n",
       "           0.1057, -0.1192, -0.0862,  0.1428,  0.2772,  0.3415, -0.0135,\n",
       "          -0.3260,  0.2297, -0.1112,  0.1494,  0.0402, -0.0035, -0.3595,\n",
       "           0.0530,  0.0768,  0.1043, -0.4540, -0.3675, -0.0347, -0.2939,\n",
       "           0.0986,  0.3436, -0.2551, -0.0425,  0.3878,  0.0232, -0.1985,\n",
       "           0.0871,  0.1413,  0.0420, -0.3377, -0.0517,  0.0734,  0.2853,\n",
       "           0.1263,  0.2080,  0.3106,  0.0363, -0.1259,  0.1367, -0.0236,\n",
       "           0.0059, -0.2059,  0.0770,  0.2314,  0.2887, -0.2321,  0.2677,\n",
       "           0.3322, -0.0104,  0.0753,  0.1792, -0.0364, -0.1600,  0.2044,\n",
       "           0.1066,  0.0878, -0.0729, -0.3002,  0.2410,  0.1514,  0.0786,\n",
       "           0.2157,  0.0044,  0.0313, -0.1811, -0.0677,  0.1213,  0.0166,\n",
       "          -0.0895,  0.0730,  0.3020,  0.1025, -0.2539,  0.0202, -0.1291,\n",
       "          -0.0147,  0.1801, -0.2723, -0.2467, -0.2597,  0.2114, -0.0116,\n",
       "          -0.1242, -0.2467,  0.2093, -0.0415,  0.3189,  0.1016, -0.1427,\n",
       "           0.1504,  0.0359, -0.0202, -0.1183, -0.1273,  0.0713,  0.3022,\n",
       "          -0.3362,  0.0889, -0.0651,  0.0354,  0.0996,  0.2898,  0.2654,\n",
       "           0.0181,  0.0476,  0.0671,  0.0450,  0.1042, -0.2330,  0.1694,\n",
       "          -0.2912,  0.0498, -0.2012,  0.0054, -0.0980, -0.2290,  0.3548,\n",
       "           0.0393,  0.1183,  0.0140, -0.0550,  0.2119, -0.0482, -0.1635,\n",
       "          -0.2126, -0.1331, -0.0749, -0.1528,  0.2511, -0.3572,  0.0651,\n",
       "           0.1639, -0.0474, -0.2276,  0.2130, -0.2172, -0.0088, -0.1910,\n",
       "          -0.1349, -0.0925,  0.0368,  0.0115, -0.0905, -0.3161, -0.2291,\n",
       "           0.3855, -0.0119, -0.1859, -0.0184,  0.2718, -0.0435,  0.0294,\n",
       "           0.0048,  0.0609,  0.3427,  0.2663,  0.0738, -0.1906,  0.1415,\n",
       "           0.0080,  0.2293,  0.1016, -0.0851,  0.1614, -0.2153, -0.2513,\n",
       "          -0.2231,  0.1939, -0.3983,  0.2780, -0.1536,  0.2901,  0.2071,\n",
       "           0.0864,  0.2847, -0.4276, -0.1412, -0.2593,  0.1157, -0.0944,\n",
       "          -0.1299,  0.0309, -0.3528, -0.2229,  0.1776,  0.1256, -0.0362,\n",
       "           0.1899, -0.3575, -0.1139,  0.0121,  0.2975,  0.1429, -0.1966,\n",
       "           0.3859,  0.0024,  0.1990, -0.1001,  0.1957,  0.0387,  0.2655,\n",
       "          -0.1472, -0.0603, -0.3520, -0.1476,  0.0266,  0.1393, -0.0705,\n",
       "          -0.0923,  0.1358, -0.2218, -0.0456,  0.0808, -0.0215,  0.2949,\n",
       "           0.2635,  0.1083,  0.0824,  0.0128, -0.1098,  0.2651,  0.2884,\n",
       "          -0.1883, -0.0537, -0.2159,  0.2914,  0.1183, -0.0550,  0.1706,\n",
       "          -0.1728,  0.1213, -0.0561,  0.0713, -0.0686, -0.2940, -0.0996,\n",
       "           0.0281,  0.0606,  0.2186,  0.0151, -0.1051, -0.2021,  0.0501,\n",
       "          -0.0493,  0.2234,  0.1382,  0.1215,  0.0035, -0.0251,  0.2637,\n",
       "          -0.1322, -0.0746, -0.0817,  0.1829,  0.0098, -0.0150, -0.0982,\n",
       "           0.1615,  0.0883,  0.0474,  0.0061, -0.0326, -0.1693, -0.0166,\n",
       "          -0.0873, -0.0079, -0.0015, -0.0054, -0.1735, -0.3530, -0.1937,\n",
       "           0.2845,  0.0228,  0.1186,  0.0256,  0.1347, -0.3437, -0.1867,\n",
       "          -0.1196, -0.3519, -0.1176,  0.1276, -0.1165,  0.0405,  0.1707,\n",
       "           0.2719,  0.0322, -0.0073, -0.1450,  0.0280, -0.2774,  0.1542,\n",
       "          -0.2600,  0.2099,  0.1891,  0.2556,  0.2311, -0.1214, -0.1028,\n",
       "          -0.2564,  0.0048,  0.0430, -0.0607,  0.1109,  0.0481, -0.1368,\n",
       "          -0.1015]]], device='cuda:0', grad_fn=<CudnnRnnBackward0>)"
      ]
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "decoder_hidden"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "fd73ba9b-a5fc-48c8-bee0-6ba2521f916b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 1, 128])"
      ]
     },
     "execution_count": 129,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embedded.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "cd3364c8-30c1-4620-9141-1f9a5e488c5d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 128])"
      ]
     },
     "execution_count": 130,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "##입력한 단어 38 => \"부지역\"\n",
    "#특성을 저장한 배열 embedded\n",
    "#emnedded.squeeze(0) : embedded 의 차원을 삭제\n",
    "#squeeze(0) : 0 번째 차원 삭제\n",
    "embedded.squeeze(0).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "e5c14b63-e5a9-4e80-a258-a48b1e3ff70b",
   "metadata": {},
   "outputs": [],
   "source": [
    "embedded = embedded.squeeze(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "40a65532-47ff-4196-bb77-0795586e61c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "decoder_out = decoder_out.squeeze(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "9ebf4261-fed5-4e98-b142-946c2d505574",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 512])"
      ]
     },
     "execution_count": 133,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "decoder_out.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "9707c640-c7a1-4fe9-9ac6-5f8ea5597f5f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 1, 1024])"
      ]
     },
     "execution_count": 134,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#weighted:\n",
    "##attention_output(어텐션결과) encoder_output(인코더결과) 곱\n",
    "weighted.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "id": "b70c6d5c-174c-4402-95cf-20ed40c74722",
   "metadata": {},
   "outputs": [],
   "source": [
    "#weighted.squeeze(0): weighted의 차원을 삭제\n",
    "#squeeze(0) : 0번째 차원 삭제\n",
    "weighted = weighted.squeeze(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "id": "6494e9f4-8b57-4ac4-aa0f-2c76bb2be7f3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 1024])"
      ]
     },
     "execution_count": 136,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weighted.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "id": "4cabbb62-9c05-4326-a2d7-9c47f48c4a7b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.0531,  0.1032, -0.3259,  ..., -2.6939,  0.0000, -0.0000]],\n",
       "       device='cuda:0', grad_fn=<CatBackward0>)"
      ]
     },
     "execution_count": 137,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#decoder_out: 디코더 연산 결과\n",
    "#weighted : attention_output(어텐션 결과) encoder_output(인코더 결과) 곱\n",
    "#embedded: ##입력한 단어 38 => \"부지역\" 특성을 저장한 배열\n",
    "#torch.cat(): 하나로 합침\n",
    "#dim = 1 : 배열의 1번째 차원에서 합침\n",
    "torch.cat((decoder_out.cuda(), weighted.cuda(), embedded.cuda()), dim = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "id": "853942ab-b842-4eb0-b318-dd3ee350d18d",
   "metadata": {},
   "outputs": [],
   "source": [
    "decoder_out = torch.cat((decoder_out.cuda(), weighted.cuda(), embedded.cuda()), dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "id": "016ad5f6-dafa-44d3-8b7a-9faaf993659d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 1664])"
      ]
     },
     "execution_count": 139,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "decoder_out.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "id": "bc7b1aaa-8c7e-411e-8ebf-55098113dcf5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#nn.Linear: 선형회귀를 실행 할 객체 생성\n",
    "fc_out = nn.Linear(\n",
    "                    (HID_DIM*2) + HID_DIM+ EMB_DIM, #입력값의 열 개수 \n",
    "                                                    #(HID_DIM(512)*2) + HID_DIM(512) + EMB_DIM(128) = 1664\n",
    "                    OUTPUT_DIM #선형 회귀 결과의 열개수 OUTPUT_DIM(162)\n",
    ").cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "id": "67e0ef76-8666-4d8f-b5c4-7015f14793dd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.2303, -0.1374,  0.3837,  ...,  0.0708, -0.0787, -0.1628]],\n",
       "       device='cuda:0', grad_fn=<AddmmBackward0>)"
      ]
     },
     "execution_count": 141,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#decoder_out : 디코더 연산 결과\n",
    "#weighted : attention_output (어텐션 결과) encoder_output(인코더결과) 곱\n",
    "#embedded : ##입력한 단어 38 => \"부지역\" 특성을 저장한 배열\n",
    "#을 1개로 통합한 decoder_out\n",
    "#선형회귀 실행\n",
    "fc_out(decoder_out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "id": "ae579376-589b-438a-911f-ece49a5e8932",
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction = fc_out(decoder_out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "id": "c39acf95-64ab-4ac4-b3e8-95d0b930b9bf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.2303, -0.1374,  0.3837,  ...,  0.0708, -0.0787, -0.1628]],\n",
       "       device='cuda:0', grad_fn=<AddmmBackward0>)"
      ]
     },
     "execution_count": 143,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#예측결과\n",
    "prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "id": "0f55ca8c-7296-4e72-9b59-02414668ec92",
   "metadata": {},
   "outputs": [],
   "source": [
    "#디코더 연산을 클래스로 구현\n",
    "class Decoder(nn.Module):\n",
    "    def __init__(self, output_dim, emb_dim, hid_dim, n_layer, attention, dropout):\n",
    "        super().__init__()\n",
    "\n",
    "        self.output_dim = output_dim\n",
    "        self.hid_dim = hid_dim\n",
    "        self.attention = attention\n",
    "        self.n_layer = n_layer\n",
    "        self.embedding = nn.Embedding(output_dim, emb_dim)\n",
    "\n",
    "        self.gru = nn.GRU(hid_dim*2+emb_dim,hid_dim)\n",
    "        self.fc_out = nn.Linear((hid_dim*2)+hid_dim+emb_dim, output_dim)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "\n",
    "    def forward(self, input, encoder_hidden, encoder_output):\n",
    "\n",
    "        input = input.unsqueeze(0)\n",
    "        embedded = self.dropout(self.embedding(input))\n",
    "\n",
    "        attention_output = self.attention(encoder_hidden, encoder_output)\n",
    "        attention_output = attention_output.unsqueeze(1)\n",
    "\n",
    "        weighted = torch.bmm(attention_output, encoder_output)\n",
    "\n",
    "        weighted = weighted.permute(1,0,2)\n",
    "\n",
    "        rnn_input = torch.cat((embedded, weighted), dim = 2)\n",
    "\n",
    "        decoder_output, decoder_hidden = self.gru(rnn_input, encoder_hidden.unsqueeze(0))\n",
    "\n",
    "        embedded = embedded.squeeze(0)\n",
    "        decoder_output = decoder_output.squeeze(0)\n",
    "        weighted = weighted.squeeze(0)\n",
    "\n",
    "        prediction = self.fc_out(torch.cat((decoder_output, weighted, embedded), dim = 1))\n",
    "\n",
    "        return prediction,decoder_hidden.squeeze(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "id": "5ca7b962-f491-4985-b518-f77677e8ecba",
   "metadata": {},
   "outputs": [],
   "source": [
    "#SequenceToSequence 구현\n",
    "\n",
    "class GRU_AT_Seq2Seq(nn.Module):\n",
    "\n",
    "    def __init__(self, encoder, decoder, device):\n",
    "        super().__init__()\n",
    "\n",
    "        self.encoder = encoder\n",
    "        self.decoder = decoder\n",
    "        self.device = device\n",
    "\n",
    "    #딥러닝 학습시 호출되는 함수\n",
    "    #src : 수어 keypoint\n",
    "    #trg : 수어 스크립트 문장이 저장\n",
    "    def forward(self, src, trg, teacher_forcing_ration = 0.5):\n",
    "        #trg.shape[0] : trg에 저장된 문장의 개수 (16)\n",
    "        batch_size = trg.shape[0]\n",
    "\n",
    "        #trg.shape[1] : 수어 스크립트 단어의 개수 (30)\n",
    "        trg_len = trg.shape[1]\n",
    "\n",
    "        #decoder.output_dim : 수어 스크립트를 구성하는 단어의 개수 (162)\n",
    "        trg_vocab_size = self.decoder.output_dim\n",
    "\n",
    "        #torch.zeros(trg_len, batch_size, trg_vocab_size): 0으로 초기화된 배열 생성\n",
    "                                                        # 배열 shape[trg_len(30), batch_size(16), trg_vocab_size(162)]\n",
    "        output = torch.zeros(trg_len, batch_size, trg_vocab_size).cuda()\n",
    "\n",
    "        #self.encoder(src) : 인코더 연산 실행\n",
    "        encoder_output, hidden = self.encoder(src)\n",
    "\n",
    "        #trg[:,0] :수어스크립트 trg 0번째 칸 리턴 <START>\n",
    "        input = trg[:,0]\n",
    "\n",
    "        for t in range(1, trg_len):\n",
    "            #self.decoder(input, hidden, encoder_output) :디코더 연산 실행\n",
    "            decoder_output, hidden = self.decoder(input, hidden, encoder_output)\n",
    "\n",
    "            output [t] = decoder_output        #decoder_output: 디코더 연산 결과\n",
    "\n",
    "            #random.random() < teacher_forcing_ration : 0~1 사이 난수를 생성해서 난수가 0.5 미만이면 난수 리턴\n",
    "                                                     # 난수가 0.5이상이면 None 리턴\n",
    "\n",
    "            teacher_force = random.random() < teacher_forcing_ration\n",
    "\n",
    "            #decoder_output.argmax(1) : decoder_output에서 가장 확률이 높은 단어 대입\n",
    "            top1 = decoder_output.argmax(1)\n",
    "\n",
    "            #trg[:,t] if teacher_force : teacher_force 가 None이 아니면 수어스크립트가 저장된 trg[:,t] 리턴\n",
    "            #  else top1:                teacher_force 가 None이면 decoder의 예측값 top1리턴\n",
    "            input = trg[:,t] if teacher_force else top1\n",
    "\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "id": "48c7c9c0-94d6-41dc-9984-6c6b6c8cf159",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "134"
      ]
     },
     "execution_count": 146,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "id": "8d6f4f97-6ce2-49ac-84d1-7718fe7f33ef",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Encoder(\n",
       "  (gru): GRU(134, 512, num_layers=2, batch_first=True, bidirectional=True)\n",
       "  (fc): Linear(in_features=2048, out_features=512, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 147,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "enc = Encoder(input_size, HID_DIM, N_LAYER).to(device)\n",
    "enc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "id": "1f3f47b2-424d-4dee-b7a8-74f036f12ac9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Attention(\n",
       "  (attn): Linear(in_features=1536, out_features=512, bias=True)\n",
       "  (v): Linear(in_features=512, out_features=1, bias=False)\n",
       ")"
      ]
     },
     "execution_count": 148,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "att = Attention(HID_DIM).to(device)\n",
    "att"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "id": "b9c35484-90da-49a2-b9dc-32d386ac5ca4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Decoder(\n",
       "  (attention): Attention(\n",
       "    (attn): Linear(in_features=1536, out_features=512, bias=True)\n",
       "    (v): Linear(in_features=512, out_features=1, bias=False)\n",
       "  )\n",
       "  (embedding): Embedding(1078, 128)\n",
       "  (gru): GRU(1152, 512)\n",
       "  (fc_out): Linear(in_features=1664, out_features=1078, bias=True)\n",
       "  (dropout): Dropout(p=0.5, inplace=False)\n",
       ")"
      ]
     },
     "execution_count": 149,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dec = Decoder(OUTPUT_DIM, EMB_DIM, HID_DIM, N_LAYER, att, DEC_DROPOUT).to(device)\n",
    "dec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "id": "850d8a92-59ec-432d-9379-aada12562190",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GRU_AT_Seq2Seq(\n",
       "  (encoder): Encoder(\n",
       "    (gru): GRU(134, 512, num_layers=2, batch_first=True, bidirectional=True)\n",
       "    (fc): Linear(in_features=2048, out_features=512, bias=True)\n",
       "  )\n",
       "  (decoder): Decoder(\n",
       "    (attention): Attention(\n",
       "      (attn): Linear(in_features=1536, out_features=512, bias=True)\n",
       "      (v): Linear(in_features=512, out_features=1, bias=False)\n",
       "    )\n",
       "    (embedding): Embedding(1078, 128)\n",
       "    (gru): GRU(1152, 512)\n",
       "    (fc_out): Linear(in_features=1664, out_features=1078, bias=True)\n",
       "    (dropout): Dropout(p=0.5, inplace=False)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 150,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = GRU_AT_Seq2Seq(enc,dec,device).to(device)\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "id": "5c198a3e-b985-4fdb-b9ed-6c808171dab0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def init_weights(m):\n",
    "    for name, param in m.named_parameters():\n",
    "        nn.init.uniform_(param.data, -0.08, 0.08)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "id": "724932bc-0173-4235-a9a7-e9f6765b4c3c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GRU_AT_Seq2Seq(\n",
       "  (encoder): Encoder(\n",
       "    (gru): GRU(134, 512, num_layers=2, batch_first=True, bidirectional=True)\n",
       "    (fc): Linear(in_features=2048, out_features=512, bias=True)\n",
       "  )\n",
       "  (decoder): Decoder(\n",
       "    (attention): Attention(\n",
       "      (attn): Linear(in_features=1536, out_features=512, bias=True)\n",
       "      (v): Linear(in_features=512, out_features=1, bias=False)\n",
       "    )\n",
       "    (embedding): Embedding(1078, 128)\n",
       "    (gru): GRU(1152, 512)\n",
       "    (fc_out): Linear(in_features=1664, out_features=1078, bias=True)\n",
       "    (dropout): Dropout(p=0.5, inplace=False)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 152,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.apply(init_weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "id": "4467a71b-f888-400c-b86d-8ce7d9566d1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = torch.optim.Adam(model.parameters(),lr = learning_rate)\n",
    "criterion = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "id": "775720dd-9711-46fb-91e3-d81a2bc75df0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, dataloader, OUTPUT_DIM,optimizer, criterion, clip):\n",
    "    #학습시작\n",
    "    model.train()\n",
    "\n",
    "    epoch_loss = 0\n",
    "    \n",
    "    #dataloader : keypoint와 수어스크립트 단어를 리턴하는 객체\n",
    "    #input: keypoint\n",
    "    #target: 수어스크립트 단어\n",
    "    for i, (input, target) in enumerate(dataloader):\n",
    "\n",
    "        src = input #keypoint 대입\n",
    "        trg = target #수어스크립트 단어 대입\n",
    "        \n",
    "        #torch.cuda.is_available() : GRU 사용 가능하면 True\n",
    "        if torch.cuda.is_available():\n",
    "            model.cuda() #model을 gru에 저장\n",
    "\n",
    "            #src.cuda(): src를 GPU에 저장\n",
    "            #.float(): 실수타입으로 변환\n",
    "            src = src.cuda().float()\n",
    "\n",
    "            #trg.cuda(): trg를 GPU에 저장\n",
    "            #.long(): long타입으로 변환\n",
    "            trg = trg.cuda().long()\n",
    "\n",
    "        #0으로 초기화\n",
    "        optimizer.zero_grad()\n",
    "        #model 실행\n",
    "        output = model(src, trg)\n",
    "\n",
    "        #output[0] => <START>  입력의 예측결과 저장\n",
    "        #output[1] : 수어 스크립트 저장\n",
    "\n",
    "        #view(-1, OUTPUT_DIM): 배열 차원을 OUTPUT_DIM(162)열로 변환\n",
    "                                # 행은 생략(-1)\n",
    "        output = output[1:].view(-1, OUTPUT_DIM)\n",
    "        #torch.transpose(trg,0,1): trg 배열 차원의 0번째(행) 1번째(열) 서로 바꾸기\n",
    "        trg = torch.transpose(trg,0,1)\n",
    "\n",
    "        #trg[1:].contiguous() : 배열에 저장된 요소들의 메모리 주소가 서로 인접하도록 설정\n",
    "        #view(-1) :1 차원 배열로 변환\n",
    "        trg = trg[1:].contiguous().view(-1)\n",
    "\n",
    "        #criterion(output, trg) : output(예측한 수어스크립트) trg(실제 수어스크립트)의 차이를 계산\n",
    "        loss = criterion(output, trg)\n",
    "\n",
    "        #역전파 실행\n",
    "        loss.backward()\n",
    "\n",
    "        #output(예측한 수어스크립트) trg(실제 수어스크립트) 의 loss가 1이상이면 #loss를 clip(1)로 치환해서 역전파 실행\n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(),clip)\n",
    "\n",
    "        #역전파 결과로 매개변수 수정\n",
    "        optimizer.step()\n",
    "\n",
    "        epoch_loss += loss.item()\n",
    "    return epoch_loss / len(dataloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "id": "ee4994c4-5440-43ac-8053-349fd34b0633",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f741ca299d6a4467ba5597addf9db4bb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "RuntimeError",
     "evalue": "input.size(-1) must be equal to input_size. Expected 1152, got 134",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[155], line 9\u001b[0m\n\u001b[0;32m      5\u001b[0m train_loss_Ls \u001b[38;5;241m=\u001b[39m []\n\u001b[0;32m      7\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m epoch \u001b[38;5;129;01min\u001b[39;00m tqdm(\u001b[38;5;28mrange\u001b[39m(N_EPOCH)):\n\u001b[0;32m      8\u001b[0m     \u001b[38;5;66;03m#train 함수 호출\u001b[39;00m\n\u001b[1;32m----> 9\u001b[0m     train_loss \u001b[38;5;241m=\u001b[39m \u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_dataloader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mOUTPUT_DIM\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcriterion\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mCLIP\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     11\u001b[0m     \u001b[38;5;66;03m#train_loss를 리스트에 추가\u001b[39;00m\n\u001b[0;32m     12\u001b[0m     train_loss_ls\u001b[38;5;241m.\u001b[39mappend(train_loss)\n",
      "Cell \u001b[1;32mIn[154], line 30\u001b[0m, in \u001b[0;36mtrain\u001b[1;34m(model, dataloader, OUTPUT_DIM, optimizer, criterion, clip)\u001b[0m\n\u001b[0;32m     28\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mzero_grad()\n\u001b[0;32m     29\u001b[0m \u001b[38;5;66;03m#model 실행\u001b[39;00m\n\u001b[1;32m---> 30\u001b[0m output \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43msrc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrg\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     32\u001b[0m \u001b[38;5;66;03m#output[0] => <START>  입력의 예측결과 저장\u001b[39;00m\n\u001b[0;32m     33\u001b[0m \u001b[38;5;66;03m#output[1] : 수어 스크립트 저장\u001b[39;00m\n\u001b[0;32m     34\u001b[0m \n\u001b[0;32m     35\u001b[0m \u001b[38;5;66;03m#view(-1, OUTPUT_DIM): 배열 차원을 OUTPUT_DIM(162)열로 변환\u001b[39;00m\n\u001b[0;32m     36\u001b[0m                         \u001b[38;5;66;03m# 행은 생략(-1)\u001b[39;00m\n\u001b[0;32m     37\u001b[0m output \u001b[38;5;241m=\u001b[39m output[\u001b[38;5;241m1\u001b[39m:]\u001b[38;5;241m.\u001b[39mview(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m, OUTPUT_DIM)\n",
      "File \u001b[1;32mC:\\ProgramData\\anaconda3\\envs\\ict_sign_language_env01\\lib\\site-packages\\torch\\nn\\modules\\module.py:1532\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1530\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1531\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1532\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mC:\\ProgramData\\anaconda3\\envs\\ict_sign_language_env01\\lib\\site-packages\\torch\\nn\\modules\\module.py:1541\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1536\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1537\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1538\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1539\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1540\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1541\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1543\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1544\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "Cell \u001b[1;32mIn[145], line 30\u001b[0m, in \u001b[0;36mGRU_AT_Seq2Seq.forward\u001b[1;34m(self, src, trg, teacher_forcing_ration)\u001b[0m\n\u001b[0;32m     27\u001b[0m output \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mzeros(trg_len, batch_size, trg_vocab_size)\u001b[38;5;241m.\u001b[39mcuda()\n\u001b[0;32m     29\u001b[0m \u001b[38;5;66;03m#self.encoder(src) : 인코더 연산 실행\u001b[39;00m\n\u001b[1;32m---> 30\u001b[0m encoder_output, hidden \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mencoder\u001b[49m\u001b[43m(\u001b[49m\u001b[43msrc\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     32\u001b[0m \u001b[38;5;66;03m#trg[:,0] :수어스크립트 trg 0번째 칸 리턴 <START>\u001b[39;00m\n\u001b[0;32m     33\u001b[0m \u001b[38;5;28minput\u001b[39m \u001b[38;5;241m=\u001b[39m trg[:,\u001b[38;5;241m0\u001b[39m]\n",
      "File \u001b[1;32mC:\\ProgramData\\anaconda3\\envs\\ict_sign_language_env01\\lib\\site-packages\\torch\\nn\\modules\\module.py:1532\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1530\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1531\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1532\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mC:\\ProgramData\\anaconda3\\envs\\ict_sign_language_env01\\lib\\site-packages\\torch\\nn\\modules\\module.py:1541\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1536\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1537\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1538\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1539\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1540\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1541\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1543\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1544\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "Cell \u001b[1;32mIn[49], line 22\u001b[0m, in \u001b[0;36mEncoder.forward\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m     20\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, x):\n\u001b[0;32m     21\u001b[0m     h0 \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mzeros(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_layer\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m2\u001b[39m, x\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m], \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhid_dim)\u001b[38;5;241m.\u001b[39mcuda()\u001b[38;5;241m.\u001b[39mfloat()\n\u001b[1;32m---> 22\u001b[0m     encoder_output, encoder_hidden \u001b[38;5;241m=\u001b[39m \u001b[43mgru\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43mh0\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     24\u001b[0m     encoder_hidden \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mcat((\n\u001b[0;32m     25\u001b[0m         encoder_hidden[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m4\u001b[39m,:,:],\n\u001b[0;32m     26\u001b[0m         encoder_hidden[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m3\u001b[39m,:,:],\n\u001b[0;32m     27\u001b[0m         encoder_hidden[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m2\u001b[39m,:,:],\n\u001b[0;32m     28\u001b[0m         encoder_hidden[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m,:,:]\n\u001b[0;32m     29\u001b[0m     ), dim \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m)\n\u001b[0;32m     31\u001b[0m     encoder_hidden \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mtanh(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfc(encoder_hidden))\n",
      "File \u001b[1;32mC:\\ProgramData\\anaconda3\\envs\\ict_sign_language_env01\\lib\\site-packages\\torch\\nn\\modules\\module.py:1532\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1530\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1531\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1532\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mC:\\ProgramData\\anaconda3\\envs\\ict_sign_language_env01\\lib\\site-packages\\torch\\nn\\modules\\module.py:1541\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1536\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1537\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1538\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1539\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1540\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1541\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1543\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1544\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32mC:\\ProgramData\\anaconda3\\envs\\ict_sign_language_env01\\lib\\site-packages\\torch\\nn\\modules\\rnn.py:1131\u001b[0m, in \u001b[0;36mGRU.forward\u001b[1;34m(self, input, hx)\u001b[0m\n\u001b[0;32m   1126\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   1127\u001b[0m         \u001b[38;5;66;03m# Each batch of the hidden state should match the input sequence that\u001b[39;00m\n\u001b[0;32m   1128\u001b[0m         \u001b[38;5;66;03m# the user believes he/she is passing in.\u001b[39;00m\n\u001b[0;32m   1129\u001b[0m         hx \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpermute_hidden(hx, sorted_indices)\n\u001b[1;32m-> 1131\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcheck_forward_args\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mhx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_sizes\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1132\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m batch_sizes \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m   1133\u001b[0m     result \u001b[38;5;241m=\u001b[39m _VF\u001b[38;5;241m.\u001b[39mgru(\u001b[38;5;28minput\u001b[39m, hx, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_flat_weights, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbias, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnum_layers,\n\u001b[0;32m   1134\u001b[0m                      \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdropout, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtraining, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbidirectional, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbatch_first)\n",
      "File \u001b[1;32mC:\\ProgramData\\anaconda3\\envs\\ict_sign_language_env01\\lib\\site-packages\\torch\\nn\\modules\\rnn.py:274\u001b[0m, in \u001b[0;36mRNNBase.check_forward_args\u001b[1;34m(self, input, hidden, batch_sizes)\u001b[0m\n\u001b[0;32m    273\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcheck_forward_args\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor, hidden: Tensor, batch_sizes: Optional[Tensor]):\n\u001b[1;32m--> 274\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcheck_input\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_sizes\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    275\u001b[0m     expected_hidden_size \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mget_expected_hidden_size(\u001b[38;5;28minput\u001b[39m, batch_sizes)\n\u001b[0;32m    277\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcheck_hidden_size(hidden, expected_hidden_size)\n",
      "File \u001b[1;32mC:\\ProgramData\\anaconda3\\envs\\ict_sign_language_env01\\lib\\site-packages\\torch\\nn\\modules\\rnn.py:240\u001b[0m, in \u001b[0;36mRNNBase.check_input\u001b[1;34m(self, input, batch_sizes)\u001b[0m\n\u001b[0;32m    237\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[0;32m    238\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124minput must have \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mexpected_input_dim\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m dimensions, got \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28minput\u001b[39m\u001b[38;5;241m.\u001b[39mdim()\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m    239\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39minput_size \u001b[38;5;241m!=\u001b[39m \u001b[38;5;28minput\u001b[39m\u001b[38;5;241m.\u001b[39msize(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m):\n\u001b[1;32m--> 240\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[0;32m    241\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124minput.size(-1) must be equal to input_size. Expected \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39minput_size\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, got \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28minput\u001b[39m\u001b[38;5;241m.\u001b[39msize(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m)\n",
      "\u001b[1;31mRuntimeError\u001b[0m: input.size(-1) must be equal to input_size. Expected 1152, got 134"
     ]
    }
   ],
   "source": [
    "#학습진행\n",
    "\n",
    "best_loss = float('inf')\n",
    "\n",
    "train_loss_Ls = []\n",
    "\n",
    "for epoch in tqdm(range(N_EPOCH)):\n",
    "    #train 함수 호출\n",
    "    train_loss = train(model, train_dataloader, OUTPUT_DIM, optimizer, criterion, CLIP)\n",
    "\n",
    "    #train_loss를 리스트에 추가\n",
    "    train_loss_ls.append(train_loss)\n",
    "\n",
    "    #train_loss가 best_loss 미만\n",
    "    if train_loss < best_loss:\n",
    "        #train_loss를 대입\n",
    "        best_loss = train_loss\n",
    "        #학습모델 저장\n",
    "        torch.sava(model.state_dict(), f'{model_sava_path}{save_model_name}')\n",
    "\n",
    "    #cache 삭제\n",
    "    torch.cuda.empty_cache()\n",
    "    print(f'Epoch:{epoch + 1:02}')\n",
    "    print(f'\\t Train Loss: {train_loss:.3f} | Train PPL: {math.exp(train_loss):7.3f}')\n",
    "    print(\"=\"*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c24455bf-5db8-4cc8-9d15-8fa81babf595",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
